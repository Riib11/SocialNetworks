{"entities":["Address space","Algorithm","Baseline (configuration management)","Big data","Cache (computing)","Cube","Data compression","Dynamic Markov compression","Hybrid Memory Cube","Locality of reference","Multiple granularity locking","OpenVMS","Page (computer memory)","Server (computing)","Translation lookaside buffer"],"journalVolume":"","journalPages":"206-218","pmid":"","year":2017,"outCitations":["309ad0357af7722a24192781340881390055a3db","d4e153d0ff33cb15cd6c13570599c6c36cc78db5","1121c104e9d2951462f67f8eb364f043fe9a65e5","4c689148ee5e9d6d116f6babbfab21bf2116802e","94973810b159138f16577179daf63fc3c19f3224","297c981cc41ac8073f4a9aeda6f4a1039ce3a0f0","41b24c890ae0ef99ff031c9c8549375af6025fb6","44607270754f8521d6c4d42297aa881393f4f8e0","33da3dcba06cf453f74203e3fb2adaa8c1133f3b","7f23db6b9ea34556e90f1e49b0e91ade82c9d2d5","59d426dda9e2d2db7b887440a77adebb1227631b","4f02395639cfdac14ea42e99b18fde92f8288b63","bd64635ee260c3fec8589f6af402b92db8142c15","11a3cacd4e3f11d61203aa4c68b124ab5fe54ba3","8b04ea524cb6ced72868c120a00c4679d84be006","87a4156fc53e76450b4766cea45edd4bb7e84b7d","a7bf5729876a0499cd4a1fa428622e3fa47c5016","54a15f2c25bec4274d5bb423dbc5002426a506a3","12bc20a1963859e9f76afb4b308b90ded1cff1fe","6785219a4e5901962137299bded495dd5c841729","56017a274989ce08c331a5bf6b7f435665d69c97","49dc03814c171c08331fe9f1afc34a54951ae8e0","12d6da762b2a5d512d383f3b587bd30c23c3df97","3d951ad1164c17217a24e46b57f9b31cea1b2b96","64320211fdc563ebf03c1ed972d6eee5661ac876","72166f3aa4cdbc91d65b890b83c8c084dec846b0","e7c6f67a70b5cf0842a7a2fc497131a79b6ee2c5","052095bb131a0942053be4ff4097b41c429c7e65","bc4ebb16afeb93a8ebbce34eb0e759b4fb4e80d7"],"s2Url":"https://semanticscholar.org/paper/aaa11576d4ebd0b17dd3750189cbe7785b2fa188","s2PdfUrl":"","id":"aaa11576d4ebd0b17dd3750189cbe7785b2fa188","authors":[{"name":"Seikwon Kim","ids":["2836493"]},{"name":"Seonyoung Lee","ids":["8569719"]},{"name":"Taehoon Kim","ids":["1837923"]},{"name":"Jaehyuk Huh","ids":["36595712"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"The increasing memory requirements of big data applications have been driving the precipitous growth of memory capacity in server systems. To maximize the efficiency of external memory, HW-based memory compression techniques have been proposed to increase effective memory capacity. Although such memory compression techniques can improve the memory efficiency significantly, a critical trade-off exists in the HW-based compression techniques. As the memory blocks need to be decompressed as quickly as possible to serve cache misses, latency-optimized techniques apply compression at the cacheline granularity, achieving the decompression latency of less than a few cycles. However, such latency-optimized techniques can lose the potential high compression ratios of capacity-optimized techniques, which compress larger memory blocks with longer latency algorithms.Considering the fundamental trade-off in the memory compression, this paper proposes a transparent dual memory compression (DMC) architecture, which selectively uses two compression algorithms with distinct latency and compression characteristics. Exploiting the locality of memory accesses, the proposed architecture compresses less frequently accessed blocks with a capacity-optimized compression algorithm, while keeping recently accessed blocks compressed with a latency-optimized one. Furthermore, instead of relying on the support from the virtual memory system to locate compressed memory blocks, the study advocates a HW-based translation between the uncompressed address space and compressed physical space. This OS-transparent approach eliminates conflicts between compression efficiency and large page support adopted to reduce TLB misses. The proposed compression architecture is applied to the Hybrid Memory Cube (HMC) with a logic layer under the stacked DRAMs. The experimental results show that the proposed compression architecture provides 54% higher compression ratio than the state-of-the-art latency-optimized technique, with no performance degradation over the baseline system without compression.","inCitations":[],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.12"],"title":"Transparent Dual Memory Compression Architecture","doi":"10.1109/PACT.2017.12","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.12","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Algorithm","Automatic vectorization","Compiler","Experiment","Holism","Line code","Parallel computing","SIMD","Scalar processor","Successive linear programming","SuicideGirls","Superword Level Parallelism","Top-down and bottom-up design","Unreachable memory"],"journalVolume":"","journalPages":"330-342","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/5fc51880d9b8a75549d4063def7441d7424881bf","s2PdfUrl":"","id":"5fc51880d9b8a75549d4063def7441d7424881bf","authors":[{"name":"Vasileios Porpodas","ids":["2589074"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"SIMD vectors help improve the performance of certain applications. The code gets vectorized into SIMD form either by hand, or automatically with auto-vectorizing compilers. The Superword-Level Parallelism (SLP) vectorization algorithm is a widely used algorithm for vectorizing straight-line code and is part of most industrial compilers. The algorithm attempts to pack scalar instructions into vectors starting from specific seed instructions in a bottom-up way. This approach, however, suffers from two main problems: (i) the algorithm may not reach instructions that could have been vectorized, and (ii) atomically operating on individual SLP graphs suffers from cost overestimation when consecutive SLP graphs share data. Both issues lead to missed vectorization opportunities even in simple code.In this work we propose SuperGraph-SLP (SG-SLP), an improved vectorization algorithm that overcomes these limitations of the existing algorithm. SG-SLP operates on a larger region, called the SuperGraph. This allows it to reach and successfully vectorize code that was previously unreachable. Moreover, the new region helps eliminate the inaccuracies in the cost-calculation as it allows for a more holistic view of the code. Our experiments show that SG-SLP improves the vectorization coverage and outperforms the state-of-the-art SLP across a number kernels by 36% on average, without affecting the compilation time.","inCitations":["5cdd10ad78b4d50888c837196839acb15c88298d"],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.21"],"title":"SuperGraph-SLP Auto-Vectorization","doi":"10.1109/PACT.2017.21","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.21","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Heuristic","Network on a chip","Router (computing)","Simulation","Span and div","Value-driven design"],"journalVolume":"","journalPages":"260-272","pmid":"","year":2017,"outCitations":["4d2bdb8d9da5b1b20708b8f41f93e7b85cd8ad51","50de0f6a952131dfe562c5b3836e5d934b39b939","621f06195844f960c7afca4aa04fc39dc12ba559","7a09870c68862177d92892474700fd34b335f71a","3ed84f2fbdc4dc6450919ec5b017e66440a5833c","4f59ff5b79482f498bbb178cc6d73ae4b8eadd9b","e7c1e6ece41d2a4db49354cc5166ead63cd250f6","339ae2f3507728126b32fb2e077f3e5707dae774","5facba913915834c37f340eca9df5618cc350547","3966eb5cabdef5b437708a958d0480b34a87bbaf","932d6f2725ac81019dcab28386871ebe93115c9b","fc8da95a002aa377778d9d06afcd937ebe414340","27c3c07363666d5dd7a28d8c329ed3154148ae76","bfa696236c766973328bdfe3f7fd3ffd7ac9a607","19d38434e785e3e27ed1bb4bf8cc119c0032407c","f644e5ed34af1a47b80a8428c8e812082f1c3dae","6e31fffc237af47fc0f09064d38465f28aa99941","90ab2cdb38a005f887227a0904f4c4483fcc5871","10dc03bab236aa58778b74520978ec280ecdf731","184e36291edee5e9d850219fc07f61d2ef7bf00f","6a9773de27440377ca480fae7c3f1a4324f0fc0a","1c5e8319f4497d829049d8ea05dca782eed200ef","46921fd25823cb6a7d0a5310f39667fe19baac65","5f049497fab24c39cb69eff6defc5731dcf217a9","5236160832766c58b1be2bf4f76f33d9d25b4600","3acc24a9954a323149209c2a49a5a4e3603d2ae3","47a356bf5462a495fd2240a11665a23969e1202c","6bad4549c14a39dee0cdd3a29455fba584d61e0a","3315112da21a8806581d473b9168b50648bf65f0","481309c85ade5f4ff5770613ce6acb49acb12396","e1be591e0bd8eda4ef109166db0b5edeb9ad934b","0b0b8f1c3ffa887bf8080a3d44348c3d98a11272","0573066c173d07f01d543392d311430a015845fa","0c89d5d37a25f693bc31e65c0c5b9bea63148e57","42d96591e5583c2001c100d979a8f180e1a4e6b1","2444d6e88c9f18ea35c329fc78a2cb22688076ae","650954f9731cdcdf75beb3fb33765815828c598f","009400317f5bd193079715b821aecd7f1ac45704","066c073180c003718a8b667db823c6fcd23cd30a","b7e033561f964c657491b8f25fecc8480764bf80","1260dbc45978a1d9ed57dc2e96e239b9a23f013e","35c1c691ece3069baf5712a1b5cce4bbd345953e","120490f2ed5937bbec70fcc4d8bf0a13cce9fba5","ffecbd183dff55bd98e9cfc8c11ffb4f29031b78","16a7dba3aeae984e32183bda49c4c5612d51bb8a","329756f2d29829e1b2e713360016995855d0ea26","3446d6833234bf1924b3b82fec84b766b65a72cb","b1162cf8d956f02acecb40e1ca457a62619c4d8a","5175688633b7c22fdd0b1bec4f042c30d1650a15","f57ac7f53438b2877022125bac957fda2bb2a97b","485b9204a1df97fceb4aedbc62e9efbc09a4525a","63cc9119a1d29ef68c8ae5d1db44f53fe15625e5"],"s2Url":"https://semanticscholar.org/paper/99201dc46fb530777d6645a6f376d554c270fb88","s2PdfUrl":"","id":"99201dc46fb530777d6645a6f376d554c270fb88","authors":[{"name":"Raghavendra Pradyumna Pothukuchi","ids":["3449317"]},{"name":"Amin Ansari","ids":["2186447"]},{"name":"Bhargava Gopireddy","ids":["3384083"]},{"name":"Josep Torrellas","ids":["1695950"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Networks-on-Chip (NoCs) in chip multiprocessors are prone to within-die process variation as they span the whole chip. To tolerate variation, their voltages (Vdd) carry over-provisioned guardbands. As a result, prior work has proposed to save energy by operating at reduced Vdd while occasionally suffering and fixing errors. Unfortunately, these proposals use heuristic controller designs that provide no error bounds guarantees.In this work, we develop a scheme that dynamically minimizes the Vdd of groups of routers in a variation-prone NoC using formal control-theoretic methods. The scheme, called Sthira, saves substantial energy while guaranteeing the stability and convergence of error rates. We also enhance the scheme with a low-cost secondary network that retransmits erroneous packets for higher energy efficiency. The enhanced scheme is called Sthira+. We evaluate Sthira and Sthira+ with simulations of NoCs with 64-100 routers. In an NoC with 8 routers per Vdd domain, our schemes reduce the average energy consumptionof the NoC by 27%; in a futuristic NoC with one router per Vdd domain, Sthira+ and Sthira reduce the average energy consumption by 36% and 32%, respectively. The performance impact is negligible. These are significant savings over the state-of-the-art. We conclude that formal control is essential, and that the cheaper Sthira is more cost-effective than Sthira+.","inCitations":[],"pdfUrls":["http://iacoma.cs.uiuc.edu/iacoma-papers/pact17.pdf","http://iacoma.cs.uiuc.edu/iacoma-papers/PRES/present_pact17.pdf","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.23"],"title":"Sthira: A Formal Approach to Minimize Voltage Guardbands under Variation in Networks-on-Chip for Energy Efficiency","doi":"10.1109/PACT.2017.23","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.23","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Algorithm","Computation","Data structure","General-purpose computing on graphics processing units","Graphics","Graphics processing unit","Posting style","Skip list"],"journalVolume":"","journalPages":"449-450","pmid":"","year":2017,"outCitations":["3c9b5b9e3e8ad647498f1650df08ac2a4fa83346","762f5a712f4d6994ead089fcc0c5db98479a2008","1ae7993c0c2d795b243354de48dab80bf2000356","d410f8128bd4efa6adc886259e5d9de4cd7587bc"],"s2Url":"https://semanticscholar.org/paper/81844d32b15beba1555c77b0048ebac353e7fda1","s2PdfUrl":"","id":"81844d32b15beba1555c77b0048ebac353e7fda1","authors":[{"name":"Nurit Moscovici","ids":["9560905"]},{"name":"Nachshon Cohen","ids":["2898845"]},{"name":"Erez Petrank","ids":["2210090"]}],"journalName":"","paperAbstract":"We propose a design for a fine-grained lock-based skiplist optimized for Graphics Processing Units (GPUs). While GPUs are often used to accelerate streaming parallel computations, it remains a significant challenge to efficiently offload concurrent computations with more complicated data-irregular access and fine-grained synchronization. Natural building blocks for such computations would be concurrent data structures, such as skiplists, which are widely used in general purpose computations. Our design utilizes array-based nodes which are accessed and updated by warp-cooperative functions, thus taking advantage of the fact that GPUs are most efficient when memory accesses are coalesced and execution divergence is minimized. The proposed design has been implemented, and measurements demonstrate improved performance of up to 2.6x over skiplist designs for the GPU existing today.","inCitations":["f85ea15f5d417dc9b1cac8f58bec7157df47e6ba","729b5839ec8f9078f32b4c5f0f0115fdcc4317c9"],"pdfUrls":["http://dl.acm.org/citation.cfm?id=3019032"],"title":"POSTER: A GPU-Friendly Skiplist Algorithm","doi":"10.1145/3018743.3019032","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3018743.3019032","venue":"PPOPP"},
{"entities":["AVL tree","Algorithm","HTML","In-place algorithm","Multi-core processor","Non-blocking algorithm","Read-copy-update","Read-only memory","Red–black tree","Server (computing)","TRAVERSE","Transactional memory","Tree structure"],"journalVolume":"","journalPages":"1-13","pmid":"","year":2017,"outCitations":["491091e7b99ef8f663886a802e8efe4f5ee58c87","663eda36657a10a2ab0d1e6482b0844efb1291cc","00b3ebd315991e5b5f4e6beec2e1488281368028","e9af96fbbacb4268c3c5ff974cc44990b12294e5","0c11bb1c8a50f81c30a82d76b1f1bfb5b4f8693b","3c2ffc86bcdd1de048983c77f6222e888b3814df","0b82470bb9cd233bff6228d3d1b484024b9f9c3b","0bddbe35fa6e3cf625d15553365a690d3a6bf7aa","6a26e67389ed9b975c79ddcd711bdadb32e56bdc","38611b424808954be2c1375da1a873b1e2487ace","9a8ff6073b183de6940bba457fb6f996736c39a2","1cb0679ae82be093268747da0f634281ea6a41df","4f499f49640fb39d16b9c05f42503b5d6b0cb531","42142c121b2dbe48d55e81c2ce198a5639645030","21e51da40ab080ca2b71ad36094e2b686008b6cc","1372e033396fe1a5aa12a1b148c5015a2e09d1d6","2ea25f6ba6e9758e25514e3a6b89fe968bfd6707","023ba3dff9e17a15ae8448ec6cacc3e9a5ff116a","2cda119834a1bbaf73dcc6a83a0057af91a666a1","500adfb955f443c9fb0b8a44a5a03887fa4e9729","6075f8bfc541841270f223de64b577e17a748b75","6abf5107efc723c655956f027b4a67565b048799","00b5fe0e942f292414329a5621a53da4016cdb3e","3f339e7075319465a2a7937995d7d56089114a34"],"s2Url":"https://semanticscholar.org/paper/ce74142a87fb28a60cf480898ed4257d59c7b2e3","s2PdfUrl":"","id":"ce74142a87fb28a60cf480898ed4257d59c7b2e3","authors":[{"name":"Dimitrios Siakavaras","ids":["27832849"]},{"name":"Konstantinos Nikas","ids":["2260192"]},{"name":"Georgios I. Goumas","ids":["2825685"]},{"name":"Nectarios Koziris","ids":["1774783"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"In this paper we introduce RCU-HTM, a technique that combines Read-Copy-Update (RCU) with Hardware Transactional Memory (HTM) to implement highly efficient concurrent Binary Search Trees (BSTs). Similarly to RCU-based algorithms, we perform the modifications of the tree structure in private copies of the affected parts of the tree rather than in-place. This allows threads that traverse the tree to proceed without any synchronization and without being affected by concurrent modifications. The novelty of RCU-HTM lies at leveraging HTM to permit multiple updating threads to execute concurrently. After appropriately modifying the private copy, we execute an HTM transaction, which atomically validates that all the affected parts of the tree have remained unchanged since they've been read and, only if this validation is successful, installs the copy in the tree structure.We apply RCU-HTM on AVL and Red-Black balanced BSTs and compare theirperformance to state-of-the-art lock-based, non-blocking, RCU- and HTM-basedBSTs. Our experimental evaluation reveals that BSTs implemented with RCU-HTMachieve high performance, not only for read-only operations, but also for update operations. More specifically, our evaluation includes a diverse range of tree sizes and operation workloads and reveals that BSTs based on RCU-HTM outperform other alternatives by more than 18%, on average, on a multi-core server with 44 hardware threads.","inCitations":[],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.17"],"title":"RCU-HTM: Combining RCU with HTM to Implement Highly Efficient Concurrent Binary Search Trees","doi":"10.1109/PACT.2017.17","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.17","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Adaptive filter","Complex adaptive system","Limiter","Nexus S","Read-only memory","Self-replication","Server (computing)"],"journalVolume":"","journalPages":"166-179","pmid":"","year":2017,"outCitations":["40ef6e2d7046e7c8de60b4e82711ecfc97a0de8a","3d6e0b3d54b7f675ac12817f7cdd2da9c2134482","2cc40e5ca495af9a8e3aea5f357b59cc680c472e","69652a30c1badf6a4c21006f3ec8da3de976cbaf","3bf23f74bf33ed52f7c28587fab315610b27221a","5d999f4a5567e6f4a54e46bbcd6006f75ab0cbac","6885cd324017c499d44fa3c94fca23c3104e0aed","429dd28f609d97a883174d3a5a2db3cc936fb062","6acd75781396e5dedcf2f06a7131ba7f3153bfb5","03e53dddc865bf688fe313a94ad186a4d96bffe0","1a36150af44446fe9664005c447a0f0e04667065","0595bd8014c76b4d2b23e41154f193ec3ba64cc0","ba0043bd748bb26a1ba2a8297df6320d8df7489d","5119e4b11132d48d5fa4a5ddaf2ca1a0389b9b0f","0f8ae60e5e1bcf549017f10883428ef957148b00","7adc7940bc250bab39c7823fbb1ef3f86fe0625a","43bf4c7af676fcedc629c2563eb1e9708bbe0db2","29f766723ca752138855500084ced04503bfc9c8","1c110c1a5fdd87a99381b796c35f6d301244b4ae","1072d1f9eab9f69fab598f9d47ad323473b45ce3","35c348a3663de6387a45dc58b2c85092d247818a","16ba3e5c5e0084fef0fa4705d639f2ad164f2dbe","12fcade43d5d01977f712193fe242322dc57ba0e","ca57798e927b6ac4e77dc3be0522c53c31fdd6aa","a042f95a307d4f72d2aac95ac5d5e9dbfa24db79","110c050c6c992d2b956f7b47d717810ac5c91bdc","88412b002ee39eb121d93c0a2c11ddbb658e9d6b","c7ae87b4e5952560362e24274a3e9f4e78a666f6","cd8477fa225b6758f8e73ad1252d7556b11cbffe","78ef173529cae4a19c7718e88cc4107cff99ff0f","274e7e576534b3e091f09e801cce807f5fd221c1","5507d741031a1ce2ddc0d6fec9d497192f037eda","28552ecf4eaedb3461edca97304b29082b02fbab","3bec21f0f1954d31642537c02b33e280d7e12029","8bf5afa21a0bd74551b261a7399eac4ffe2494e5","b116227c9782509c1d5a667da3632deb4356727a","081dec43c2dbe76ff43c810594495f11ab092a10","53691325ee4a42e0b0cf3e9d463a0bc71f447c99","2253d6559ae9793b5cfa6e409d1d9de50dafa29a","bc4fbbaaf1ede8d8aff16a10243226419fc32cf8","047b0a5b50f996f3d9bcb51aab7f3176d12a69c3","8c97a156746cf0f9e8db4dde4e76169d589da449","352a8957005dc5519b15ed1870751ec494d66395","165528cdf9c76edd98729c142faf50fbd6cfc69e"],"s2Url":"https://semanticscholar.org/paper/5e6453019f2682df2e1ad7a07ffcc87517c4d7af","s2PdfUrl":"","id":"5e6453019f2682df2e1ad7a07ffcc87517c4d7af","authors":[{"name":"Po-An Tsai","ids":["30901893"]},{"name":"Nathan Beckmann","ids":["2576892"]},{"name":"Daniel Sánchez","ids":["39783437"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Last-level caches are increasingly distributed, consisting of many small banks. To perform well, most accesses must be served by banks near requesting cores. An attractive approach is to replicate read-only data so that a copy is available nearby. But replication introduces a delicate tradeoff between capacity and latency: too little replication forces cores to access faraway banks, while too much replication wastes cache space and causes excessive off-chip misses. Workloads vary widely in their desired amount of replication, demanding an adaptive approach. Prior adaptive replication techniques only replicate data in each tile's local bank, so they focus on selecting which data to replicate. Unfortunately, data that is not replicated still incurs a full network traversal, limiting the performance of these techniques.We argue that a better strategy is to let cores share replicas and that adaptive schemes should focus on selecting how much to replicate (i.e., how many replicas to have across the chip). This idea fully exploits the latency-capacity tradeoff, achieving qualitatively higher performance than prior adaptive replication techniques. It can be applied to many prior cache organizations, and we demonstrate it on two: Nexus-R extends R-NUCA, and Nexus-J extends Jigsaw. We evaluate Nexus on HPC and server workloads running on a 144-core chip, where it outperforms prior adaptive replication schemes and improves performance by up to 90% and by 23% on average across all workloads sensitive to replication.","inCitations":["6848f36de4d236cbe363a8eda86a039baa4eb50b"],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.42","http://people.csail.mit.edu/sanchez/papers/2017.nexus.pact.pdf","http://people.csail.mit.edu/poantsai/talks/2017.nexus.pact.slides.pdf","http://people.csail.mit.edu/poantsai/papers/2017.nexus.pact.pdf"],"title":"Nexus: A New Approach to Replication in Distributed Shared Caches","doi":"10.1109/PACT.2017.42","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.42","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Fairness measure"],"journalVolume":"","journalPages":"194-205","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/6473a95e6049b2d3759061d5211aa936c20b3f5a","s2PdfUrl":"","id":"6473a95e6049b2d3759061d5211aa936c20b3f5a","authors":[{"name":"Vicent Selfa","ids":["2896559"]},{"name":"Julio Sahuquillo","ids":["1813689"]},{"name":"Lieven Eeckhout","ids":["1717133"]},{"name":"Salvador Petit","ids":["5482726"]},{"name":"María Engracia Gómez","ids":["39569410"]}],"journalName":"","paperAbstract":"","inCitations":["a11e842fdf25256a2ded132db0af76b49fdf6e73"],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.19"],"title":"Application Clustering Policies to Address System Fairness with Intel's Cache Allocation Technology","doi":"10.1109/PACT.2017.19","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.19","venue":"PACT"},
{"entities":["Algorithm","Bit array","Central processing unit","Graph (abstract data type)","Graphics processing unit","Out of memory","Overhead (computing)","Rename (relational algebra)","Shared memory","TRAVERSE","Time complexity","Vertex (computer graphics)","Vertex (geometry)","X-Stream Network"],"journalVolume":"","journalPages":"233-245","pmid":"","year":2017,"outCitations":["015ecc71cf4efce11dda83942f84b8e27692a402","993e21ed73fc39048a42d06855bc85236ffd1063","191fd33f17c2a79b3825d4cc2105c47a8f16ba44","8db3c11cd85195f459b8ba82fe3326e8f86f1d52","1156f60e40548096df49528b1342bb3e88b0f378","175d795f44037ef60dd9df341701cd5fdc449f1f","ee065876c6605908724392b0e19307598d22a8f9","b513711621e81d0abd042e0877ca751581a993f5","6de3915df2b9927a78f213629f3bcb052ec21e8b","41c80483e80fab3a18280da790cec2c8d6060bdb","93ee8e1c05d11d63aa3d61653b2c8bae75e0aecd","0ad8e89091eed09217e66adc98136126addc2619","2a17c90ed723d6a14415cc1f677a5c0aa512f501","141e35263ab810983c90d47ad62eb4fab5e51717","21f35a5ecc0faf0c5f760e20cb9ce9e63a30a768","512a1ebdcaca56f3ea0c21aa2abe9a5ab7dace06","0706356c9ab6014d6b04577d38289ea8328291a5","7ebb9fad71ce8e08d5284b7644a5452cff6c75b3","2b9e6181502369199bd89691a27f89bdbaac36e4","bdbac20d53a08672c5b926ebcf84f54276b467a3","2ae3ac3f7463f838c38e6ca250ca294e813529f2","ce18973fb7c23cb4fc1c1a61c1c1c4333f4abad1","6a888f3dd0a17b0241be61daa378ba6caffa6617","3486aeaf540c48952120fe853d672af984f40a6a","1eb3992563b7b9fbf0c1da57d62f47220e6af5d5","586414efa54ba9f4a7def0dc5322b7723f22c552","46f3bb6751419b87856c4db0193e7a72ef3fa17c","24e8be45a2b2a30a01b7e9f1502e7bd6a7870e7a","11e4d4d00c7b1e3aa9fcf3c490b635df98827dd9","41880f9408bf4d826e4a715ee783e2d9d8666c2f","5b75c61e3183ea6228d08b2f6c00fd2cd74baada","3c84f22df1948dfa8b1b14bbd4c850baf9c5b632","75089ac937d66503cd8442d74bbaec1b578ed5ea","3bb6d5834bfb355553588e382ac5f9fa8a8d831d","410ae589668068dcc0a25b39763ff68684806433","a62ea31fbbdb5c4031ea929e82ea086122d7833c","2209304ccc2b0501debd5e9a90ae739f9a30cdef","095abbc06375f5790967c174ef58f8e677d1a21b","3d985a05e4a49be71d497e7a2ff3fcbeb74c4bc8","217beeb53274ba6972d660afff1841e890f3721e","52a4130c74ad95664fbc067ef91fd75b748ac409","080f44d89bf6f4404f476ffec8d2f8ad3f60e07d"],"s2Url":"https://semanticscholar.org/paper/f4e42c15a7a35a198a04a74cbdbe19d360a2d00c","s2PdfUrl":"","id":"f4e42c15a7a35a198a04a74cbdbe19d360a2d00c","authors":[{"name":"Wei Han","ids":["38872388"]},{"name":"Daniel Mawhirter","ids":["27998850"]},{"name":"Bo Wu","ids":["22401706"]},{"name":"Matthew Buland","ids":["28028789"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Most GPU-based graph systems cannot handle large-scale graphs that do not fit in the GPU memory. The ever-increasing graph size demands a scale-up graph system, which can run on a single GPU with optimized memory access efficiency and well-controlled data transfer overhead. However, existing systems either incur redundant data transfers or fail to use shared memory. In this paper we present Graphie, a systemto efficiently traverse large-scale graphs on a single GPU. Graphie stores the vertex attribute data in the GPU memory and streams edge data asynchronously to the GPU for processing. Graphie's high performance relies on two renaming algorithms. The first algorithm renames the vertices so that the source vertices can be easily loaded to the shared memory to reduce global memory accesses. The second algorithm inserts virtual vertices into the vertex set to rename real vertices, which enables the use of a small boolean array to track active partitions. The boolean array also resides in shared memory and can be updated in constant time. The renaming algorithms do not introduce any extra overhead in the GPU memory or graph storage on disk. Graphie's runtime overlaps data transfer with kernel execution and reuses transferred data in the GPU memory. The evaluation of Graphie on 7 real-world graphs with up to 1.8 billion edgesdemonstrates substantial speedups over X-Stream, a state-of-theart edge-centric graph processing framework on the CPU, and GraphReduce, an out-of-memory graph processing systems on GPUs.","inCitations":["1f0572f47be66c2c0fbf3fd0f98f25e5b5f88361"],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.41"],"title":"Graphie: Large-Scale Asynchronous Graph Traversals on Just a GPU","doi":"10.1109/PACT.2017.41","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.41","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Dynamic dispatch","Lavasoft Ad-Aware","Multithreading (computer architecture)","Out-of-order execution","Parallel computing","Speculative execution","Speculative multithreading","Speedup","Thread (computing)","Transactional memory"],"journalVolume":"","journalPages":"64-78","pmid":"","year":2017,"outCitations":["1d9889486e2e4e553e73f7154bb73bcb3e2024c8","2933635dc761e1a343a8b7bed8045a0a7884ce7c","3d50c803cc715e51d263f5a42b06858be9466c0f","4fb0a129c06bd8752f965b27a19ea3255e4b771f","12f2cfcbb56718a967ca37bafb1ec014bb17d3e0","35d357020f53e6aba43fe5c8a42c07ad87be745f","3d68e6c36e36f47c74368c917436b249218177b7","43c36c242f0f7e1095227da0a04bb766d91fde04","b575c072dcde1d7c627e6108da5814696fff9bfb","44dce8469bc082356b71f49e7e05c6d8954af72c","06570f434bb3d5d822d43bddbadd41d187878c02","4aa993db77b888a02084a542a929b1a81a8d03f6","1487996e2cd07b15dd42791cd5f567246f8b83e6","29f766723ca752138855500084ced04503bfc9c8","0c8fef219adbbd4eeae3498428fb6a334bc62a67","0653e2ed9f683868cb4539eb8718551242834f6b","09ed565e84057123c15ab12b885c235d1f241aed","13e5cbd3303db47e422469dca09bb59bffe2eafe","145763b88b9a3bc332180e9628a2642c99b2aac6","6bd6a0cc1a4bf62784d8573ca1aeafe2673dcc02","0948c0acfb779e551e5c2420081eab206f57f396","49137d43a3c23d8f5aa3885813ae76a72ca763a5","2b0cf3614e919ef3fb623ac9382caa444ec44fb0","89c5340c85f56dc7192ea4f0a7ac8fce792cbdb9","25855e37885c85803b2a015a2b8b5eaa7d1f5326","e0857c644b1059323d15ef9d45ffe86f4f3b6a09","32aa6bc4a8a014b65135e4d82f103f1d0017d578","35c89b2ad35ff57c7006a65a84d05df1f00affbe","5557b730f22e3e90272d477ecfa82013649086c8","b5e9865f09f61f987f4e55b8bc07334d3972de84","17ad1361dfabc1c50b506813d0f5d54df159fc36","4805282c0f03457e297ab4cea11044a4a81316cc","044cafde686e811d1a6aa19a93fe97d0e4d8ab51","1b9e9bfdc66140d2eb192e4ac8aca9281f0239b8","1ef7f02bce931c8e9ef529e095b274132ce4011a","1eeb50d5f7937f65a910203ae61430ff8b969012","34a97a016e6c419eb4b1005a7306d45a775a407b","7c17663c48a367fdabd0600c1cca6a3d0c711788","5a1a774e3a4563fde667fbaa35adaff9a41014db","a10fde829f83a5e5c101de85dd78e330c9c33d1b","22f02a69bbcafa7bfbe7824ec30f29aa23ab303a","14b1e403f0ab89b61e3e5431283f5aa764e301b7","ae96e0563298c23b777be98d110bc86963b896c0","57cf29529977cc5407497aba2f9032e01a12c1a9","a01d4a0f26ec9bba3e21f12f60489a6a20a8ae17","d8777ef17c18609781aa889055100603b13b2986","770fdb91c74005c8b34a744c6b2188729b2a9c63","57f0570911626318a13a69a378dd96feb011eedf","106cfdc91f33ed647e8ca97e9d7ce495fa79dae3","48f044ba3e7524413468d90a687c2a9ca3f2847c","16ba3e5c5e0084fef0fa4705d639f2ad164f2dbe","2c1ea92d6a4237ede5ea112f1880710b25bec8b3","429e313d33a82bf086b69d47eee735450cbeb4ae","01d32e62828315a140a5db4010431cac3d6868c6","50b84e2e1d1289ac6e3fae14f292d274f6db27e1","6e78c1b830ff611d82ae00d75b3c6592e000a91f","6f090d59bde17b7604985acf38e26785e794bcc0","0b6feaae9d2d2f3bc8e487a8228d712a68fea14d","2b585692b2337286e88095c2341af4d8121e80b8","323292fad95a1bce506e100ac8d622019a2012d2","13e6aa5f61267b2814fa9b32f47c17c0fcdef2d5","40cb40b7812e019c1051e3a457a8643400b81d51","28552ecf4eaedb3461edca97304b29082b02fbab","3bf23f74bf33ed52f7c28587fab315610b27221a","540892abd51e931839dbe15b4d55ab108b5a7f71","b1d14e2b28759afd361d50e14744224b654e205e","2e33c9a0e0ba542693610f36cabee4d8291f8e09","023ba3dff9e17a15ae8448ec6cacc3e9a5ff116a","44695679d7619ec3526627c9f93e388f1d24f3b6","d67f67e2a8d2caf5ff04f315c21611571f7779c6","94c20561f102ede79c461c6aeee74eb7a55d5eb4","abf1157c2043274a8d580151db1d4ef5be2c892e","51225f24b4bfb922bc9ed9738566de0b3cae5393","03fc198adf79731c92070b8aa839c46ebf9b3c14","a16d51087e5505b296e2b15a4b5b6fddff194ebf","28cc7453c5f3f9ecb9415e631b0829ec9af8a4c3","4bad51c7685254155733ee8def6a1294378aa1af","fd9dc505e3cf0b6a828ae67f1850658540ec9179","a16ae7a7367391f7baeb5085655c329af12683ce","5ff71859d9602c9a3d1332fa47ce01a5ec81db72","200609035711763e162096cc010cc3e00895c6c6","0335bf6957ecb92f709fc79c72c4237939f32c9e","ab12cef09635b578d1c6479a2a693de8a75be2c7","13f6ddd72bcf62dcc13cf4515be29d48948b9693"],"s2Url":"https://semanticscholar.org/paper/2ccf4fcca56f7d14579eab46c529fcdf06365cfc","s2PdfUrl":"","id":"2ccf4fcca56f7d14579eab46c529fcdf06365cfc","authors":[{"name":"Maleen Abeydeera","ids":["3273348"]},{"name":"Suvinay Subramanian","ids":["1929462"]},{"name":"Mark C. Jeffrey","ids":["2573160"]},{"name":"Joel S. Emer","ids":["1775477"]},{"name":"Daniel Sánchez","ids":["39783437"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"This work studies the interplay between multithreaded cores and speculative parallelism (e.g., transactional memory or thread-level speculation). These techniques are often used together, yet they have been developed independently. This disconnect causes major performance pathologies: increasing the number of threads per core adds conflicts and wasted work, and puts pressure on speculative execution resources. These pathologies often squander the benefits of multithreading.We present speculation-aware multithreading (SAM), a simple policy that addresses these pathologies. By coordinating instruction dispatch and conflict resolution priorities, SAM focuses execution resources on work that is more likely to commit, avoiding aborts and using speculation resources more efficiently.We design SAM variants for in-order and out-of-order cores. SAM is cheap to implement and makes multithreaded cores much more beneficial on speculative parallel programs. We evaluate SAM on systems with up to 64 SMT cores. With SAM, 8-threaded cores outperform single-threaded cores by 2.33x on average, while a speculation-oblivious policy yields a 1.85x speedup. SAM also reduces wasted work by 52%.","inCitations":[],"pdfUrls":["http://people.csail.mit.edu/sanchez/papers/2017.sam.pact.pdf","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.37","https://people.csail.mit.edu/mcj/talks/2017.sam.slides.pact.pdf","http://people.csail.mit.edu/emer/papers/2017.09.pact.sam.pdf"],"title":"SAM: Optimizing Multithreaded Cores for Speculative Parallelism","doi":"10.1109/PACT.2017.37","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.37","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Automatic parallelization","Computational science","Just-in-time compilation","Linear algebra","Open-source software","Parallel computing","Partial evaluation","Programmer","Scripting language","Speculative execution","Speedup"],"journalVolume":"","journalPages":"356-369","pmid":"","year":2017,"outCitations":["22e775c629ad9d1e1cf6842eae60c5b9b96ce309","6074c1108997e0c1f97dc3c199323a162ffe978d","304fe263b042cedd3309422292e487f59cf39ffa","a22080f1a7f54317b24d4176b8810446665dd8d1","183298f38c2a16c4534db3de7c6e5c320b861b75","da1df0946c1a0b2be7a265e9158c441c028715ad","41d290943f39d23949f88a2ca52f1ebfc62a7090","6a2814c9876ca97c99d9edcb204475dfd0bbc2bc","9d9d7bc940e17a11bf4738deb3bdff6d5aef2ee2","73538f17cbeb45fd0822cb971375ad03c515dbe7","b7efe971a34a0f2482e0b2520ffb31062dcdde62","20b2421005a95fe747a3f186ada61525a361bfaa","a23e6569cafc467cde325c59f69f0d5f3838fce1","0d4889a452a9948944f628c3b8147ab2cb9e70f9","f0f4757aa2f923a349e8357e73850a78e9b80fee","08c10397976e566fb27d984e42a44a75c350d0da","40cb40b7812e019c1051e3a457a8643400b81d51","0425f1e7e8651b5ba3c9e2eb98a3c50a07146972","808b90dadea6426924374633c8c49f78175f04a8","a19a7c5e45125a570dcbac018184669b8cab2789","09ed565e84057123c15ab12b885c235d1f241aed","619fe8f80908a6001c96b606c39137d4ad48802c","d1c2ecf0fea4c430633389553f40189d0a23b3a0","11e947e6509ecd98c905b44747b3978ac06c2900","09cc66777e889e7ba26c5e8265cf4f62e841fd9d","131ca2d600bc720343c1a735729a9b4521aed2d2","0d281938d3ff2377541704cab6ba1c4408420733","4c41353ff2b2acc45a0fd3b35c841f442d11591e","4c372083685ab8b8cfc6ff984310c6d078580897","6662ad36d052739f19a40a230e9e8afc26d88bc2","35c89b2ad35ff57c7006a65a84d05df1f00affbe","0856f6f40b889dba559f19654834114e9f469760","93bb36b2fa886a808919a93ad13092790a4cca8f","d67f67e2a8d2caf5ff04f315c21611571f7779c6","5231091fd9fe75115bedf967fa8ed95810ae6ae3","2b5d290bc646fb86ed31340c32017f83ffcb5d33","58b00f733f75f0dd4fa5236263b5e1a64c5161d7","16a74ec035f5cb660e839abf1ac076bea6469989","5c6c460e58b72651a60d880c42d7e14b5daf206c","2e88cb3f95da0342be347ac3903d50a9c5c95cf3","448f4144a1d818754d91d0821ece830501ae6f9f","6a2edd2c10e6daaea7ffdc4b0a58f8ad9527ca49","159437777bba0139a6b4d6bde460b9201d284500","280f49d0bbcc23780d6452f0aae6851f61b012bf","2804ca11158d8d5a85d6e4dfd7b226dc1f203403","5d00483952d303b9cfd9b9acfc8fd1173d5058c6","c85f605689fff6599d55f6f057264b2eb068ea5a","2194c3460ab71f3826db00b045b2ae590c753319","0560fc4924bbbe7e920122dc25c1ecfc3e59e374","28461538e59946bdb9c629629f1afdbfd7afb5aa","08a3b7e1aef12dbd2500e65946b98d57b400dbf0","72682890677496da1a98f2d4ce9396ad13997e07"],"s2Url":"https://semanticscholar.org/paper/000f18a98b1a305d5ff07972b2a63849f9b26908","s2PdfUrl":"","id":"000f18a98b1a305d5ff07972b2a63849f9b26908","authors":[{"name":"Taewook Oh","ids":["2519125"]},{"name":"Stephen R. Beard","ids":["1888818"]},{"name":"Nick P. Johnson","ids":["2744545"]},{"name":"Sergiy Popovych","ids":["1840375"]},{"name":"David I. August","ids":["1722513"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Computational scientists are typically not expert programmers, and thus work in easy to use dynamic languages. However, they have very high performance requirements, due to their large datasets and experimental setups. Thus, the performance required for computational science must be extracted from dynamic languages in a manner that is transparent to the programmer. Current approaches to optimize and parallelize dynamic languages, such as just-in-time compilation and highly optimized interpreters, require a huge amount of implementation effort and are typically only effective for a single language. However, scientists in different fields use different languages, depending upon their needs.This paper presents techniques to enable automatic extraction of parallelism within scripts that are universally applicable across multiple different dynamic scripting languages. The key insight is that combining a script with its interpreter, through program specialization techniques, will embed any parallelism within the script into the combined program that can then be extracted via automatic parallelization techniques. Additionally, this paper presents several enhancements to existing speculative automatic parallelization techniques to handle the dependence patterns created by the specialization process. A prototype of the proposed technique, called Partial Evaluation with Parallelization (PEP), is evaluated against two open-source script interpreters with 6 input linear algebra kernel scripts each. The resulting geomean speedup of 5.10&#x00D7; on a 24-core machine shows the potential of the generalized approach in automatic extraction of parallelism in dynamic scripting languages.","inCitations":["a075f3a381ee3856fda63b006e8f841d003fb354","305826910778ccbb0c39d830e90913a1fcef6c57"],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.28","http://liberty.princeton.edu/Publications/pact17_pep.pdf"],"title":"A Generalized Framework for Automatic Scripting Language Parallelization","doi":"10.1109/PACT.2017.28","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.28","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Branch predictor","HTML","Programmer","Side effect (computer science)","Transactional memory"],"journalVolume":"","journalPages":"79-90","pmid":"","year":2017,"outCitations":["1d9889486e2e4e553e73f7154bb73bcb3e2024c8","0fca03c476d869660dec04fb83f54161767a4ba7","0fc3098d4413dd75ef750c8dddf6cbe87ea9d8d7","1e5343aedb2117e9a211f471edd553af45e450f7","e02ec8cd92c8e687b9e343868b07e0898302c72f","51e8b3cfca99f4477f7267ea633adb72a442288a","9cf4ca5d05db678f40b09d044203ab940fc62bb5","7b1a8647dd6482adee6b774d694e5c85b6d5a9cf","2f7ae6b41a97bf7dc705b4a4bd42ec37a8dc1d87","14d5de21fd760893f9195e257b5f7e01919733e1","1ef7f02bce931c8e9ef529e095b274132ce4011a","3e77a77247734dc918a5723573e1158eee1955f9","1e365e63d5001819f11eb14e84057e8b85b4b138","46e61ad29ab20618fb551afbc00ebb8eb4e9be21","36165d72079a03f10e420dbca85e661e8b811534","2ae2684f120dab4c319e30d33b33e7adf384810a","222fafc8afce5219bd3e40c6784b6f3502e42c32","3db65842289ba31794d504ba11ddcb8f4440f241","3370784dacf9df1e54384190dad40b817520ba3a","3150e68dccebd9d8e371143270f6bc3942b7d69c","339a15240ff850110e211bb141e282a4626e7b91","ab12cef09635b578d1c6479a2a693de8a75be2c7","023ba3dff9e17a15ae8448ec6cacc3e9a5ff116a","3150af98e61952c09f70e53a3f84911291d8f440","18084bc614fec70d920a899d39cdb32255007863","faa97a8689d9204d4ca11e9c1188414bd0bd4bbe","206d4ebdf93ae6c9b530efc94fa408ccca2b402f","056aea9d5e4961533ea849f05478856a09fb367d","40cb40b7812e019c1051e3a457a8643400b81d51","22839816fbd337d77b81a7f3c6430324e057c250","5798c7f1114d8db20627a8aa994ae77e005eb623"],"s2Url":"https://semanticscholar.org/paper/0866accf3169ba838b77fbe8600ab0a0146e89d9","s2PdfUrl":"","id":"0866accf3169ba838b77fbe8600ab0a0146e89d9","authors":[{"name":"Joseph Izraelevitz","ids":["2071127"]},{"name":"Lingxiang Xiang","ids":["2794865"]},{"name":"Michael L. Scott","ids":["19882154"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Several research groups have noted that hardware transactional memory (HTM), even in the case of aborts, can have the side effect of warming up the branch predictor and caches, thereby accelerating subsequent execution. We propose to employ this side effect deliberately, in cases where execution must wait for action in another thread. In doing so, we allow &#x0022;warm-up&#x0022; transactions to observe inconsistent state. We must therefore ensure that they never accidentally commit. To that end, we propose that the hardware allow the program to specify, at the start of a transaction, that it should in all cases abort, even if it (accidentally) executes a commit instruction. We discuss several scenarios in which always-abort HTM (AAHTM) can be useful, and present lock and barrier implementations that employ it. We demonstrate the value of these implementations on several real-world applications, obtaining performance improvements of up to 2.5x with almost no programmer effort.","inCitations":[],"pdfUrls":["http://www.cs.rochester.edu/u/jhi1/papers/2017-transact-aahtm.pdf","http://ftp.cs.rochester.edu/u/jhi1/papers/2017-transact-aahtm.pdf","http://cs.rochester.edu/u/jhi1/papers/2017-transact-aahtm-slides","http://ftp.cs.rochester.edu/u/jhi1/papers/2017-pact-aahtm-slides","http://cs.rochester.edu/u/jhi1/papers/2017-transact-aahtm.pdf","http://ftp.cs.rochester.edu/u/jhi1/papers/2017-pact-aahtm.pdf","http://www.cs.rochester.edu/u/jhi1/papers/2017-transact-aahtm-slides","http://ftp.cs.rochester.edu/u/scott/papers/2017_TRANSACT_AAHTM.pdf","http://cs.rochester.edu/u/scott/papers/2017_TRANSACT_AAHTM.pdf","http://ftp.cs.rochester.edu/u/jhi1/papers/2017-transact-aahtm-slides","http://transact2017.cse.lehigh.edu/izraelevitz.pdf","http://www.cs.rochester.edu/u/scott/papers/2017_TRANSACT_AAHTM.pdf","http://cs.rochester.edu/u/scott/papers/2017_PACT_AAHTM.pdf","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.16"],"title":"Performance Improvement via Always-Abort HTM","doi":"10.1109/PACT.2017.16","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.16","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":[],"journalVolume":"","journalPages":"14-26","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/1bdc70a32c03b4455277639d4f79dd5ecac2de34","s2PdfUrl":"","id":"1bdc70a32c03b4455277639d4f79dd5ecac2de34","authors":[{"name":"Louis Jenkins","ids":["6916919"]},{"name":"Tingzhe Zhou","ids":["2390252"]},{"name":"Michael F. Spear","ids":["1687335"]}],"journalName":"","paperAbstract":"","inCitations":[],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.45"],"title":"Redesigning Go's Built-In Map to Support Concurrent Operations","doi":"10.1109/PACT.2017.45","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.45","venue":"PACT"},
{"entities":["Algorithm","Computation","Data structure","General-purpose computing on graphics processing units","Graphics","Graphics processing unit","Skip list"],"journalVolume":"","journalPages":"246-259","pmid":"","year":2017,"outCitations":["0c25ac1fb86259bc91e22b51bdaa56ce1dbc50c5","762f5a712f4d6994ead089fcc0c5db98479a2008","4291f71707a8ac18d5bf72c2b2c52e16c208e0ba","22a3110123362412f91ae44c2b15e2234324f6fd","00dd1306de5e28a6cb766f409779c784db11c58d","4c77e5650e2328390995f3219ec44a4efd803b84","78e47b768c784fcb15004bab48e24f80fdad579e","6479c756e597c38e57aa45e2eae8550fd738418b","5b975248796c2ee3f65b2f4430fd3be4d7e6191e","8085460933105498577e741a02185c0097e36711","2916fd514c69c1b3141c377c1c97d957bdc86c5e","63bc7beec90c98b54add6b8d5767c10e36caa667","4ccb2d0f62dfd174f2fe9551a4d2a32c2424c618","3168cc1e8951c2652b7878748e77228dbf4090cb","d410f8128bd4efa6adc886259e5d9de4cd7587bc","3c9b5b9e3e8ad647498f1650df08ac2a4fa83346","fa15e80d71f831ed1a3f11d5b94c88b8f098a17c","a4d431fd93d941abb8797d2a8e7333606504c7fb","942f2a6df29234c304b69129872835d60cf5e9e9","217d408f60f749aab6705ff3056b8e77640f2948","b1fc033792679dc0e12ddce2aa2e4869a33ba2c2","1ae7993c0c2d795b243354de48dab80bf2000356","5d153a55b6f12752afc11bb96d9d72a51c990dba","6710769f8fb90d6fe30dc8e27183f19a6cb31faa","b1cbfd6c1e7f8a77e6c1e6db6cd0625e3bd785ef","3a5a237a114d70291b9611675cc97ba2bf20aa87","a877b04a01146eae9c6c7ab27e9dda97fbee7d89","04f020a4ab2134db6f9e98eadf216d94d440414a","072cad08a6886c1800cb6144a8cfec4bced6f7d9","54a882bc5f15877097dfb1aab8c480323036e48c","0a5033c0b2bb2421f8c46e196fb0fb1464a636b6","295521cfe1a56458d53a58613de5fb92c97c5c23","2724de31317b1b9e026b5f90251829ee02f3fa3f","24f641c3987721be01f2c484198608b4c53f0208","05e4baf190150bd9ef6516ee777c003431ec57dc"],"s2Url":"https://semanticscholar.org/paper/ef61748705e2728501a122ad779673a8bebae79a","s2PdfUrl":"","id":"ef61748705e2728501a122ad779673a8bebae79a","authors":[{"name":"Nurit Moscovici","ids":["9560905"]},{"name":"Nachshon Cohen","ids":["2898845"]},{"name":"Erez Petrank","ids":["2210090"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"We propose a design for a fine-grained lock-based skiplist optimized for Graphics Processing Units (GPUs). While GPUs are often used to accelerate streaming parallel computations, it remains a significant challenge to efficiently offload concurrent computations with more complicated data-irregular access and fine-grained synchronization. Natural building blocks for such computations would be concurrent data structures, such as skiplists, which are widely used in general purpose computations. Our design utilizes array-based nodes which are accessed and updated by warp-cooperative functions, thus taking advantage of the fact that GPUs are most efficient when memory accesses are coalesced and execution divergence is minimized. The proposed design has been implemented, and measurements demonstrate improved performance of up to 11.6x over skiplist designs for the GPU existing today.","inCitations":["c447884ff203380eea57c9072b36db5323b2c28e","69485516475fcd6e78692ae3b952888c7d1443df"],"pdfUrls":["http://www.cs.technion.ac.il/~erez/Papers/GPUSkiplist.pdf","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.13","http://www.cs.technion.ac.il/RESEARCH_DAY_17/POSTERS/nurit_moscovici.pdf"],"title":"A GPU-Friendly Skiplist Algorithm","doi":"10.1109/PACT.2017.13","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.13","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["ARM architecture","AVX-512","Advanced Vector Extensions","Binary translation","Parallel computing","Performance per watt","Register allocation","SIMD","Superword Level Parallelism","X86"],"journalVolume":"","journalPages":"343-355","pmid":"","year":2017,"outCitations":["8705177ae97c80d29d6c976efc7624edc69112ea","0a5033c0b2bb2421f8c46e196fb0fb1464a636b6","10bd3ed1e85e59956382c8634f13088be058e93c","0ac6b674dbd4c3f552ee8b2b79a4179ee330b785","0a65844b2e318305c7031eb53cb306efe7763d22","2194c3460ab71f3826db00b045b2ae590c753319","0e65407ea4bea5f92860752c3056a82b7ed58cd1","4aebded56ed41b8cfdeac42f25dc6437155bd5e7","3ad8e1308849167d96355b9b1906994eb92283a3","46dd6b8867a08bf8796963c937ccd3b09744f38e","15bccb4ffd4f2f44fa0fae5cdbe85afc362855f6","5afe81cf448c928d23fc0cf9e385c3febe92fda0","0653e2ed9f683868cb4539eb8718551242834f6b","2c0d13841a1c0b94ca7730a5bcbe443bd780c151","2960c89331eb7afa86584792e2e11dbf6a125820","6d12aea56165acf3715e2c82b5f560e48359366d","09dbf94357b21ad14d2897282703ee99ae06a35e","5eea7073acfa8b946204ff681aca192571a1d6c2","6430084d77aaddbc692612b42654e73040b93a7b","0cfd44531f917a1819346fc053e8f8662e3635bf","58f1d8e4c3588fd4bb7d58276ef14bafa603aaa9","0fd1f536dff3991738cfacb1acedf1a8e695cc9e","5af4d8a14510af9ffa9832d7a4bb9a07b99f7ebb","2549f9b455f75ebaaa3736208e319847140b705e","039449e900b28ae63ef515063e59642fe501aed7","06c0f336042ac299430728be10dd63bd57680081","6b135a7d4fb3e2d205956c2f60ffd2695c2363c7","984d45494026f7a2fc9c4193ee65b5ef35d937ad","35e843d7d4b35d640e274b123b78ffeb919a4638","b6d4a02cc699f081821ee4b84765e56c716953ce","48b22e82dba733f04a5af3408ecab872ba38f0c3","49c04aea5a4038c911e3e0733371940b9bc7e74c","88b42246806890ea88d2d64621c2ac828541be90","64285179b8bdf7861aef8719a4aa49704aa16912","a5ff2ef2177a466b8b9c8dec93d6b2d60d7a17a4","60d607c26019503cc6521b45aed3bff2044c2cf8","0856f6f40b889dba559f19654834114e9f469760","d72023b94bd41915d163e13f3be7bc386280de29","497e498e6031de6ebb567ffde85243237e91a387"],"s2Url":"https://semanticscholar.org/paper/14ea23fe5d2ed2bc7d93e9f3e60e5d18ca209568","s2PdfUrl":"","id":"14ea23fe5d2ed2bc7d93e9f3e60e5d18ca209568","authors":[{"name":"Yu-Ping Liu","ids":["3164813"]},{"name":"Ding-Yong Hong","ids":["1685169"]},{"name":"Jan-Jan Wu","ids":["1726584"]},{"name":"Sheng-Yu Fu","ids":["2584163"]},{"name":"Wei-Chung Hsu","ids":["1741913"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Processor manufacturers have adopted SIMD for decades because of its superior performance and power efficiency. The configurations of SIMD registers (i.e., the number and width) have evolved and diverged rapidly through various ISA extensions on different architectures. However, migrating legacy or proprietary applications optimized for one guest ISA to another host ISA that has fewer but longer SIMD registers through binary translation raises the issues of asymmetric SIMD register configurations. To date, these issues have been overlooked. As a result, only a small fraction of the potential performance gain is realized due to underutilization of the host's SIMD parallelism and register capacity.In this paper, we present a novel dynamic binary translation technique called spill-aware SLP (saSLP), which combines short ARMv8 NEON instructions and registers in the guest binary loops to fully utilize the x86 AVX host's parallelism as well as minimize register spilling. Our experiment results show that saSLP improves the performance by 1.6X (2.3X) across a number of benchmarks, and reduces spilling by 97% (99%) for ARMv8 NEON to x86 AVX2 (AVX-512) translation.","inCitations":[],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.15"],"title":"Exploiting Asymmetric SIMD Register Configurations in ARM-to-x86 Dynamic Binary Translation","doi":"10.1109/PACT.2017.15","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.15","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Benchmark (computing)","Data (computing)","Edge detection","Graph (abstract data type)","Graphics processing unit","High- and low-level","Load balancing (computing)","Multigraph","Sparse matrix","Two-phase commit protocol"],"journalVolume":"","journalPages":"27-40","pmid":"","year":2017,"outCitations":["586414efa54ba9f4a7def0dc5322b7723f22c552","175d795f44037ef60dd9df341701cd5fdc449f1f","2b9e6181502369199bd89691a27f89bdbaac36e4","3ebf3857a60c3e224284bbbe6c7127d0a12c546d","191fd33f17c2a79b3825d4cc2105c47a8f16ba44","00b8d047cad54ac03ac5d1d919a5d4a09ea4bbbb","3c84f22df1948dfa8b1b14bbd4c850baf9c5b632","3c2cc49ee044d3b5815e9d5ad9c6010e94484d92","2916fd514c69c1b3141c377c1c97d957bdc86c5e","94c20561f102ede79c461c6aeee74eb7a55d5eb4","1156f60e40548096df49528b1342bb3e88b0f378","0f34ea8535dc5833a1a3692ffc7abc6740d2406a","d6c4c76076efecb15655274adc648af8a445ed3a","0074e55e67c74420b725fbb09a8f2f351d6947a9","123b7a6282243af8a81f693f0cd9ac6263946dbe","c4f83b436c164005bde22f6997de18c3fc1cb725","512a1ebdcaca56f3ea0c21aa2abe9a5ab7dace06","2724de31317b1b9e026b5f90251829ee02f3fa3f","46f3bb6751419b87856c4db0193e7a72ef3fa17c","c3008dd707e4dfd43606a544d4cac4bf1f081f2b","3dff11679346f5344af1018cad57fa14cc349f2f"],"s2Url":"https://semanticscholar.org/paper/79d68db415c56f5641cd645173f7d3f0b5307035","s2PdfUrl":"","id":"79d68db415c56f5641cd645173f7d3f0b5307035","authors":[{"name":"Changwan Hong","ids":["39173720"]},{"name":"Aravind Sukumaran-Rajam","ids":["2342667"]},{"name":"Jinsung Kim","ids":["3099014"]},{"name":"P. Sadayappan","ids":["1750948"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"High-level GPU graph processing frameworks are an attractive alternative for achieving both high productivity and high performance. Hence, several high-level frameworks for graph processing on GPUs have been developed. In this paper, we develop an approach to graph processing on GPUs that seeks to overcome some of the performance limitations of existing frameworks. It uses multiple data representation and execution strategies for dense versus sparse vertex frontiers, dependent on the fraction of active graph vertices. A two-phase edge processing approach trades off extra data movement for improved load balancing across GPU threads, by using a 2D blocked representation for edge data. Experimental results demonstrate performance improvement over current state-of-the-art GPU graph processing frameworks for many benchmark programs and data sets.","inCitations":[],"pdfUrls":["http://doi.ieeecomputersociety.org/10.1109/PACT.2017.48"],"title":"MultiGraph: Efficient Graph Processing on GPUs","doi":"10.1109/PACT.2017.48","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.48","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Branch predictor","Central processing unit","Dynamic voltage scaling","Manycore processor","Moore's law","Multi-core processor","Spatial variability","String metric","Transistor"],"journalVolume":"","journalPages":"180-193","pmid":"","year":2017,"outCitations":["7bb72a9437a1ddb7e0eced6f243b8f9e66438f28","17d72a792b35fa9e65499b3e8f9c15a1f6f8b7b6","08237b5a7862d65185977e3dac0f81e616188add","2dc59e60b34b3863e4eb381b17384105fe523cec","43260df86b2aaa20824d73eff48e0b49162689cb","06125169a21ef17641d7199544417b21c378eede","313b6d6a2fe071869507ba7530aef10c91aefe11","2ab1b98b642e341006d18ebce41359e95373422f","057ecc6780a2b2cb533884167962654451e4960b","294273a4a63a4d06d3dbd2880598a9cd64b3087f","25e0dcb0e7b3446fbf16c48e9a6a4ad36f645f3b","bfd1b422fa359ed49811e6b49fd9cdc443d07c22","4a58e3066f12bb86d7aef2776e9d8a2a4e4daf3e","8b10b13fb495101d1e4eb768907cff05e3bd9315","0717371b254df3e466a11d1965c2c9541a43b7a3","a169ca8993abcfa03eb22c50a4227983d740b31a","8671317d25f917af263b457612f959823d5c86b1","7779c10dfa1f84953016b6292844815c5faf84f5","2790284b6a16790d03b0cb5ed46bc6b0fecde1eb","77d4fb23ce0b5499016f2c162a5430d04f976542","12ecd8079ae103ccdf9c8b5a5fb2e2844b7a25da","1728de7b027e827dfc67ceb3b0e23b841a4b1538","792aa5a81ac1d344de450ec59eec339aa0e508aa","55043afbb87e38627778a323dfdc35a55357e47d","6d5099039729d930841c21893c5585a194d90a79","3c02593a7f5ea8a22583c507c20a65c0244d385e","4408b7049f9241920ff8dcb5ad387e5358a75694","f29dac2e26273532c81c933f091c7a60b9480f94"],"s2Url":"https://semanticscholar.org/paper/16d0de1e3d3c8e6020a0a3bd3accabfd6a937497","s2PdfUrl":"","id":"16d0de1e3d3c8e6020a0a3bd3accabfd6a937497","authors":[{"name":"Priyank Faldu","ids":["27802227"]},{"name":"Boris Grot","ids":["2309941"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"The looming breakdown of Moore's Law and the end of voltage scaling are ushering a new era where neither transistors nor the energy to operate them is free. This calls for a new regime in computer systems, one in which every transistor counts. Caches are essential for processor performance and represent the bulk of modern processor's transistor budget. To get more performance out of the cache hierarchy, future processors will rely on effective cache management policies.This paper identifies variability in generational behavior of cache blocks as a key challenge for cache management policies that aim to identify dead blocks as early and as accurately as possible to maximize cache efficiency. We show that existing management policies are limited by the metrics they use to identify dead blocks, leading to low coverage and/or low accuracy in the face of variability. In response, we introduce a new metric &#x2013; Live Distance &#x2013; that uses the stack distance to learn the temporal reuse characteristics of cache blocks, thus enabling a dead block predictor that is robust to variability in generational behavior. Based on the reuse characteristics of an application's cache blocks, our predictor &#x2013; Leeway &#x2013; classifies application's behavior as streaming-oriented or reuse-oriented and dynamically selects an appropriate cache management policy. By leveraging live distance for LLC management, Leeway outperforms state-of-the-art approaches on single- and multi-core SPEC and manycore CloudSuite workloads.","inCitations":[],"pdfUrls":["http://www.research.ed.ac.uk/portal/files/40016712/LEEWAY_PACT17_1.pdf","http://homepages.inf.ed.ac.uk/bgrot/pubs/LEEWAY_PACT17.pdf","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.32"],"title":"Leeway: Addressing Variability in Dead-Block Prediction for Last-Level Caches","doi":"10.1109/PACT.2017.32","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.32","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Cache (computing)","Cache coherence","Central processing unit","Circular definition","Memory coherence","Memory model (programming)","Open-source software","Operational definition","Out-of-order execution","RISC-V","Time Sharing Option"],"journalVolume":"","journalPages":"288-302","pmid":"","year":2017,"outCitations":["69e6fb41751ebf0a6b99522a2fabcd3879e8cf2b","17e4e843676868b7dd5dcacea945141d7a8e17ee","0ed62848d5c9e01f692c0c0b3851848ac7bb0764","d4c5e14e27b45266532c74f6aa0d51a1a4280e7c","62bd72d7a4160bd1a35191c51137d11cfbe30cf7","05a518c3b1a6f5c15d77f8829368677a263ff15d","33dcafd805a3b44fd64270028633032ff0bb6fac","4bb640b092cbbf55ed4d1de8edb79ba8a79b0ebd","3082d9ff0a7356b7414a5c6f0521e43dbcb9b2f8","180189c3e8b0f783a8df6a1887a94a5e3f82148b","9b117e3188bc7e7aba69d532165c0cceccc78f04","a28f4c45ad72a50f56f7f9df13762c739230b646","16dc592aa326ecd1f8d46ca7e3485a7311af3dba","857726e6c21504e66569e3d61ed6b8710e44db4a","13210f969b8b4d1d12d63a9a8361028a6be498bc","0c10529346c4d2d5d4462636a0b3a0dd9fb8d25c","bbac864f6815762a57ad18bdc3e6c456b7140947","47b8b9cd7b064619e6bf25cde95e7af4bf5bc197","ad913bd3d95fc9e5f6888974e04726eb441a6fc6","413d938109026fb513083a3b3f1c616da005639c","9a95cb1f79a8078e47dfb17f695952a6bea92fb5","044aa72dd3879d4164094c3c8d32e9a1ba2a4f2e","10f1faeec4ee2158b8535b249a20de5419998153","1ea33a0ba2ded13492a4afa6817f953eede0e037","2cea911044b0b9dc2cee2e2b04915b9aab22f86f","e2cd72273908651ea11f9cb45d0dd5d755ca3bd0","49f0f6c03f6eec08fe4426706609413fa5fa6f17","3eae0271717f6b4d65024abf04e5d98aef41d748","c7ae87b4e5952560362e24274a3e9f4e78a666f6","3972fee7dbef2c2c1fc695d175faf4a56dcb382b","362e9b5afe5934a9d8046d758c17c5bada0652b3","5eef609f21fc9327e551ab40425f7f1715c3e200","3a850f54e6dea4728aaa6a71ba222b7d612cd2b1","101bcfb23ad622fa5fed78ca627f0ef3fc8e5624","ae8ee52b076263e1108ac35714bf15c6dd514f11","5ae07f575fb2feb1e03d08af9fe29fafe0a306d7","0f0046ae34181e08594ad9be7b5bfffdbaeda177","51b172edac5e4f60321db6127bd04d9a8931ca1a","34d2db88f259d69022e7492225301ffd6e0f55c0","4d1e3d20531b7118c50b137715b69926d990d7c6","071686697917fd56ae8ace0c4d6bfcf3bef5700a","1476bc7362e02995a8869ed6d3703e740284f450","bb6cedd67b26fce1f0d8eacb0357658c6831586d","1b9e9bfdc66140d2eb192e4ac8aca9281f0239b8","3a66a682ee36cde0738824b152a51df2ccbb80fd","520f2bb3565ab01a28c35f5c7e506bbbef71ed79","1aac5c5e6dda36e455bed8af80dd1fd6bb31321e","3e033205357becbb70e0b697134a5fe6fa17da43","54fe429f0292ad691daaf923e6bf477788892b3b"],"s2Url":"https://semanticscholar.org/paper/00949bff493a83be184650c80e94a74b9e238b52","s2PdfUrl":"","id":"00949bff493a83be184650c80e94a74b9e238b52","authors":[{"name":"Sizhuo Zhang","ids":["1894033"]},{"name":"Muralidaran Vijayaraghavan","ids":["2287352"]},{"name":"Arvind","ids":["3285866"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"The memory model for RISC-V, a newly developed open source ISA, has not been finalized yet and thus, offers an opportunity to evaluate existing memory models. We believe RISC-V should not adopt the memory models of POWER or ARM, because their axiomatic and operational definitions are too complicated. We propose two new weak memory models: WMM and WMM-S, which balance definitional simplicity and implementation flexibility differently. Both allow all instruction reorderings except overtaking of loads by a store. We show that this restriction has little impact on performance and it considerably simplifies operational definitions. It also rules out the out-of-thin-air problem that plagues many definitions. WMM is simple (it is similar to the Alpha memory model), but it disallows behaviors arising due to shared store buffers and shared write-through caches (which are seen in POWER processors). WMM-S, on the other hand, is more complex and allows these behaviors. We give the operational definitions of both models using Instantaneous Instruction Execution (I2E), which has been used in the definitions of SC and TSO. We also show how both models can be implemented using conventional cache-coherent memory systems and out-of-order processors, and encompasses the behaviors of most known optimizations.","inCitations":[],"pdfUrls":["https://arxiv.org/pdf/1707.05923v1.pdf","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.29","http://arxiv.org/abs/1707.05923"],"title":"Weak Memory Models: Balancing Definitional Simplicity and Implementation Flexibility","doi":"10.1109/PACT.2017.29","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.29","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Data-intensive computing","Gigabyte","Limiter","MPU-401","Memory address","Memory management (operating systems)","Microprocessor","Page (computer memory)","Page table","Serialization"],"journalVolume":"","journalPages":"303-317","pmid":"","year":2017,"outCitations":["0ec0e80ebb61ddf97dc26cea65e5013b6de998b1","9c001d2546b07f4325dfa32d46f602bdf56ec474","bf70d60fc8d1de5fa53e8220a014fe463de4b7e5","07c3c9f1be15b52e259309b2e0a9ca71fa7dc76f","33196b69eeec351efd5178eae5da92979bdc6fd7","30c7ccf9860911b37bb6bf17248e2d84afc4b4ba","1c2aed008f7bcb769d0e6f8109434c766fb22bde","7b943438994370dc4903ce28e359ff98fc23027f","0f44833eb9047158221e7b3128cde1347b58ccd6","1a5ce35fc5ad575c2c9e5f692bf263082d656f80","01e6176d319e3bfecc3667447c5bbaf2d00b9c7c","1bed30d161683d279780aee34619f94a860fa973","4678cdcf7e57c1563379ac7cc344254f01ace572","44f779d08d629e915ee7cbe1c0f4f17e9f6a626f","9e2dca06b0ea81c82aa749f9bc7bad220247ebe6","24281c886cd9339fe2fc5881faf5ed72b731a03e","27ee92f60f650feda893a853d4e552a1e9dc2979","61d13a9a4a6cb66e2d5fcf4f75d97570dca8f3fe","0693ff4b3a8d1452b897a876d3ffe6b2074e98e4","2a526bdacd04ea0d6d31cd0e62ed0a772f7d57c3","3f63a2362b1fabc83194d10d6b5a0b2a56c1799b","40f85cbe67ce1ce89009985e9caed648dd08c12e","5ece19ddc8abc5454426deece280d0750972c2da","d9043a6c844905687ac72054d83d7680a82ece9d","3c0bc4e9d30719269b0048d4f36752ab964145dd","6017dd9b32e3c58b8a85c44971d6d82a1e3560cc","1b3bcc24a88caf011201e1ed2a0f94f36a415d50","2bb0f3f198b6f05454a2b4f8b6d3c3ed1c559371","01a337488e77c2fec3037cf7432b7ac10e39b45c","89f4842ef627eb667691b5329e1eaac9bd66a0bf","0fdc029342552729b72e1245a22b60ac96020124","5e41307a2f2850f164ad0175f372799ce61e0bf9","2e5ef3e461eaccf533aaae000ef847ae581d4363","06902cb95ede2c305db4000852014f276b25c082","30db3e0e6add0c2c699e863e56eb8b5e89b10951","1930a2ecb0cd7439647cfe3e79d4bbad198f7697","0653e2ed9f683868cb4539eb8718551242834f6b","2037e142f3b45da72d5c99c0c0de2bb506d4a829","f29dac2e26273532c81c933f091c7a60b9480f94","6ac87f5ef30f787e5dacd59e97d7804e99a7366e","83d8f3fe2468adba47386a90e56e72373f757744","1b1ea9f3f15f5160b77aa2177e7fdeb6eeed911a","e4aed18e1b965f90a86b57a787c52af44a8c20a4","72dfed87d3549369ae93dbbbfd371f88c4e344c8","19de90c933c20849c85d5428c8a643210b97ec83","02d9013e5d370fb79ff1569a59190e18515fa3cd","6068cdb7a834f47a38ffcbfa4128e70ed3e385eb","28af524636137424ad574afa38463b4771e6f006","8b10b13fb495101d1e4eb768907cff05e3bd9315","343a384d5476ead9496f96559aba5ad09e95e01e","42c29d08d9a7bcf5b481300cb06974d6067de5be","ade263c815bf995916a2fa56c89f70efacf6ec5f","7a978f2902460e732c50c36a171deb11733df1fc","369702e8b28a410f7cf4347a1c26e2ea2e0a6a79","d63e4cada8347686372d63a3d00afa89a1515a31","1cb0679ae82be093268747da0f634281ea6a41df","59ca42e1911be417863d0f7068b89e1e59189cc9","73115d3d434d81ba79f125a853a993598c602d26","04dcd8acdc16e42463e783ea5bc8283607ccee3f","4e8505919eb22265f107ebbeeee3fa78bf6d893a","01a7c93e6b5d65b9f8e9b9db8b556964dcf9bf1f","39ac2e0fc4ec63753306f99e71e0f38133e58ead","07add9c98a979e732cfa215c901adb1975f3f43a","07a63423cc46ec67ff18f707379b77ebdfbc1eb9","48215f3287f7d527dc63c5b504ca8397d3bdef4e","08d800d993514c09e1bcf48f244e40346abdc361","776846c6a922e3a9ae25d03e66dda5bba772f576"],"s2Url":"https://semanticscholar.org/paper/16666c536b04035b013c718bd91aad3594b4b894","s2PdfUrl":"","id":"16666c536b04035b013c718bd91aad3594b4b894","authors":[{"name":"Javier Picorel","ids":["3257188"]},{"name":"Djordje Jevdjic","ids":["2217840"]},{"name":"Babak Falsafi","ids":["1701364"]}],"journalName":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)","paperAbstract":"Memory and logic integration on the same chip is becoming increasingly cost effective, creating the opportunity to offload data-intensive functionality to processing units placed inside memory chips. The introduction of memory-side processing units (MPUs) into conventional systems faces virtual memory as the first big showstopper: without efficient hardware support for address translation MPUs have highly limited applicability. Unfortunately, conventional translation mechanisms fall short of providing fast translations as contemporary memories exceed the reach of TLBs, making expensive page walks common.In this paper, we are the first to show that the historically important flexibility to map any virtual page to any page frame is unnecessary in today's servers. We find that while limiting the associativity of the virtual-to-physical mapping incurs no penalty, it can break the translate-then-fetch serialization if combined with careful data placement in the MPU's memory, allowing for translation and data fetch to proceed independently and in parallel. We propose the Distributed Inverted Page Table (DIPTA), a near-memory structure in which the smallest memory partition keeps the translation information for its data share, ensuring that the translation completes together with the data fetch. DIPTA completely eliminates the performance overhead of translation, achieving speedups of up to 3.81x and 2.13x over conventional translation using 4KB and 1GB pages respectively.","inCitations":[],"pdfUrls":["https://arxiv.org/pdf/1612.00445v1.pdf","https://arxiv.org/pdf/1612.00445v2.pdf","https://infoscience.epfl.ch/record/230437/files/EPFL_TH7875.pdf?version=1","http://doi.ieeecomputersociety.org/10.1109/PACT.2017.56","http://arxiv.org/abs/1612.00445","https://arxiv.org/pdf/1612.00445.pdf"],"title":"Near-Memory Address Translation","doi":"10.1109/PACT.2017.56","sources":["DBLP"],"doiUrl":"https://doi.org/10.1109/PACT.2017.56","venue":"2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)"},
{"entities":["Artificial neural network","Biological Neural Networks","Deep learning","Graphics processing unit","Heuristic","Heuristics","Legal expert system","Machine learning","Mathematical optimization","Optimization problem","Parallel computing","Predictive modelling","Program optimization","Unicom System Architect"],"journalVolume":"","journalPages":"","pmid":"","year":2017,"outCitations":["762b63d2eb86f8fd0de98a08561b77527ae8f165","2a042a60aef9eaa6b23241fec2b95831b40030dd","0380c641bf8ffe814e3e48c6964438bfd40e3480","2c5d6794acdb528070df68038a33c1bd16ced1b3","44efef85d56e61fb304f27010cc0d1bd80283a69","a538b05ebb01a40323997629e171c91aa28b8e2f","bc4638f55f6ec57e37ac201ec3a61fdf58540aca","10d3e0f0648d0a5cfaebb3044ea7b14a52e54466","00156e79606084497789662dfaf59c3b54a10722","3ab98cab824062228713b1278ad1e4f026ec346e","278730d2c05757f83417a423d758d3bbe91e6d32","081651b38ff7533550a3adfc1c00da333a8fe86c","69b2f8482713be20b6025c01a475f6da6fddd15b","23f3a802af8493d6fd72d3034ab3bfa7345e9db1","4954fa180728932959997a4768411ff9136aac81","33cd9eda21fa21e3efb6e67fde1d6b98878e32a1","8ac6be0e3ea62e9819d5a25da645f2d350474693","5643b2bf3b8d8a6d7ebf231becb9123b5b4a9287","9952d4d5717afd4a27157ed8b98b0ee3dcb70d6c","075d460a4737d7c0b3fd4b7aa03e315f7256b1af","235317b7ce64b4b3aefe57c1304e8157a4832d2c","03e3a481d9713ad4d39dc608959d87b3f8d8144e","14b5e8ba23860f440ea83ed4770e662b2a111119","235fa2b1983eff9f13b27c620cda389359126bf4","3db24ba1a7db13fb9506713a226bc075a0f8057f","03028a78daf97a01a26975a72c59c8d97cb18810","1ab2dc3c109c2d20cd663e4183f2aed174b71248","60f068dea641df784a379411c57aa8f2b23d1a98","a0327bb12a31beabf5dac9b9e21669047e1565b6","46e107b7e1cecb04310e9c7be51567aefcc18f6f","597a37c1282639a3f5920455bed38dacc5d1aa71","02e0bc77460469aefec5bd794ee6c4efc15e6adb","272216c1f097706721096669d85b2843c23fa77d","01fcae344d2edb715bcc63a40b6052c0331741bd","4708c983f55344273764e064f4f45f94f3e3920e","0c76a904b28c775eb5f33cd982f0bfeddab353e3","1ce7ab36a94bf59817992a906fb4f0b3bf4cc90a","1827de6fa9c9c1b3d647a9d707042e89cf94abf0","065e9991a5481f10da8d35ddb436d3ca3eeae3ee","4506fe8399bd04892293051e895db2ae6b52b4e3","1aec04aa64f165bb075cc4ce6ad79d36c89d62b6","0172cec7fef1815e460678d12eb51fa0d051a677","5f3cce1bc739ebfc03e003010d3438bb318efc14","27e1dbe9f7c71cd6cc1b0357f49aef497e572d09","a5eb8900450908f3e245c3740420af4cb2348ef8","7f013f172a45824d907f68481e92a22e0188ea0b","0bde2adacbdb9a66ba3103e3f128a9d6f3ee032e","14505c2bdd3822d7a62385121d28ba3eb36fea1d"],"s2Url":"https://semanticscholar.org/paper/ca61a1a0cd31ffee5472b12620b7daff81ab740a","s2PdfUrl":"http://pdfs.semanticscholar.org/ca61/a1a0cd31ffee5472b12620b7daff81ab740a.pdf","id":"ca61a1a0cd31ffee5472b12620b7daff81ab740a","authors":[],"journalName":"","paperAbstract":"Accurate automatic optimization heuristics are necessary for dealing with the complexity and diversity of modern hardware and software. Machine learning is a proven technique for learning such heuristics, but its success is bound by the quality of the features used. These features must be hand crafted by developers through a combination of expert domain knowledge and trial and error. This makes the quality of the final model directly dependent on the skill and available time of the system architect. Our work introduces a better way for building heuristics. We develop a deep neural network that learns heuristics over raw code, entirely without using code features. The neural network simultaneously constructs appropriate representations of the code and learns how best to optimize, removing the need for manual feature creation. Further, we show that our neural nets can transfer learning from one optimization problem to another, improving the accuracy of new models, without the help of human experts. We compare the effectiveness of our automatically generated heuristics against ones with features hand-picked by experts. We examine two challenging tasks: predicting optimal mapping for heterogeneous parallelism and GPU thread coarsening factors. In 89% of the cases, the quality of our fully automatic heuristics matches or surpasses that of state-of-theart predictive models using hand-crafted features, providing on average 14% and 12% more performance with no human effort expended on designing features.","inCitations":[],"pdfUrls":["http://www.research.ed.ac.uk/portal/files/37747688/AE_PACT_2017_paper_2.pdf"],"title":"End-to-end Deep Learning of Optimization Heuristics","doi":"","sources":[],"doiUrl":"","venue":""},
