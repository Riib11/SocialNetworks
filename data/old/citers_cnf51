{"entities":["Algorithm","Bitmap","Database","Experiment","Information retrieval","Inverted index","Real life","Synthetic data","Zipf's law"],"journalVolume":"","journalPages":"993-1008","pmid":"","year":2017,"outCitations":["62c7aa24f09320320a309c4298e045faf25ac7cd","ce97bda189755032f19e092dbbf7740707f2ae86","0437e781bf22d47f3a13cca1e27eca6ae91d3f41","0447f4b8b695f76b2ce768cc236068dd89841767","409f067439ecbc2da37a03c9609034946393608e","3f807d32f1033ddb76ae52527bbc5c3a72ef1e0e","392d804a0fe5ad68f721857cf5cbe01963f3d8a4","5d37dbcead67858f972056555745041250bb1b6a","fc3272302461b74217662085a8a05a5e500dbf05","1feb21ac7d86ed235f9989aea1131c6008061de1","2c5b8766a1dae62b86ba38013253ab8673f6ec44","6f4cc8b9561b5afb401bf07834e746d6ac28d141","8f5dce9df50316a41578e0689b41b8ab69a0ff09","55ce0391cae3d7663a26bc6bb1a1e5618b8b9475","8ce69d30bca576f7230782a15df55b231ecd6cc3","037f2f2a9b6d3438d87b2ae3f38f53be8c47f44b","3cd9a873ba0f7fb754feb2cd7da567a31290b6e5","11e7e1001f96fd537f1f24cf211cd8c170773970","9233979387c07fb9dd32b91612804c33ce53b8b8","20548990990c447ab54a3ecba82af2b5443a01d6","e6bc99c79d2187a7a5f99dfc5e92b623f6bfc050","ad585974e2d05758cd36e2ab2e346f38b4de4a0f","180477d8f809745da689372715c225ef5d3c098d","02d9013e5d370fb79ff1569a59190e18515fa3cd","66713fbcb8d5e48a9eb6425bd7fdbb53751e60b1","51f53b98ccc60bf255ab653a11b1573ed3c5d815","e4c158621b855d30292d36558d19f90af28d7978","040678daf6a49a88345ee0c680fccfd134f24d4b","d2be22e50067b6ac13ccbafb3f7ece2a96988c9d","313e8120c31fda6877ea426d8a3be9bcf1b6e088","7531ab50766c71d05e7d8bd5039bab1e82623e97","5df0ced15b18103c9517805c4c0447e2af72e217","c83dd0b8ecbae77b799d61c8c40889d1d0b555a6","3a387279bb9dd664dd29d65cda95c3fddad823e8","0e7148699994155cf8afae0ed943812fbb4f4b7f","3c513e3f47c87da19a12cc65fb809eab671bf7ee","19ae1215523450e717acb3d510bced0b88499233","924276d95d1bdaf087beb0ccf699443b9bf855ec","46341278ed333089ba99bcc45eb87f61c32f63f5"],"s2Url":"https://semanticscholar.org/paper/0f2a463eece4960dc62da2df58a224ae85e1473b","s2PdfUrl":"","id":"0f2a463eece4960dc62da2df58a224ae85e1473b","authors":[{"name":"Jianguo Wang","ids":["40362329"]},{"name":"Chunbin Lin","ids":["40648346"]},{"name":"Yannis Papakonstantinou","ids":["1786049"]},{"name":"Steven Swanson","ids":["1760342"]}],"journalName":"","paperAbstract":"Bitmap compression has been studied extensively in the database area and many efficient compression schemes were proposed, e.g., BBC, WAH, EWAH, and Roaring. Inverted list compression is also a well-studied topic in the information retrieval community and many inverted list compression algorithms were developed as well, e.g., VB, PforDelta, GroupVB, Simple8b, and SIMDPforDelta. We observe that they essentially solve the same problem, i.e., how to store a collection of sorted integers with as few as possible bits and support query processing as fast as possible. Due to historical reasons, bitmap compression and inverted list compression were developed as two separated lines of research in the database area and information retrieval area. Thus, a natural question is: <i>Which one is better between bitmap compression and inverted list compression?</i>\n To answer the question, we present the first comprehensive experimental study to compare a series of <b>9</b> bitmap compression methods and <b>12</b> inverted list compression methods. We compare these <b>21</b> algorithms on synthetic datasets with different distributions (uniform, zipf, and markov) as well as <b>8</b> real-life datasets in terms of the space overhead, decompression time, intersection time, and union time. Based on the results, we provide many lessons and guidelines that can be used for practitioners to decide which technique to adopt in future systems and also for researchers to develop new algorithms.","inCitations":["a5081939c059add7ed0754cee736e1f272916de3"],"pdfUrls":["http://db.ucsd.edu/wp-content/uploads/2017/03/sidm338-wangA.pdf","http://doi.acm.org/10.1145/3035918.3064007"],"title":"An Experimental Study of Bitmap Compression vs. Inverted List Compression","doi":"10.1145/3035918.3064007","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064007","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Algorithmic efficiency","Computation","Distributed algorithm","Distributed computing","Experiment","Graph partition","Load balancing (computing)","PageRank","Personalization","Scalability"],"journalVolume":"","journalPages":"479-494","pmid":"","year":2017,"outCitations":["462408be7dea21a28232a72dd0d1fed122872f26","631e721376e844a016ffe18a8a9af3d75766f91c","3e1e5a5edd5858d906b49363984a3e3659fb9478","b78c04c7f29ddaeaeb208d4eae684ffccd71e04f","3ad743e436bb8749b7f750e4b316550a9d124bac","1dd8db60043f51c04eb7200915ebd253d2fabf64","2e9755294bfcebbe2d6bbdc7937cf76f25d605fc","02903a2d438b242d87904d18c20f191ec98f9b2b","41a70062d260feb62e0ae64acf252a839c0bbd61","04b55cb152457e741aeffcc06108963a019c8cc6","408cd9103f2d7cdafce2f6b984035b2be0ed9b7d","183c44d2b9ac64e8c795464f91ef98f1e3ba2ea3","18141e44f720c49dde29ebe4ad16a481796fd422","233084c0d1c818c842be6a9bb50f5dd2d1d1682f","1606f7d2634e593d617ee67985fbdd9915bd7190","2eed842c2cf908df5c5d9c1c1e0a160ecd881679","95b251202e1f5ff7d7f41dda553a38e395ecf555","0ecdf0d9e33ae993d5f789c6e1bb410ba2fca0b8","87f931f4d8aad3b71b8261703bbcfa18c1293181","eb82d3035849cd23578096462ba419b53198a556","9fdfb79b25450f42434d0baf39362052e1192acd","51ea20dc4f688af41f9840a854d15bac49db1be6","010a3f35d8d245ad0dcc87fc5f598ed0cda31ebf","39eb6f355b0dc5fbd7115b93d389cc8fa3c5b1c3","2a622720d4021259a6f6d3c6298559d1b56e7e62","468c3b2bf358d07cc625b075f91595d825299948","47e6565146580f4550e496bd9bfc70053bf748d6","09b4276e4c1bd3621de3830b8ee1ebfc4876136e","47c4651a707a91db806a6034897e42e2530bb681","423befa4222b5b54cf63f0879e99243b0e5139b0","87ee99d4cc4e0601cbb519f6ddbac85772bdc49e","6d30db4bdb14d5a23320970407e1fa5bb514b7c2","009dbf3187862352aac542bf7d61e27bce6b27f5","040d45e995ab920588607ebc6977ea19dc781923","630b514e68c0de62fa3dca5a45e3131f1515c90c","29efbdf3f95cee97405accafdebd3bd374f1f003","543bb14ed41e66a4a964a81110417facd7c20744","b3ca8fb21ef2e12b4aba555230559d632c1e3ea3","32452c6be455b2ec18403866e4fc48ef842f2587","607c8ae7b868015ea2deb61969d7e38988de8ca1","3726c60552263e648c6856679e672de2e1c110e5","3105c03f6ee3135ac6b649ed6313ae0e6c0eb8fc","0b3292b79721cda54001902d54b3142d6ec3012f","1156f60e40548096df49528b1342bb3e88b0f378","4f9df283f1dac228fbbd3efd50765ecb317efe6c","05881ca4901379f7e9221d6ee3c0c5921e8f24be","138a0de40dcaacf258e5e02499cb960ae549aa8f"],"s2Url":"https://semanticscholar.org/paper/a38c6933d5ea67a33a679a2d925cdf82045b5c50","s2PdfUrl":"","id":"a38c6933d5ea67a33a679a2d925cdf82045b5c50","authors":[{"name":"Tao Guo","ids":["38561978"]},{"name":"Xin Cao","ids":["2324195"]},{"name":"Gao Cong","ids":["1737379"]},{"name":"Jiaheng Lu","ids":["1680607"]},{"name":"Xuemin Lin","ids":["2873542"]}],"journalName":"","paperAbstract":"As one of the most well known graph computation problems, <i>Personalized PageRank</i> is an effective approach for computing the similarity score between two nodes, and it has been widely used in various applications, such as link prediction and recommendation. Due to the high computational cost and space cost of computing the exact Personalized PageRank Vector (PPV), most existing studies compute PPV approximately. In this paper, we propose novel and efficient distributed algorithms that compute PPV exactly based on graph partitioning on a general coordinator-based share-nothing distributed computing platform. Our algorithms takes three aspects into account: the load balance, the communication cost, and the computation cost of each machine. The proposed algorithms only require one time of communication between each machine and the coordinator at query time. The communication cost is bounded, and the work load on each machine is balanced. Comprehensive experiments conducted on five real datasets demonstrate the efficiency and the scalability of our proposed methods.","inCitations":["7528af5e921212f3e338951bdabf653977eabb72"],"pdfUrls":["https://www.cs.helsinki.fi/u/jilu/documents/SIGMOD2017.pdf","http://doi.acm.org/10.1145/3035918.3035920"],"title":"Distributed Algorithms on Exact Personalized PageRank","doi":"10.1145/3035918.3035920","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035920","venue":"SIGMOD Conference"},
{"entities":["Bit array","Bit manipulation","Bloom filter","Central processing unit","Computational biology","Concurrency control","Data structure","Database","Experiment","Hash table","Haswell (microarchitecture)","In-memory database","Locality of reference","Lookup table","Quotient filter","Random-access memory","Solid-state drive","X86"],"journalVolume":"","journalPages":"775-787","pmid":"","year":2017,"outCitations":["1688c9bb957395bf7ac05098537c736cfd076382","f2bec2b1a69d8db2cb8ada7096be847fb5b83dd4","76e43a0e0ff9e32cfc0223721e13d8d2a0d2bfd0","6c1f7496580d1169b232c53981f1e63e593be21f","0ce479229630e55e732597cf9b2aeb5018aae4c2","e9105f3cdb634572032d99c3a762921a4b2842c7","fc645620fbf4a6667e11e237c882f276aa2df573","8f491cc687250f6ae2c3d87dcb256680c25ff1ce","3946e3a4a4f5b42d55859153e98d3e83151303bb","41cdc268d9ec5595f40ebf2e457f3f7f87a503de","d87c6b6a1a5da0502e311e24fb2d2f79dd956623","da6a07944d97723d6c154d76609b5c20a3636f9a","34bb8a2c052e358e14b49eb8b03f02826cdfecaf","339888b357e780c6e80fc135ec48a14c3b524f7d","3492873a8bc6d1d501dcac97e891c43dfecc29c0","59f0f5f7ee08d4d690d95c96db6af793c139c7a4","389b618c42c0d5d32a569b9cbaa02a7ff77c6be6","21eef1690dccbd1aacc8098da4bae7299096792c","7a278ee0578f194700cadc3811cdda4ec751f88a","2ebf5570bee564efbf1b782ba23454708d6c251b","24d8d6225ea758f240dd75a658a1f2957fb18d20","3a2f37d3648592ffb42155c28f71894ad61937fe","92a6961f076307d5b4778fd45d5f01f6d5d84e12","7f49cad23f57a8bc48133b2c599d40c216d1c046","03a3b5ca18f6482cfee128eb24ddd1a59015fb2d","3593269a4bf87a7d0f7aba639a50bc74cb288fb1","8c23432e7c894bcadfd0aed0fa36dc00ba5bd75f","13bf79b773cc84590d3efeb88187f2675dea4b81"],"s2Url":"https://semanticscholar.org/paper/6bdef4a86108309086de4071c9d28d97565a84a4","s2PdfUrl":"","id":"6bdef4a86108309086de4071c9d28d97565a84a4","authors":[{"name":"Prashant Pandey","ids":["1890685"]},{"name":"Michael A. Bender","ids":["33877556"]},{"name":"Rob Johnson","ids":["2387399"]},{"name":"Robert Patro","ids":["2620138"]}],"journalName":"","paperAbstract":"Approximate Membership Query (AMQ) data structures, such as the Bloom filter, quotient filter, and cuckoo filter, have found numerous applications in databases, storage systems, networks, computational biology, and other domains. However, many applications must work around limitations in the capabilities or performance of current AMQs, making these applications more complex and less performant. For example, many current AMQs cannot delete or count the number of occurrences of each input item, take up large amounts of space, are slow, cannot be resized or merged, or have poor locality of reference and hence perform poorly when stored on SSD or disk. This paper proposes a new general-purpose AMQ, the counting quotient filter (CQF). The CQF supports approximate membership testing and counting the occurrences of items in a data set. This general-purpose AMQ is small and fast, has good locality of reference, scales out of RAM to SSD, and supports deletions, counting (even on skewed data sets), resizing, merging, and highly concurrent access. The paper reports on the structure's performance on both manufactured and application-generated data sets.\n In our experiments, the CQF performs in-memory inserts and queries up to an order-of magnitude faster than the original quotient filter, several times faster than a Bloom filter, and similarly to the cuckoo filter, even though none of these other data structures support counting. On SSD, the CQF outperforms all structures by a factor of at least 2 because the CQF has good data locality.\n The CQF achieves these performance gains by restructuring the metadata bits of the quotient filter to obtain fast lookups at high load factors (i.e., even when the data structure is almost full). As a result, the CQF offers good lookup performance even up to a load factor of 95%. Counting is essentially free in the CQF in the sense that the structure is comparable or more space efficient even than non-counting data structures (e.g., Bloom, quotient, and cuckoo filters).\n The paper also shows how to speed up CQF operations by using new x86 bit-manipulation instructions introduced in Intel's Haswell line of processors. The restructured metadata transforms many quotient filter metadata operations into rank-and-select bit-vector operations. Thus, our efficient implementations of rank and select may be useful for other rank-and-select-based data structures.","inCitations":["746ff01cf8bf954e15eb6ad9c240205d39dca387","3a6f98e3cb616dc7fe479282f032975cb898fa5a","f2bec2b1a69d8db2cb8ada7096be847fb5b83dd4","8a7b52dd3bf98996bdcafad45b5549ff0f199424","0030ab76d18084ebae4da1cab829c535a71b984c","7140dfc69ed2ca65dd8bbdcf5d5b3742f2d839c2","3e3f8fcf746a8bfa1aa6773ded336bd3ae6245bf","0821389b330338a5b844080287440c583d05d441"],"pdfUrls":["http://www3.cs.stonybrook.edu/~ppandey/files/p775-pandey.pdf","http://doi.acm.org/10.1145/3035918.3035963","http://www3.cs.stonybrook.edu/~ppandey/files/SIGMOD17_Talk_CQF_long.pdf"],"title":"A General-Purpose Counting Filter: Making Every Bit Count","doi":"10.1145/3035918.3035963","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035963","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Approximation algorithm","Computation","Convex hull","Database","Experiment","Linear function","Linear function (calculus)","Maxima","Ranking (information retrieval)","Regret (decision theory)","Scalability","Synthetic data","Time complexity"],"journalVolume":"","journalPages":"821-834","pmid":"","year":2017,"outCitations":["5dbe84872b42cb6167d3b601fdf68b4eb2d7f5d9","0f7e7d9add82a37b44764bd706b60fddd97b13fd","627948936c3c3d99ff539adf3a6e7cb59dd223b7","23be8286c280f45599625fda69cd708d68453e04","bfffeceec24b343526a0b2125edcaae1642dcd2e","1a5fe34a83e3b6f08b628b7af2d915876ba13819","04ff502fe2cd481a151230fb890d7ae9a093f561","4b70aada3dbbf70608a9461afa586f76f271c5a2","23ba8478c076752e21d57d43f82e32ac13b69a6b","6156864e6fd0836726fc7e7ce1d5bdcff112fe27","0d1537ac7c69142c02547bbccd5a8bdd5693edfd","279c6d90821d46703fe6c17daa9c64064cc2044a","561b0881fb83c7182bca4aec70bd287ea0f5be28","383aea82514e1d148ec6dd81796ae5a64d50725d","6cac85a7bc11b9cab6cf971ff0bc4628b380ee2f","9cc857b1e9c4a8ad6b3b0c774a13bff9e5d01c77","10927ae8a906b482330a95b411285e2e4e407ca6","4e0f71061c47f45fd1281875db38902540f59c95","7e4cb3ca74b9e0d83cb53340d4ead2331cc8328c","3a456b2933cb09bc192b390defe3e479e85ba595","959258cb7ff636fee908e6f6877388081ca706b6","17d3d9783e4d2793fbf6ee18a490034d99534253","114fd5089776a0562cf4e8276049cc11222fe51f","2569420c9ed2ea744216351b803f68f9cceb5ce6","ebb133a407796154622c625e54c57ead21e322da"],"s2Url":"https://semanticscholar.org/paper/119e2f92baa9d2079f32f29089b29f4aa2ecaae7","s2PdfUrl":"","id":"119e2f92baa9d2079f32f29089b29f4aa2ecaae7","authors":[{"name":"Abolfazl Asudeh","ids":["1717283"]},{"name":"Azade Nazi","ids":["3038200"]},{"name":"Nan Zhang","ids":["36856144"]},{"name":"Gautam Das","ids":["1690440"]}],"journalName":"","paperAbstract":"Finding the maxima of a database based on a user preference, especially when the ranking function is a linear combination of the attributes, has been the subject of recent research. A critical observation is that the <i>em convex hull</i> is the subset of tuples that can be used to find the maxima of any linear function. However, in real world applications the convex hull can be a significant portion of the database, and thus its performance is greatly reduced. Thus, computing a subset limited to $r$ tuples that minimizes the <i>regret ratio</i> (a measure of the user's dissatisfaction with the result from the limited set versus the one from the entire database) is of interest.\n In this paper, we make several fundamental theoretical as well as practical advances in developing such a compact set. In the case of two dimensional databases, we develop an optimal linearithmic time algorithm by leveraging the ordering of skyline tuples. In the case of higher dimensions, the problem is known to be NPcomplete. As one of our main results of this paper, we develop an approximation algorithm that runs in linearithmic time and guarantees a regret ratio, within any arbitrarily small user-controllable distance from the optimal regret ratio. The comprehensive set of experiments on both synthetic and publicly available real datasets confirm the efficiency, quality of output, and scalability of our proposed algorithms.","inCitations":["23323ba9634f395d01e01a1b3f196e5e14e5d6b1","4d77b6b7a8b7954a99d54280cc7f3c84a85c29e8"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035932","https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/EfficientRegretRatio.pdf"],"title":"Efficient Computation of Regret-ratio Minimizing Set: A Compact Maxima Representative","doi":"10.1145/3035918.3035932","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035932","venue":"SIGMOD Conference"},
{"entities":["Crowdsourcing","Database","Estimation theory","Experiment","Money"],"journalVolume":"","journalPages":"1415-1430","pmid":"","year":2017,"outCitations":["0ee10b695a90d7699b0518436d9bac53410c2d0b","3a5066bcd59f81228876b6bf7d5410c63a82f173","7e402f75d09b2de259e14e07cdb88d40e3128e7c","8b58ef72e680bfbceeae3baaa01487ac00aead48","d8e320d7bacb68a13c90f8913cbf0c38fe4f80e0","32be67f8fb5b21554b950fb49f3c81098d5d23c7","146e33f6ac7ee643af0a6a10f78a5273e6dfad86","162c68e07814704109122d61771c1ce067e95b86","49ceba7f32b3d440f20b7b35d4c7462016666ef9","5611660a5f09be040e2a1c5c942fac88bd1e5d0e","8490234d79b47e459824dcf87c1e288211a3c964","2220feec76a17e509a58abf8c742ea9b7866a99e","4033104e3a37324df023fec7e95d852e962617de","a96c51a903d244b6006a2999269f5e9931e25403","01bc8e0e0048255596ec56498fc6b80e4340d244","5f2c3d94ef509af1fc49dbecf5c69f2663dbc827","35c71faec5506d8fe79bb997f6e9e3743dc436a6","16c36a0ab390553d77877ee634607899e4eececf","eb82d3035849cd23578096462ba419b53198a556","1b264b6547cda91a7d1599b875669c7853974ad9","199dcbb1e5287eedb458c867b171cc83c06b0d2a","37ae295ba271939ca67a6d2ddc60a256829df9cf","08f51a9138458f667f0c00d40b6a820c451c7d36","2ae7aa1572cb39539b9b4c558f2bd7836cae151c","5ee09c89bdcf9b1aa7b62e78549f17a6774417a7","8a0b267493ac9510e47ceb4bcebb6d202b2f89a5","f585d28de2c8bf0ab1f149d1cf9becb8e77b2af0","58ce51c7e7875403904741390e1c81079f97441a","a21398c57a2859b492602d854cf9ccfb36ba9541","64edd2c5c41e856695e1dcb950c0512c3a87edec"],"s2Url":"https://semanticscholar.org/paper/142a51f57f3066efbb52d84ba1c43b068dc585b9","s2PdfUrl":"","id":"142a51f57f3066efbb52d84ba1c43b068dc585b9","authors":[{"name":"Ngai Meng Kou","ids":["2991150"]},{"name":"Yan Li","ids":["1698571"]},{"name":"Hao Wang","ids":["39049654"]},{"name":"Leong Hou U","ids":["1713638"]},{"name":"Zhiguo Gong","ids":["1735422"]}],"journalName":"","paperAbstract":"Crowdsourced query processing is an emerging processing technique that tackles computationally challenging problems by human intelligence. The basic idea is to decompose a computationally challenging problem into a set of human friendly microtasks (e.g., pairwise comparisons) that are distributed to and answered by the crowd. The solution of the problem is then computed (e.g., by aggregation) based on the crowdsourced answers to the microtasks. In this work, we attempt to revisit the crowdsourced processing of the top-<i>k</i> queries, aiming at (1) securing the quality of crowdsourced comparisons by a certain confidence level and (2) minimizing the total monetary cost. To secure the quality of each paired comparison, we employ two statistical tools, Student's t-distribution estimation and Stein's estimation, to estimate the confidence interval of the underlying mean value, which is then used to draw a conclusion to the comparison. Based on the pairwise comparison process, we attempt to minimize the monetary cost of the top-<i>k</i> processing within a Select-Partition-Rank framework. Our experiments, conducted on four real datasets, demonstrate that our stochastic method outperforms other existing top-<i>k</i> processing techniques by a visible difference.","inCitations":["4d96002263faa311fa61d7fefda7361061356f26"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035953"],"title":"Crowdsourced Top-k Queries by Confidence-Aware Pairwise Judgments","doi":"10.1145/3035918.3035953","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035953","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Analysis of algorithms","Apache Hadoop","Column (database)","Column-oriented DBMS","Data deduplication","Hard disk drive performance characteristics","Input/output","Memory-mapped I/O","Real life","Requirement"],"journalVolume":"","journalPages":"299-314","pmid":"","year":2017,"outCitations":["0b99db47b233e2ddb743a82c9a5cc755c8aedb84","4ec54afc661d9fe0caebafb80a3de3482de3b545","24281c886cd9339fe2fc5881faf5ed72b731a03e","8db5d8f4bf055bbe64ccfe29c5fd778ef24ade5b","21854a5fb77a45f411865652a63663bb9ff3cde9","40c2e4e3a0f9d2fef4e4c9bed8fce7b624fadac0","495e4ab43ffc0e5c11919c6ec42e48a4ce651327","78a44566e76c0d702524d8ff4a99d3f505e739e4","06fb8f5e59bac8b014e7ab70851b3568ea5a0a46","09c1b69ab0fe1315b0d5e5e0b0853585c4a319b5","4c0afc69b07e3bb2daa32ca628ee491cb0338f80","024157990c0257c454beae3915f83ce5b088d767","229467e56c6093cb1f5927f8ffeddd51ac012934","0a0c026b2b6c04baaf1fa2933d5998519bc9c5fa","3e4af9e1e3e64be2ef79bbf63daf4ef640183719","207def18c67fa8024741b7ae3cdc655b57f2053f","4c7bfa933c11c7a802c2fa9c1dc475dba36a2bd5","a087b0fcc9439faca5e3a68f8c9a2a47f5c95cc2","075f51b0aeaac7ebed18d5fbf67e64a14c8943f1","045d927280938686695693a1e265654969670f50","21d3abf5a2ccbeb0aa58ab950784491ed59567d4","00aa614734a26a19b09a0a3bdee2adc77bdac5e4","0109b8d4f75feed4ffbd4b5d555bac1e2d27815d","03ff946dc6e4170ad4271b6e8ca26402ee957472","9165824baf8b0dd3c4065cc1282f489185db95d8","7459d07ca88484784a6c895aba0f8b019c971289","1c27eafecd3d6f0008d74ffbe1e7c59a25869407","1e557937f418accc13f9c5edb33a3d48259d80e5","0b56f1f864a5949ab4ba06a6cb7ecc0c986b3f45","9141bafcff1df2dbabf9a20671d2fa1bcb55aae5","5046a718f92447642939f5c93414dc97225d726a","0bc27c2354e6c86b0150662e45856dd4e446b2ed","d7ac71ec88fc9e5a63f44b950e32d65eaf3b1c2f"],"s2Url":"https://semanticscholar.org/paper/1ae7ba9910b07b1c38353615dd3fa668f4554c68","s2PdfUrl":"","id":"1ae7ba9910b07b1c38353615dd3fa668f4554c68","authors":[{"name":"Haoqiong Bian","ids":["2667024"]},{"name":"Ying Yan","ids":["30563822"]},{"name":"Wenbo Tao","ids":["2893500"]},{"name":"Liang Jeff Chen","ids":["40119206"]},{"name":"Yueguo Chen","ids":["1743832"]},{"name":"Xiaoyong Du","ids":["1688063"]},{"name":"Thomas Moscibroda","ids":["1715172"]}],"journalName":"","paperAbstract":"Modern data analytical tasks often witness very wide tables, from a few hundred columns to a few thousand. While it is commonly agreed that column stores are an appropriate data format for wide tables and analytical workloads, the physical <i>order of columns</i> has not been investigated. Column ordering plays a critical role in I/O performance, because in wide tables accessing the columns in a single horizontal partition may involve multiple disk seeks. An optimal column ordering will incur minimal cumulative disk seek costs for the set of queries applied to the data. In this paper, we aim to find such an optimal column layout to maximize I/O performance. Specifically, we study two problems for column stores on HDFS: column ordering and column duplication. Column ordering seeks an approximately optimal order of columns; column duplication complements column ordering in that some columns may be duplicated multiple times to reduce contention among the queries' diverse requirements on the column order. We consider an actual fine-grained cost model for column accesses and propose algorithms that take a query workload as input and output a column ordering strategy with or without storage redundancy that significantly improves the overall I/O performance. Experimental results over real-life data and production query workloads confirm the effectiveness of the proposed algorithms in diverse settings.","inCitations":["18e93539fe6163a0b56f3427fc562733f89449a6"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035930"],"title":"Wide Table Layout Optimization based on Column Ordering and Duplication","doi":"10.1145/3035918.3035930","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035930","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Cluster analysis","DBSCAN","Relaxation (approximation)"],"journalVolume":"","journalPages":"1493-1507","pmid":"","year":2017,"outCitations":["1375c722eee6e58041f9e295042d42e43ac3428c","77e9256276e2014b6d801d16f896653f5bc6d5d4","057249d12815a5b01cca41e808704954ac616a22","1a6715bc96b4661424ffc1218c2bd65fcd76a844","02e0bc77460469aefec5bd794ee6c4efc15e6adb","5869b3d5607bff1a079aa24c8a241d656fe683b7","39a73f94c33cf8f0268930b7ec538f3d95152f5e","757effee0314f1b81386ffb7c48c11a7aedf546c","1f63499a9cb43f0f4d6a56b37de551c7e0c94971","13a375a84a6c414b85477a401541d3e28db1e11a","6d0e181087547f6306468560e2b3f8242892bf46","92f47daf7dedc1443729d711a54a5be21129cb61","1a92a74bd60ba49c26958eda0cfedef12ef61171","371db75f3f668317af075767b0630c6c93288212","75a4860c9b3b2e95bc3a8056543e7560a1753f2b","c923be743ee3990e1ac0f29bd53531a8d54832e1","0d557c7a7d6b50c3ccdb6a9f48e4c552541f5930","0157f142bee7b462897424908cd6c73d84f225cc","0597d7259c0a61fa13f2f9aa852525d127a7fe16","c5a17da1916bd3a7f2dc5fb3339374c1988389a7","309d445a15ce2e71c20bd069e4c655888ae501e5"],"s2Url":"https://semanticscholar.org/paper/829677ca5af4daba5a1619457869462db075905b","s2PdfUrl":"","id":"829677ca5af4daba5a1619457869462db075905b","authors":[{"name":"Junhao Gan","ids":["2445536"]},{"name":"Yufei Tao","ids":["1802067"]}],"journalName":"","paperAbstract":"<i>Dynamic clustering</i>---how to efficiently maintain data clusters along with updates in the underlying dataset---is a difficult topic. This is especially true for <i>density-based clustering</i>, where objects are aggregated based on transitivity of proximity, under which deciding the cluster(s) of an object may require the inspection of numerous other objects. The phenomenon is unfortunate, given the popular usage of this clustering approach in many applications demanding data updates.\n Motivated by the above, we investigate the algorithmic principles for dynamic clustering by DBSCAN, a successful representative of density-based clustering, and &#961;-approximate DBSCAN, proposed to bring down the computational hardness of the former on <i>static</i> data. Surprisingly, we prove that the &#961;-approximate version <i>suffers from the very same hardness when the dataset is fully dynamic</i>, namely, when both insertions and deletions are allowed. We also show that this issue goes away as soon as tiny further relaxation is applied, yet still ensuring the same quality---known as the ``sandwich guarantee''---of &#961;-approximate DBSCAN. Our algorithms guarantee near-constant update processing, and outperform existing approaches by a factor over two orders of magnitude.","inCitations":["1f3fa5b6b7b74cb585132c6cbfd5dbc708fef30c","b6b1e61a25d080570b0295d84d96266af0293188","d5bcb5d7198e8936d5d5946c7feb3364eadba542"],"pdfUrls":["http://www.cse.cuhk.edu.hk/~taoyf/paper/sigmod17.pdf","http://doi.acm.org/10.1145/3035918.3064050"],"title":"Dynamic Density Based Clustering","doi":"10.1145/3035918.3064050","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064050","venue":"SIGMOD Conference"},
{"entities":["Linear programming","Routing","Run time (program lifecycle phase)"],"journalVolume":"","journalPages":"203-218","pmid":"","year":2017,"outCitations":["35347e426812f44addc5885ba54c9d48ca14fb72","153506e97f5db120d28f0f4c726cbb5d751baa00","1960fb12c5e7de808f64db14f7316b562bae6b2c","111864cac232d8a9c170bd63069eb4af155a9f7b","313d4b7583d730c2864422d9d7d4e06db59f1527","94d44e9c456b755524e5d28dddaa918584cd755b","6a338178e088868e5253914ed4363b73ce81a0f4","36583417faf3d052c415262cca1ba44a6b90d75c","51d1cfdf9233cab9cc40f72bf049c2ad2f36082c","17d122f143726288da193a767fd0a7634010f0ff","1289116bbdfeef7070507dd18688753d8ca32d52","0a30411ad3f537fe026bc6335adbde75a6da3a8e","26b0a144690bf20d8ab06ea69ac3d49ce870979c","000c557e5bcb9def56479751f06fc8eec3f8acda","22fe15c47aa7f8adfe733aeb6fe9956932a2a98d","1d80de948ddcf8f3524763ed3d5f4485f46d70fb","231793a731604a9f756fe8453098ea814c1c0ef3","28c15499e6175f26966ac57a07fbe1b79a1d4c18","c07928641bba0e42199a19b63763e96dd48183e4","ad9b5bfc8371836c5499d5525493935d8adda5f9","481d75d413e61440db177b0c954a650f9506f331","1fe41b1240a0eddec736b675e914b4858a955876","2bd43ff1b3bb7db0e430e8578e913c2787dd6532","069103feb2d2d3f1b0115b484d5c2f978a983df0"],"s2Url":"https://semanticscholar.org/paper/abbf56a715fc32b9ef04103bac7759bbaa509e4d","s2PdfUrl":"","id":"abbf56a715fc32b9ef04103bac7759bbaa509e4d","authors":[{"name":"Chen Chen","ids":["40481129"]},{"name":"Harshal Tushar Lehri","ids":["10741766"]},{"name":"Lay Kuan Loh","ids":["31682740"]},{"name":"Anupam Alur","ids":["10761550"]},{"name":"Limin Jia","ids":["1758542"]},{"name":"Boon Thau Loo","ids":["35206168"]},{"name":"Wenchao Zhou","ids":["33779522"]}],"journalName":"","paperAbstract":"Network provenance, which records the execution history of network events as meta-data, is becoming increasingly important for network accountability and failure diagnosis. For example, network provenance may be used to trace the path that a message traversed in a network, or to reveal how a particular routing entry was derived and the parties involved in its derivation. A challenge when storing the provenance of a live network is that the large number of the arriving messages may incur substantial storage overhead. In this paper, we explore techniques to dynamically compress distributed provenance stored at scale. Logically, the compression is achieved by grouping equivalent provenance trees and maintaining only one concrete copy for each equivalence class. To efficiently identify equivalent provenance, we (1) introduce distributed event-based linear programs (DELP) to specify distributed network applications, and (2) statically analyze DELPs to allow for quick detection of provenance equivalence at runtime. Our experimental results demonstrate that our approach leads to significant storage reduction and query latency improvement over alternative approaches.","inCitations":["53c0617eb76ed39f3ba9f3a45374839d7904ef93","0240d922d1934db0e79dbfac9721d7870299ff9a","99eb70eac5c1458beaa8fd9230fd45d05d1169ec"],"pdfUrls":["http://people.cs.georgetown.edu/~wzhou/publication/provcompress-sigmod17.pdf","http://doi.acm.org/10.1145/3035918.3035926"],"title":"Distributed Provenance Compression","doi":"10.1145/3035918.3035926","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035926","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Benchmark (computing)","FOCAL (programming language)","Row (database)","Synthetic data","Tree rearrangement","User (computing)","User interface","User profile","Weight function"],"journalVolume":"","journalPages":"805-820","pmid":"","year":2017,"outCitations":["3557d22cd663e4939a86f43d044b8cb55cd97e16","5432324996087b0081acc2637eba3455bf021bc0","74eaae49b235cee87bca9098f8a8c3fc3f8de1f4","5dbe84872b42cb6167d3b601fdf68b4eb2d7f5d9","10feecb5eebbb958439aabb2e10bd56739e315c9","42f582f01479787622357ac90ea33d813c700f85","5f814d8d2fa48cc9c29f8c94d6ae97236e6e259d","04ff502fe2cd481a151230fb890d7ae9a093f561","084916725a430a16e8469d257ebbb5ea8b0c5bbc","806bdc15cf8a85738f3e4c193780b426b2c1637a","d203fe567346510b3de7da57e974a5aff2b21b20","1beeaf5818ba40ea64972b1b3b617f7467cf6eb6","a11db1672f9bbf8c2c967b4d41b6264284882fff","2f4b3836e40fe54412cf77a002b8ab9827d5d8c3","4325e0fbf8e6e3a9574e1f070a649d8d1528abcb","0d557c7a7d6b50c3ccdb6a9f48e4c552541f5930","28e702e1a352854cf0748b9a6a9ad6679b1d4e83","4b633bec0b93f5175e45aa17b966846eaae983f9","ed56740bdab41806b41bcb9deaedf91f2f7c2f82","279c6d90821d46703fe6c17daa9c64064cc2044a","38a5150d236872d43610ded32ca0714fe0c68f7c","3dcc1a9a3d08413e680cb764988c424720400867","8826c500c659f33c76d7341105f0b7816769abda","03d09018b004d899fba9d9794c67246ed766ab1d","fc30bfb07da885dbe27c3acb50a600781c727c97","3ceaf000e836f3601d78ebfe058c5106525c2e0b","57db55f3555e9821b64ad8dd941fa87ad3f06e92","6f8660e7fa35001dbf75b60199af24b9d3482d7d","146e33f6ac7ee643af0a6a10f78a5273e6dfad86","a401596b7c337afefe0ea228ef9cd4908429b43a","0999cb9f10d1308564098246ecc48094e670045c","1c5441a63edfe3a0553e31a51bcb87e049c6a192","03d2efcaf662140acbafa4b0b743b17c755b2fda","8ee9cda65b4b28e002e416045c1e84f5d22e5df5"],"s2Url":"https://semanticscholar.org/paper/a3121498f5e8dc81a9209a03f13759fed67e8aa4","s2PdfUrl":"","id":"a3121498f5e8dc81a9209a03f13759fed67e8aa4","authors":[{"name":"Bo Tang","ids":["40351860"]},{"name":"Kyriakos Mouratidis","ids":["1753946"]},{"name":"Man Lung Yiu","ids":["1722082"]}],"journalName":"","paperAbstract":"In rank-aware processing, user preferences are typically represented by a numeric weight per data attribute, collectively forming a <i>weight vector</i>. The score of an option (data record) is defined as the weighted sum of its individual attributes. The highest-scoring options across a set of alternatives (dataset) are shortlisted for the user as the recommended ones. In that setting, the user input is a vector (equivalently, a point) in a <i>d</i>-dimensional preference space, where <i>d</i> is the number of data attributes. In this paper we study the problem of determining in which regions of the preference space the weight vector should lie so that a given option (<i>focal record</i>) is among the top-<i>k</i> score-wise. In effect, these regions capture all possible user profiles for which the focal record is highly preferable, and are therefore essential in market impact analysis, potential customer identification, profile-based marketing, targeted advertising, etc. We refer to our problem as <i>k-Shortlist Preference Region</i> identification (<i>k</i>SPR), and exploit its computational geometric nature to develop a framework for its efficient (and exact) processing. Using real and synthetic benchmarks, we show that our most optimized algorithm outperforms by three orders of magnitude a competitor we constructed from previous work on a different problem.","inCitations":["1d08cbe6da0910787ccba32a264c5e1ef9903e21"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064044"],"title":"Determining the Impact Regions of Competing Options in Preference Space","doi":"10.1145/3035918.3064044","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064044","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Anytime algorithm","Approximation algorithm","Best, worst and average case","Integer programming","Linear function (calculus)","Linear programming","Operand","PostgreSQL","Program optimization","Query optimization","Search engine optimization"],"journalVolume":"","journalPages":"1025-1040","pmid":"","year":2017,"outCitations":["a25f6ee864f0c4fd95d9ceb2f4868e9e3fe51786","1beac71beb44d2e3c512730ba5b1a071f1819cc2","8541e44cfdc11587a04581987a03daccddd3514a","f7991290e9555c18f5093de1d0c6c49bd1ad0bf0","12f83c83b6d87f158a95d0796f950995a0ed0297","e088aeeb77110d661a51cc76c884b2faf6914f6d","3a20575b768022e3d3f20c0b8da386086cc49c57","04e828ddaa05cccb1e5d380f4fe30b6aa36e6dfd","88ccf51bf7dc3599e8745fb73b3a5186bfdf0dc3","7c798b835099d95d8975e85d7fc38cc71a9ebb95","947671144b12e7dcd8c4e5c0776e8a3bf53a49c2","57f38687b5137c9a802b446d92059544c2eae8a0","4bca561a9bc360135bfc364b666687b0e394361b","04d025ea7122ee7396ad19ca94abffcc9f1b44a1","3f5253e95f7465624bb2a4b80ccae4337a7334d4","f5a9c3620d481236ad2ae274b0ad8672471a701c","0a256e222bc5781f5aaf31e90061fd16b8a8295c","4f69043e2f8e61bfa0392e718715544fdb4fe72c","6314d537bd96114e0be251eee445488730766880","00aa614734a26a19b09a0a3bdee2adc77bdac5e4","ca3ad75ed6d5db22c4df82200c42322ab69a03ef","bf6afd95ac71c3022ec9b0499528a86ecdb57de7","0ff91cc6eeb14ceaa9a18fcc232d28d74f757a18","0ec0ce9b04a869f7bf1a3fa5b6089da61f86f8eb","501fd14eae100042a4ad3ed58fb8b9baebc318b4","359760cb0df73b9d8e6501b5ab5ff93a6c12b44f","a10782f15d05ef101e4ec38968a0df4299a02fc9","82861f6b09ed3b91ceaed00b6d947660c9642051","e4a689ee7388f14896240fd24800882a1cbb7357","6ffcd9a1bb0ad5ec1c6925f52c8c1bd9d7ee6216","52327eecb10930640e23ef36bb7845d1a090e091","c50ca444a4aa5b701670fdee589df6668c0c10d5","280e98c45ceb53d878adbba0f8bee688c6716f7d","82ce0158c14708b01153ac0fe7d6dc9688dfbb18"],"s2Url":"https://semanticscholar.org/paper/c00238dca09bac25c7d229efcf9a29aa857b92ff","s2PdfUrl":"","id":"c00238dca09bac25c7d229efcf9a29aa857b92ff","authors":[{"name":"Immanuel Trummer","ids":["2636156"]},{"name":"Christoph Koch","ids":["3123617"]}],"journalName":"","paperAbstract":"We transform join ordering into a mixed integer linear program (MILP). This allows to address query optimization by mature MILP solver implementations that have evolved over decades and steadily improved their performance. They offer features such as anytime optimization and parallel search that are highly relevant for query optimization.\n We present a MILP formulation for searching left-deep query plans. We use sets of binary variables to represent join operands and intermediate results, operator implementation choices or the presence of interesting orders. Linear constraints restrict value assignments to the ones representing valid query plans. We approximate the cost of scan and join operations via linear functions, allowing to increase approximation precision up to arbitrary degrees. We integrated a prototypical implementation of our approach into the Postgres optimizer and compare against the original optimizer and several variants. Our experimental results are encouraging: we are able to optimize queries joining 40 tables within less than one minute of optimization time. Such query sizes are far beyond the capabilities of traditional query optimization algorithms with worst case guarantees on plan quality. Furthermore, as we use an existing solver, our optimizer implementation is small and can be integrated with low overhead.","inCitations":["68c3433dcebdbe94f1943a955012380a59feed50","306185d6b16f1ac9c770d2e2a80656cbdc1e9224"],"pdfUrls":["https://arxiv.org/pdf/1511.02071v1.pdf","http://doi.acm.org/10.1145/3035918.3064039","http://arxiv.org/pdf/1511.02071v1.pdf","http://arxiv.org/abs/1511.02071"],"title":"Solving the Join Ordering Problem via Mixed Integer Linear Programming","doi":"10.1145/3035918.3064039","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064039","venue":"SIGMOD Conference"},
{"entities":["Computer data storage","Data structure","Database","Hash table","In-memory database","Locality of reference","Query plan"],"journalVolume":"","journalPages":"1275-1289","pmid":"","year":2017,"outCitations":["1dc19048a74d9bc7564f0114dc201ffc9e77d43a","91abb4e9a7ccd81122203cc215e6a70e6231125b","24c3330d34d640945e0eb99fe4a0b1c31695a8cb","67eb4c1794be54919266f70b5bf8ba7a6824f091","92e0243e1a73c77ef8b90292e3798f765b38f269","05c30866c26648bab70bbecb0b8e2919b1b1d1b8","7e5abd1dccace3288bc214f810fedce942de68b3","daf208ad61c0ba239439ab46f1d1d4bbac5b69f0","888764f05a60d770cfc0b49944308fd92ed45ee5","0c8e7d740eb65402f7dc87da399730a15df75b33","a7a7110ca7fe9eec39f4c709920f9cad45dafb19","1619cb89bf559cb4b21c3eead6a475f33e75d9e3","3ca63ef954e07b65e67c50bdd9f443815c80fc44","4f05a78c2e2abf932915c33c6a2bb9c726ce4ac2","5d17cd9bd02396e5506b141c9e9a3bc12f9d6125","b2c28faec6f88bbfec636cf4cc10e40b04f33284","9611f849a05e5880ef90725e19eaa40d1805317d","0bde6332ca75d8fbe095e07e566ea49d810b8182","729d26e90b3404a85f56188ee8af070c70cb1e81","624f3f81b2665ccc9fbc117e7082fc6ef08ec17e","56bf17fb68d1b32838066997a888325d72eea83d","7ead08393fa2000ea03bb1cc1e3e6e0ac991aac6","3c457cec00499e41dd05516db79c4daf836102ad","363116c764453d9b740c46d23b1f5a3c5801d76e","cccbc3da776de497ca9d0dde2d4a76dc6c1b0fc4","291470e5e557ac526f79a59c83e98fbf53406401","e75c5d1b7ecd71cd9f1fdc3d07f56290517ef1e5","5c9d62f348c7ed09ee51e1d56643ced039ec1121"],"s2Url":"https://semanticscholar.org/paper/298d85920197142e2b6237c31e38936d77c80047","s2PdfUrl":"","id":"298d85920197142e2b6237c31e38936d77c80047","authors":[{"name":"Kayhan Dursun","ids":["2109345"]},{"name":"Carsten Binnig","ids":["2691974"]},{"name":"Ugur Çetintemel","ids":["2109957"]},{"name":"Tim Kraska","ids":["1746961"]}],"journalName":"","paperAbstract":"Reusing intermediates in databases to speed-up analytical query processing was studied in prior work. Existing solutions require intermediate results of individual operators to be materialized using materialization operators. However, inserting such materialization operations into a query plan not only incurs additional execution costs but also often eliminates important cache- and register-locality opportunities, resulting in even higher performance penalties. This paper studies a novel reuse model for intermediates, which caches internal physical data structures materialized during query processing (due to pipeline breakers) and externalizes them so that they become reusable for upcoming operations. We focus on hash tables, the most commonly used internal data structure in main memory databases to perform join and aggregation operations. As queries arrive, our <i>reuse-aware optimizer</i> reasons about the reuse opportunities for hash tables, employing cost models that take into account hash table statistics together with the CPU and data movement costs within the cache hierarchy. Experimental results, based on our prototype implementation, demonstrate performance gains of 2x for typical analytical workloads with no additional overhead for materializing intermediates.","inCitations":["87367fb395c509bc54ceb5d0f26b0917df55a178","18217d68fca6b1f5305c80a733a4a717e3e35052","8c7044398d1994b12a9bf7212e11398f59eaf446"],"pdfUrls":["https://arxiv.org/pdf/1608.05678.pdf","http://arxiv.org/pdf/1608.05678v1.pdf","https://arxiv.org/pdf/1608.05678v1.pdf","http://doi.acm.org/10.1145/3035918.3035957","http://arxiv.org/abs/1608.05678"],"title":"Revisiting Reuse in Main Memory Database Systems","doi":"10.1145/3035918.3035957","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035957","venue":"SIGMOD Conference"},
{"entities":["Arnold tongue","Concurrency (computer science)","Concurrency control","Database","Database transaction","Fastest","Hekaton (database)","IBM Tivoli Storage Productivity Center","In-memory database","Lock (computer science)","Multi-core processor","Multiversion concurrency control","Online transaction processing","Read-write memory","Serializability","Silo","Silo (library)","Throughput","Transaction processing","Transactions per second","Two-phase commit protocol","Two-phase locking","YCSB"],"journalVolume":"","journalPages":"21-35","pmid":"","year":2017,"outCitations":["1220e4a011c46804d4369b5580dc7fb6e387af54","979caaeaf7f0285910b571745642e930224b248e","09ecdb904eb7ae8a12d0c6c04ae531617a30eafa","13f7c5807452ae602046582a385c0fb544ec5de1","5121709bf42b13a93c70b45a456c82db92850a02","5a36f17e0560750a956064ff06b63bcd57c6145f","09ed565e84057123c15ab12b885c235d1f241aed","4ea47f63c8b2a026a66566dd3f733d45e692d369","13e6aa5f61267b2814fa9b32f47c17c0fcdef2d5","27611a1896feb8817eb9cebca344d9736916c3bb","05885dbd3ccbbe744a2ee1c39126bd263140e741","e75c5d1b7ecd71cd9f1fdc3d07f56290517ef1e5","83684cc2fddbe64f8902d1ee5d5112bf95eaeffe","7227999dfa663a2a1e0e81ee450f360e1e308ff7","023ba3dff9e17a15ae8448ec6cacc3e9a5ff116a","2e50af2320dab632d8046b6d4c130ae6cce8903f","96d197be2253f5c853edce37b59c186915160ce0","605277f87ee483cfd04f986780514c26160d2e87","35f751e46799e3a91425267819f40dce273abec1","33457f49553d918e912c2d8c54b81f4fd8a4c234","28ecdc50beb098d9176d992fed80eb2bac5963a4","09bd66ed15985caa6b0bf1d54a36b508141ed128","948c881ab7f1f62e9c940458e74c3e435320df72","62f1ec11da850fa2ffab031757d226c1fa67ecb9","861fbac82ae5ec0ea654d0d95ce4d48de62419ea","264cd229ac4bbdf655d5e7b44563bf84bd846364","10eb9cfb2cea0d6a256e436becd8f0f5494dc5a0","8665bf55084c825477cc9a6a64a0150a8d3850f7","6a10c0016bd1d4ecd7cf6ce71ba574a82eeb6d72","13875088254a585cd0b050f3bc27c1af9ada690f","4e3304e77dd2fecea4086e132981d1470434cf65","3ae8993ebc28dd9b99d415d04d2b766dc99212d9","aaf480b76674d99b95471f510a84b251ae3ecaeb","408b8d34b7467c0b25b27fdafa77ee241ce7f4c4","225603198cc415d363db8a8a2bd30b0df3c963b1","0bddbe35fa6e3cf625d15553365a690d3a6bf7aa","5a49c1c694028fd6ca7acc6af601c0f54efa0700","3d4eabc660b637cf3b52845c9a0295416c6bd093","2520cfc29a521f2333fda020d7ae41860f8dfebd","1e87a3e68bc744fc7e62b04b7c9597171e147e81","03416be8097852a54dd3e309434e5a0806824646","0997037e940df06ed7a6d19f7501579aab01e829","9aa0d7253574e50fe3a190ccd924433f048997dd","3bfa50099269ef3ce832bc7f3710ba6484165092","cc977141ecda4914987bb3d91b3d6aee603bef46","4827cc74dba0c39172554cf0116eb111797f0d1b","7129b305ce45f83127e928e8510da9fae0783905","333fbb77ada815bcfef5e93d4358084b4af2d1ec","6460e782a12649a478bbaeb9c149f59e206d9540","095a3cee30d64d3a6f22caadd58c45c5cd0b83e9","0ced2ecad932ec86aaa043f9b3ec0d9c6e88fbb5","412a9e54bbb31e12d008a9579994e009c5b40b46","56f6aec0132e56769e2036bbeff791dfa137d107"],"s2Url":"https://semanticscholar.org/paper/526ea6abf01ce4af860db2c1a34ab4690dc32a51","s2PdfUrl":"","id":"526ea6abf01ce4af860db2c1a34ab4690dc32a51","authors":[{"name":"Hyeontaek Lim","ids":["8939217"]},{"name":"Michael Kaminsky","ids":["1762920"]},{"name":"David G. Andersen","ids":["34752743"]}],"journalName":"","paperAbstract":"Multi-core in-memory databases promise high-speed online transaction processing. However, the performance of individual designs suffers when the workload characteristics miss their small sweet spot of a desired contention level, read-write ratio, record size, processing rate, and so forth.\n Cicada is a single-node multi-core in-memory transactional database with serializability. To provide high performance under diverse workloads, Cicada reduces overhead and contention at several levels of the system by leveraging optimistic and multi-version concurrency control schemes and multiple loosely synchronized clocks while mitigating their drawbacks. On the TPC-C and YCSB benchmarks, Cicada outperforms Silo, TicToc, FOEDUS, MOCC, two-phase locking, Hekaton, and ERMIA in most scenarios, achieving up to 3X higher throughput than the next fastest design. It handles up to 2.07 M TPC-C transactions per second and 56.5 M YCSB transactions per second, and scans up to 356 M records per second on a single 28-core machine.","inCitations":["612cce3e7c02c3c2b0d61528ba7c4791ba2dfaad","3315a9dafa8d338b6f6cc7a237b986a7959f4ed4"],"pdfUrls":["http://www.cs.cmu.edu/~hl/papers/cicada-sigmod2017.pdf","http://doi.acm.org/10.1145/3035918.3064015"],"title":"Cicada: Dependably Fast Multi-Core In-Memory Transactions","doi":"10.1145/3035918.3064015","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064015","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Branch misprediction","Central processing unit","Computer data storage","Database","Disjunctive normal form","Mathematical optimization","Program optimization","Random-access memory"],"journalVolume":"","journalPages":"731-744","pmid":"","year":2017,"outCitations":["04411bf945f721f5e375d478b0a2b2014d9fe4d3","20174871f7eca9bc0c99bd0aed7aa39c560f5ffa","36c17e3adaaab7262e6575588665bf44b344e8f3","09c1b69ab0fe1315b0d5e5e0b0853585c4a319b5","412a9e54bbb31e12d008a9579994e009c5b40b46","fc6f792e5c35d16c31ba9cfe5dd4f4cc08f16072","6c9189db2150e910837bf639f6da45d7da85effe","19629429a0ade02b450f5a585bdde880fd32b22b","e75c5d1b7ecd71cd9f1fdc3d07f56290517ef1e5","c57f3ab3737423a9518d0d2c64d78c195a4aac35","0997037e940df06ed7a6d19f7501579aab01e829","51f938c0fb1f7c6c0de1b10cabf246d823aa9fda","359760cb0df73b9d8e6501b5ab5ff93a6c12b44f","e8fc44a5e95f64e9181688ee387e33de32c5c634","8865ba2b6b169246ed0a1600bd7f9d447c4bd47f","44710d563b5ebeacaeb95935c58d1051cf723e8d","5046a718f92447642939f5c93414dc97225d726a","d1cd7a0fd94935d85536b839d64f0e963dcd1c10","28aaffa45781ae16658e96400813ee9eadbe459b","7ead08393fa2000ea03bb1cc1e3e6e0ac991aac6","30b1293e39c52ddd0e2a617de47c1ad843621258","14786ea73156d3273a235cff25e4cbe950d2e1c7","c2400e79ef8bd8449c5d09322d4ce412aeb3c30a","75824a5e3e36b1744dad99077d5d7e8d9578f9c2","8ff60fc4a4ca64d5e2351c6436f7d1ccdbd864f2","6ffcd9a1bb0ad5ec1c6925f52c8c1bd9d7ee6216","6383f40bcba78fb7b28e0d072a639fbe1f16e1a3","477c163092c54c27bc28bb7106a8c1afc4676dba"],"s2Url":"https://semanticscholar.org/paper/532d1d6c44ccf0413af0d5a6f0707a0fe9a92d15","s2PdfUrl":"","id":"532d1d6c44ccf0413af0d5a6f0707a0fe9a92d15","authors":[{"name":"Fisnik Kastrati","ids":["2793795"]},{"name":"Guido Moerkotte","ids":["1809585"]}],"journalName":"","paperAbstract":"Optimization of disjunctive predicates is a very challenging task which has been vastly neglected by the research community and commercial databases. In this work, we focus on the complex problem of optimizing disjunctive predicates by means of the bypass processing technique. In <i>bypass</i> processing, selection operators split the input tuple stream into two disjoint output streams: the <i>true-stream</i> with tuples that satisfy the selection predicate and the <i>false-stream</i> with tuples that do not. Bypass processing is crucial in avoiding expensive predicates whenever the outcome of the query predicate can be determined by evaluating the less expensive ones.\n In main memory databases, CPU architectural characteristics, such as the branch misprediction penalty, become a prominent cost factor which cannot be ignored. Our algorithm takes into account the branch misprediction penalty, and, in addition, it eliminates common subexpressions.\n The current literature relies on two assumptions: (1) predicate costs are assumed to be constant, (2) predicate selectivities are assumed to be independent. Since both assumptions do not hold in practice, our approach is not based on any of them.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064022"],"title":"Optimization of Disjunctive Predicates for Main Memory Column Stores","doi":"10.1145/3035918.3064022","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064022","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Approximation algorithm","Bilateral filter","Experiment","Greedy algorithm","Knapsack problem","NP (complexity)","Polynomial","Scheduling (computing)","Synthetic data","Time complexity","Ultima Ratio Regum","Value (ethics)"],"journalVolume":"","journalPages":"1197-1210","pmid":"","year":2017,"outCitations":["7d7658ad5b65f1438ba7e8217c72565fc89fa6c1","12bcd428a4d47a9f3c775d84e9d73033740f8bd6","5420175febf6d9d94e6d4967cf06a6a74e5b3f12","57bc59cbb94711a7945e2d8984e4e9afd49e1849","14836d573c94dc8db699cd3f0a08373c50d73fc2","4d6ea75cc13599cedb03f6a606d6154a8f424074","3b2fc7d952bd2a0dafdbf4e13617d70581e7955d","fed4ffd31ccb68162ff52d5ad97f92dfc0e558ea","18a7403cce25ab6351193ca43a5b1020ca8a69cf","1146a1fb2a35880d205160ad62511194505cc3f7","7909dc85b5d3016100bd6cba675f70de3a5e9413","118ccb22e4ffed2259f661013c3d1d626c85db17","e392f3143c86ec40b20b5b4a5a29cf209f2572e8","24c48b97725d84246f6dbd39c055648a305e1df4","a3c0a1617f640339350358745106fff590130a45","49bfad37cb0c2d82b85fa3c4cb333767ac5c49a6","1e58e490a84e5526258b43818e5b5e0dfb27852a","6bf018c9ce81b17834c8573888340000322e7650","5c6e4bba1ca3071d24bdffea78d441e0a4afb895","78b4271480ba3b143022773b9e9b5e2342db41dc","06501b7ea604a8b8ffff402ee492955e6892daad","7cbb5c100298818e260bed8a5996918a612e3545","14d73480e38599a6997a37d871353e92c71e9503","57236a1873e831e2442ec4cc2106c692c35432bb"],"s2Url":"https://semanticscholar.org/paper/8f2e0440ab4d1d9ebad2b7d4103b6609a93a92b9","s2PdfUrl":"","id":"8f2e0440ab4d1d9ebad2b7d4103b6609a93a92b9","authors":[{"name":"Peng Cheng","ids":["40129231"]},{"name":"Hao Xin","ids":["1850222"]},{"name":"Lei Chen","ids":["37833805"]}],"journalName":"","paperAbstract":"Ridesharing enables drivers to share any empty seats in their vehicles with riders to improve the efficiency of transportation for the benefit of both drivers and riders. Different from existing studies in ridesharing that focus on minimizing the travel costs of vehicles, we consider that the satisfaction of riders (the utility values) is more important nowadays. Thus, we formulate the problem of utility-aware ridesharing on road networks (URR) with the goal of providing the optimal rider schedules for vehicles to maximize the overall utility, subject to spatial-temporal and capacity constraints. To assign a new rider to a given vehicle, we propose an efficient algorithm with a minimum increase in travel cost without reordering the existing schedule of the vehicle. We prove that the URR problem is NP-hard by reducing it from the 0-1 Knapsack problem and it is unlikely to be approximated within any constant factor in polynomial time through a reduction from the DENS k-SUBGRAPH problem. Therefore, we propose three efficient approximate algorithms, including a bilateral arrangement algorithm, an efficient greedy algorithm and a grouping-based scheduling algorithm, to assign riders to suitable vehicles with a high overall utility. Through extensive experiments, we demonstrate the efficiency and effectiveness of our URR approaches on both real and synthetic data sets.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064008"],"title":"Utility-Aware Ridesharing on Road Networks","doi":"10.1145/3035918.3064008","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064008","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Cluster analysis","Computation","DBSCAN","Experiment","Image noise","Requirement","Time complexity"],"journalVolume":"","journalPages":"1095-1102","pmid":"","year":2010,"outCitations":["7d59fad9d141684981ba1e89a4f9bd9fdfdf507f","13a375a84a6c414b85477a401541d3e28db1e11a","174a03c3c6c8c3c432a40e7df00cc708136dc65f","0015f23c7af9744488e6787a35c258f07f746cda","0bcadae1786453e45985b656aab45b4b461cb8a4","c70150b4fae4ccba0c48d4f17e8813c00a12b1d7","9723d56c5baae023b0084b0960be8dabd1df94f6","26f178dbb00630ce19cccb9840ea12dbe31801be","07f42bea1b07370c5ee4f0930ea6bf2d7bb4b0ee","e0902669a15b62c80abac73ad75afbd3a241256a","06faa4bbe958e43abb6cef9d4eaacf4302dd84cb","0db3841e12bd2dae3665c4b4280cb77294fd4c77","8bdca6121b359cbbf6566e5a036741b572db37d1","502ff2f9220ebc8c3544e6c4a005e819429ab716","58925078fdb206ef7e52c8c74ec4afef891fee4c","1e6f2c91d5837014cf99fd7c5fd5266f550c53bc","18974d0a102cdae99e303136bd8244ffefbcc3c7","768da90eb300023dc625b2808b366d9b648b0dbb","841fd6f8bde07f44363b95aa4f11560d9c3405be","05b27b2a8d73efe8dc70eb8560aaf10b370ba8c0","0356b8a2de1f9400000b12e48ae8a29642b5c259","53963ddf21162bc423018505860285b4b14bb00b","0ce9d60656163eabd375825b5267265f7ff3d0c9","34b8d68087a2f7b7fe64046d6fac84b87da10e8f","02b43b7ee488f7f468756c8483f2a4b93279b4fb","2cb6f969fa99a3c33560e9f3d87beaa7aab9d9cf","51981872c69020ca35ae2955e70877a4f1f13923"],"s2Url":"https://semanticscholar.org/paper/3354469d76a236e11d1b57c05fb225f31cd67f13","s2PdfUrl":"","id":"3354469d76a236e11d1b57c05fb225f31cd67f13","authors":[{"name":"James Rosswog","ids":["2721280"]},{"name":"Kanad Ghose","ids":["9427707"]}],"journalName":"","paperAbstract":"We address the problem of detecting and tracking clusters of moving objects in very noisy environments. Monitoring a crowded football stadium for small groups of individuals acting suspiciously is an example of one such environment. In this scenario the vast majority of individuals are not part of suspicious groups and are considered noise. Existing spatio-temporal clustering algorithms are either incapable of detecting small clusters in extreme noise, or have high computation and storage requirements that prohibit their use in real-time alerting systems. We propose a technique called Dynamic Density Based Clustering (DDBC) that utilizes the relational history of the moving objects to increase the accuracy of the clustering algorithm. The incorporation of this information into the clustering algorithm is done efficiently and <b>implicitly</b> by using a relationship graph. The relationship graph incrementally estimates the strength of the relationships between moving objects. A modified DBSCAN algorithm is then used to find clusters of highly related objects from the relationship graph. We evaluate the DDBC technique experimentally on a number of data sets of mobile objects. The experiments show that DDBC outperforms both Trajectory Mining and Moving Cluster Mining techniques in terms of accuracy, memory usage, and computation time as the density of noise increases.","inCitations":["c901058e63aabf5dd2ec4a31356c3a62500ad933","ea69efb7850cc55fdfed88ad97d94e9a73d370d3","2350dc2a11185f61bbb4994b13a10dbd1ebf2a1a","020e0191aeaaf4d6c0737c1aaffd9f236e0ca3f7","bce3f9cd7049fd4a97de0665433c13b2b56a84d3","aaf7b62417b836ec0e0f51982eabfc574b1aa1a6","b3257a1637f8c0f49b900b129d141765f88a15f4","841510c01a13e946f968b17dca37ef205802fefb"],"pdfUrls":["http://doi.acm.org/10.1145/1774088.1774315"],"title":"Efficiently detecting clusters of mobile objects in the presence of dense noise","doi":"10.1145/1774088.1774315","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/1774088.1774315","venue":"SAC"},
{"entities":["Algorithm","Computer graphics","Data mining","Distance oracle","Feature vector","Global Positioning System","Oracle Database","Point of interest","Range query (data structures)"],"journalVolume":"","journalPages":"1211-1226","pmid":"","year":2017,"outCitations":["951a09c6e31a17d4b83a908372d0a642f6b6a9ee","31181e73befea410e25de462eccd0e74ba8fea0b","ab74affabf77921f73a426ad8d61020ec5487207","3388daf515b52422896037610b19abc370d8c4e2","068e0817389cdbaecb1187e4f2eabc4651b773a0","dd01c381a8099144d69909e1fc17186609404654","c300bfd4c601ca2191f659f4cb560f811d44ac41","55fe938af5b3240caa6c5e985b1ace41f6649f02","bc94a8e5010782d61c5a0ae86f00ca3b172c0aa9","323c12b895ace6ddedf9d7a2884e77183bafc7dc","810dbfe47634574fae7af51a85c65f2e10a28080","5349aff5d92f253b871140aac9de7df78ee7ccf2","986f26db95b08b3eef6bae78ea39407f15a16f79","21754342e13272ee907f4687643c2ad7014d6afb","694d2eba0a5da7abf2837a02a1ead60e41ea7202","024c07ef0f70b044f5a38e22865d517bf02ce74f","5f256003eb6519c3c7d7fb859944b860cd86ae6c","672d76423acd2c2c5e76f0162535f880974265a7","48c1cbd9b7c059f5f585c003b68ad1ec32606d41","20cf48240b89bd522beff22a0cf0c8cd5b2f8abf","335abaf408273c21f52b37a801dcd46cf2bbfb56","676434190e54c2bf80b5931d34448f3ca34b892e","e3d2b4dbcd078db08b0b98dd077511149a8febf9","12684752e1487643d849108fc82b7809d900e334","f975f7a10ae8a82e8fd5a7a4a79ef4d59c8752b3","c075149029023e5547ef3f8abf66db9397b19a06","4f4d5460640a7b4a6bef97736f622e3ea608ec1a","138f5f716990245dea973df5bd4c70e4767742d7","07662991ff16875b89b9ef80db1834fca02d7e0d","ed3fe19771dc38d5142cc88bce1fcbba53352840","07062a50d8bbb7318bd8840d322873b10082ce9c","b7449194b22fb27f90f7587c966fb30cf3f6e796"],"s2Url":"https://semanticscholar.org/paper/4d17ad72e7ec8159064662a70f8356c039537b86","s2PdfUrl":"","id":"4d17ad72e7ec8159064662a70f8356c039537b86","authors":[{"name":"Victor Junqiu Wei","ids":["10762356"]},{"name":"Raymond Chi-Wing Wong","ids":["1723745"]},{"name":"Cheng Long","ids":["1709267"]},{"name":"David M. Mount","ids":["1709509"]}],"journalName":"","paperAbstract":"Due to the advance of the geo-spatial positioning and the computer graphics technology, digital terrain data become more and more popular nowadays. Query processing on terrain data has attracted considerable attention from both the academic community and the industry community. One fundamental and important query is the shortest distance query and many other applications such as proximity queries (including nearest neighbor queries and range queries), 3D object feature vector construction and 3D object data mining are built based on the result of the shortest distance query. In this paper, we study the shortest distance query which is to find the shortest distance between a point-of-interest and another point-of-interest on the surface of the terrain due to a variety of applications. As observed by existing studies, computing the exact shortest distance is very expensive. Some existing studies proposed &#949;-approximate distance oracles where &#949; is a non-negative real number and is an error parameter. However, the best-known algorithm has a large oracle construction time, a large oracle size and a large distance query time. Motivated by this, we propose a novel &#949;-approximate distance oracle called the <i>Space Efficient distance oracle (SE)</i> which has a small oracle construction time, a small oracle size and a small distance query time due to its compactness storing concise information about pairwise distances between any two points-of-interest. Our experimental results show that the oracle construction time, the oracle size and the distance query time of <i>SE</i> are up to two orders of magnitude, up to 3 orders of magnitude and up to 5 orders of magnitude faster than the best-known algorithm.","inCitations":[],"pdfUrls":["https://cs.umd.edu/users/mount/Papers/sigmod-2017-dist-oracle.pdf","http://www.cse.ust.hk/~raywong/paper/sigmod17-ProximityTerrain.pdf","http://doi.acm.org/10.1145/3035918.3064038"],"title":"Distance Oracle on Terrain Surface","doi":"10.1145/3035918.3064038","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064038","venue":"SIGMOD Conference"},
{"entities":["Analysis of algorithms","Array data structure","Database","Deployment environment","Heuristic","Pipeline (computing)"],"journalVolume":"","journalPages":"139-154","pmid":"","year":2017,"outCitations":["12b6044216d1a0849d74d1a7258619279027e8fc","d0bc3c139c9a0129a87aa5f724e7bf82b4b04ce6","1c1266008ad7ba6ae42a6c29964616db08193f42","49c9b55fe6998f51705d824e36ab2b093b9aa552","eaf2bccd82bf4cffcf1ef85487d6722f6a04716c","0af1d9eb0c04296b9f6336ae5ee66ed4ac735e53","d6342d37c3c670b20a52f10ad9538665debb5636","a6cf03c9d151ec6ea6bc2d9df4144948d67a537e","03ab9ddbb8701ec42c2ef13c51be0e857f121318","3f419db6f66c32bbb7ea887b139abd4e088a0405","1948575f4cedf689f708d1f0880e79de9ec4c4a5","0d356d3b790477a5428ec5fb8b5d3e898f549866","3c4776e5f96ebe8a6de1a855f523a28c687eb994","01180b69272486a66ebd2c46af9383191a38276b","251cf2745297e77435a17f2c15bf6359d3c57ef7","9cedf29b81c0cf9f568d70887a5af63e9bdf66cf","129d3d09e2b2cee69f19e3a8cb91d40b19e29557","d68a46d4627ba8766906800101715bfb79069341","370e1fcea7074072fe5946d3e728affd582a9a44","ab9b4a7054f2583d6298954af451126da5c77632","aae20add6de2f5bb30de6f230fab9112cb50540e","2ba9612cbb2eeee9b4267639af3ba7a808b774fe","bc5c4c91d3de210a2120be1b7f2e4d0f229cad8a","53edf8302b72dc2bdbc878c07f623586853e67d0","7ec028ace29244cb74c105327a7e4177a34aa6bd","0d9b6fc89b06a311f35511c12cd70d97f8fa9196","2321a150c84d771d81fd81759757795dcda25750","09a9a0fc511ae93f3373dfb98f6e2d5d02ee0957","9d62a4187b126111aef25a10e6691df9ca66835f","3851430bb53b09f78880bb3480f835c22ca81a94","7982bdb498c5efeafddd2ffaf9810a7f0712f162","11e512701c7a2a5cd48d5435e8d42f292161ceca","62fc7ff2abfb026aa4353712f3819cdd8b7e24bb","490f0881f2d922a13644572540e2b0558a717499","11f17b63b6742495177ef2194d2be11d98dc8b8c","8d4178d4e62950b13121279a75f80141285e1cad","0c97fa96d179dec4f5a9349c4e5203205d427fb8","277cc859f07728aef42b6708a98b296284598590","318a9d14077d581fd6c23eec2e11c8b62db57265","05a26b5deeed6f6f7e9584555b73c5af3905063b","14c0c9ba3e69846db02a6a3df1ef8e99149aa978","25ac757c975185450da0b49530df3c1471ebc6b0","18209a97ce6996bdeb09b3329e3865af2a49c9b9","762756eba9168421d338f0aedd04e0111ca75462","4563b8386aee41e0575ef6529ee0385839f06c6f","59ea6b535d9e462ef01fe34b4576252943257870","24679ccb0586642553a21e9fcd8aa5a57f97cabe","4dbb40052b3170c3871335550f0506b9ebea6acd"],"s2Url":"https://semanticscholar.org/paper/5fe578eef61426a093b982de7bee0253c9c82265","s2PdfUrl":"","id":"5fe578eef61426a093b982de7bee0253c9c82265","authors":[{"name":"Weijie Zhao","ids":["3083209"]},{"name":"Florin Rusu","ids":["2289824"]},{"name":"Bin Dong","ids":["39131579"]},{"name":"Kesheng Wu","ids":["1773743"]},{"name":"Peter Nugent","ids":["32645680"]}],"journalName":"","paperAbstract":"Science applications are producing an ever-increasing volume of multi-dimensional data that are mainly processed with distributed array databases. These raw arrays are ``cooked'' into derived data products using complex pipelines that are time-consuming. As a result, derived data products are released infrequently and become stale soon thereafter. In this paper, we introduce materialized array views as a database construct for scientific data products. We model the ``cooking'' process as incremental view maintenance with batch updates and give a three-stage heuristic that finds effective update plans. Moreover, the heuristic repartitions the array and the view continuously based on a window of past updates as a side-effect of view maintenance without overhead. We design an analytical cost model for integrating materialized array views in queries. A thorough experimental evaluation confirms that the proposed techniques are able to incrementally maintain a real astronomical data product in a production environment.","inCitations":["0a424fcdcfd55ff0f80a193848547b5e5f434614","4c6f4328f5e0b3474dc611f2e55f7d44c7a577dc"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064041","http://faculty.ucmerced.edu/frusu/Papers/Conference/2017-sigmod-array-views.pdf","http://faculty.ucmerced.edu/frusu/Talks/2017-05-sigmod-array-views.pdf","http://faculty.ucmerced.edu/frusu/Papers/Poster/2017-04-norcaldb-array-view.pdf"],"title":"Incremental View Maintenance over Array Data","doi":"10.1145/3035918.3064041","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064041","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Login","Multi-armed bandit","Positive feedback","Social network","Thompson sampling"],"journalVolume":"","journalPages":"851-865","pmid":"","year":2017,"outCitations":["05da530858a790fdc71dc6d54c445555d0be9d48","4b83b18ecbb46a0e03b1cf7009c7f2244a729f66","454fd57b4ec44780198d786e28a74b9d72610f1a","e95db95b7b4e0552e3133f9b878d4977f92bd9df","3ef959ddbee41a976256fc604204c47ad313d164","248b5910f543e204e92789a507a2067f58b537b2","012c5167ca8732b47cd99ba879808718cb81df5b","3d4cc9ab7d0f31cec262938e687b01612d9a8e94","8d23410f5e3b8cc3235e13b0b7b04d177b107081","7807a5aadf3cc187b38f7a399f5700ea2d08b760","475304672319c1737a4e13b7c58701ce4086bb54","a0d1e0214565b6eaff4b454ebcb9336466278f2a","130b0cac6151e414b5bc0eb13cb02bf43ee66c11","14487f261dfdbb2dea70fa90e7789ded6b128356","103f6fe35033f9327611ddafde74a2b544072980","2fa7c63ee5484c688e8ec62846ed7137c4924607","572379c1d56e7e19422ae38218ee228c61aefb2f"],"s2Url":"https://semanticscholar.org/paper/3162f956caffd1751dfdda1ddef546b588f6393b","s2PdfUrl":"","id":"3162f956caffd1751dfdda1ddef546b588f6393b","authors":[{"name":"Jieying She","ids":["1872111"]},{"name":"Yongxin Tong","ids":["8230559"]},{"name":"Lei Chen","ids":["37833805"]},{"name":"Tianshu Song","ids":["3406090"]}],"journalName":"","paperAbstract":"Online event-based social networks (EBSNs) and studies on global event-participant arrangement strategies for EBSNs are becoming popular recently. Existing works measure satisfaction of an arrangement by a linear combination of few factors, weights of which are predefined and fixed, and do not allow users to provide feedbacks on whether accepting the arrangement or not. Besides, most of them only consider offline scenarios, where full information of users is known in advance. However, on real-world EBSN platforms, users can dynamically log in the platform and register for events on a first come, first served basis. In other words, online scenarios of event-participant arrangement strategies should be considered. In this work, we study a new event-participant arrangement strategy for online scenarios, the Feedback-Aware Social Event-participant Arrangement (FASEA) problem, where satisfaction scores of an arrangement are learned adaptively and users can choose to accept or reject the arranged events. Particularly, we model the problem as a contextual combinatorial bandit setting and use efficient and effective algorithms to solve the problem. The effectiveness and efficiency of the solutions are evaluated with extensive experimental studies and our findings indicate that the state-of-the-art Thompson Sampling that is reported to work well under basic multi-armed bandit does not perform well under FASEA.","inCitations":["20677673ca4d660298f236760b9568902a6a8117"],"pdfUrls":["http://www.cse.ust.hk/~yxtong/feedback_sigmod17.pdf","http://doi.acm.org/10.1145/3035918.3064020"],"title":"Feedback-Aware Social Event-Participant Arrangement","doi":"10.1145/3035918.3064020","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064020","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Approximation theory","Bell test experiments","Computation","Expectation–maximization algorithm","Graph reduction","Line graph","Scalability","Simulation","Social network","Time complexity"],"journalVolume":"","journalPages":"635-650","pmid":"","year":2017,"outCitations":["130271241a3718323e439440d897ec26acfebf06","420a0e5fc398f197bca3dfe40291a82b2c65655a","706c83309fa09454a136d4e607364b27be66172c","03231c89ecfd4790914bba49f188ac5ce69230f1","4cd73382dc17561cd276f276c61d5ebf39bf69ad","3dd577a7e4a48f4cec07dbf378269931bb5235bd","6a5ae0e083ab69153ce395874c8dddcd830dfcfd","abb152802d5b4686a394e221abe951187ea06158","480b1e3419d38363604016a2746f3f9b3bdc7de6","51ea20dc4f688af41f9840a854d15bac49db1be6","4dc578364f357b993b5554b9181c90c84aa6b4d1","6a3146b4f60e66a3aaa06842e747099f5c735510","5c8a66d49a3e7a294706b412804c07467dbc906c","b790f9ae49cdee5354eacfc7897ab9752acd5e2a","385742fffcf113656f0d3cf6c06ef95cb8439dc6","048a42699d9991ec18b34bdb484ef244830e1d71","712485b1dca37377a4b94cdd814b04f73df23ecd","b9e43395663f74c581982e9ca97a0d7057a0008c","d538c50907e9b936150d00e1205ac9a0b3dffd9a","737e43bd36ac3cc785915fa2930997976137ef35","d1a7ec5b32601f15b0fcf6021e36b7193fe09e63","4f4e1fab4ae110423e0c1236fcf5ffd35a2845fb","50d3bd1ea64259d6de6a5a1fc9f4bc6b45d6f502","28bf0df09f97e7ef9108e71b45fe1b9a7aa201e2","0fedb3f3459bb591c3c2e30beb7dd0a9d3af3bcc","34affc64b7f26520fbb96db3d87d177c831cc21b","23d85a0008429845870780c6db3640c05165acaf","141004dee9e799b40bfaf50b4a72618613137250","d7f9c3253552e13f24c3b73bc055ef60388af57c","4de0edf82aa7a5158dcca157eb9777545a989947","a6d73877be2b91e8b6c9c0896e58942c93086ff8","376ead26a0e0a87ea9a177fc683b0bedf161fbd9","98a401d55dc8089eed37e016074d048e178c67c7","1f559f2eb174d05a912b2ec39a48eadfd0160b74","4bb0f607c1f6be38ca720ad6913577a778cc2f15","460a9dbc3bc1434d1999362427f70e96be741b08","21968ae000669eb4cf03718a0d97e23a6bf75926","cf8ac5240c023c0196b36ee8af030eb000c0d6b6","9d974bff46b6a4a5a889a30ac37a5fce2c5b634d","15013a2155c9295103d836166bc3c944f90cbf07","233084c0d1c818c842be6a9bb50f5dd2d1d1682f","2d49ad12e22313a82e7f14dd41efe20ecd5daf43","20c88e23020ea3c42e640f8ae3dc2a1f8569892d","35a156f757466dbc686e4c75290383443b8efe90","35fc15f9ed1b249145ccd1e928bae4a25ff0df67"],"s2Url":"https://semanticscholar.org/paper/b793a7f8a934b6f67949b1b46b32c930c840fdc2","s2PdfUrl":"","id":"b793a7f8a934b6f67949b1b46b32c930c840fdc2","authors":[{"name":"Naoto Ohsaka","ids":["2628935"]},{"name":"Tomohiro Sonobe","ids":["2811963"]},{"name":"Sumio Fujita","ids":["33208854"]},{"name":"Ken-ichi Kawarabayashi","ids":["1743527"]}],"journalName":"","paperAbstract":"Fueled by the increasing popularity of online social networks, social influence analysis has attracted a great deal of research attention in the past decade. The diffusion process is often modeled using <i>influence graphs</i>, and there has been a line of research that involves algorithmic problems in influence graphs. However, the vast size of today's real-world networks raises a serious issue with regard to computational efficiency.\n In this paper, we propose a new algorithm for reducing influence graphs. Given an input influence graph, the proposed algorithm produces a vertex-weighted influence graph, which is compact and approximates the diffusion properties of the input graph. The central strategy of influence graph reduction is <i>coarsening</i>, which has the potential to greatly reduce the number of edges by merging a vertex set into a single weighted vertex. We provide two implementations; a <i>speed-oriented</i> implementation which runs in <i>linear time</i> with <i>linear space</i> and a <i>scalability-oriented</i> implementation which runs in practically <i>linear time</i> with <i>sublinear space</i>. Further, we present general frameworks using our compact graphs that accelerate existing algorithms for <i>influence maximization</i> and <i>influence estimation</i> problems, which are motivated by practical applications, such as viral marketing. Using these frameworks, we can quickly obtain solutions that have accuracy guarantees under a reasonable assumption. Experiments with real-world networks demonstrate that the proposed algorithm can scale to billion-edge graphs and reduce the graph size to up to 4%. In addition, our influence maximization framework achieves four times speed-up of a state-of-the-art <i>D-SSA</i> algorithm, and our influence estimation framework cuts down the computation time of a simulation-based method to 3.5%.","inCitations":["a31964b8281008ad2611845654462240e9688a89","1d94c13b1911b9f0269769089faed868d4e9bbd6"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064045"],"title":"Coarsening Massive Influence Networks for Scalable Diffusion Analysis","doi":"10.1145/3035918.3064045","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064045","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Computation","Dynamic problem (algorithms)","Graph traversal","Incremental computing","Incremental search","Pattern matching","Polynomial","Real life","Search algorithm","Undo"],"journalVolume":"","journalPages":"155-169","pmid":"","year":2017,"outCitations":["56974d490966a9d4f5c28f8be37fc34a08256388","23621097458ef14730bdf01c22b2b7a869c26d8e","04bd9aa1c56056d6ac4cf560de60d198e2094c62","68d3ada8bc4fb3de685cb870d9e72853d56b5c7d","87b7f6f406259c03b96412bbecde9711a9b8fccf","08b1a03f8e1e80273cdfe8d5049d6034177efdca","0af1d9eb0c04296b9f6336ae5ee66ed4ac735e53","38e2d3218a63c81f850fe6cc48743cd0c8099561","2b9798550d7fdec148b21c6a190bd73d7c3bb4c6","59a6fa9ef3841302aef0efb17d46579841b80031","19aaf29ead773187824695f3dcdae028ed917967","5599ed5b57958b32889c9f4f6c9261941ce2e79f","0b43a0626314c092acdb66181a839efd01b54139","6f53dbfe291a90ce168b3bea709cb0a4df8a0312","064f9e6f1db223cc761c7a98126b9337b833a9e9","081a8373c4ad9fda1d3aa9f86db48f7cbf0ac96f","0456a5c3b2001465d05e84ce6786ef200184de65","87507a498558ed6ed23115a42f42376c0884f7f2","0990405c5642e93e22e28a302935bdd2b08bd11c","182040ed27e6c9461a163fc6bff749a9687b2114","ab20b24788cbbeab7d32e6d47aacf1afffe63396","74737c472e6ba4fef759887753ab73146f96d0f2","167283803961a7216e349d27bcbfb4ee377393c8","385742fffcf113656f0d3cf6c06ef95cb8439dc6","4ffce047b0189e30e51665f0c8872d05f383a962","9da28672b71b658b8ea989e2bfc502582a79e079","be94c5051438209816397be214ee8c1bdda94165","d381f9a7234fcfb57c2f615e5c99cc7362ab60c9","04226c2c505cddbf760ba15aebb66e1685c41343","3de0169f727f8ec758d52774ec45f4c0b96bffe8","3ba66b7716d2f93ae39b2bb79427038e449f5a7c","55efcebcaaebe1765e788db748cab9342671561b","3b034ee536cbf8c0152c8eae29b74a821d958976","b8497f9088ae74a13ca498e7ecf68af8ad18e373","6099814c55861b15467d26010631124bea5dfbda","75e217284d18901ce8b1fc4a389d3c1152b544fb","46805903a8757bf4ae81a0f80cd14cc3a1423d54","54b00856c79b67e0e255952cc16c82974248dc82","628b470c664be4eaf9ae3f75ecb630d64353bc4c","18f59797fb675ae928e1c5a3af5006b44bfa28d8"],"s2Url":"https://semanticscholar.org/paper/3cabd75d1fcbc1ffeddad121cee327abf4223d49","s2PdfUrl":"","id":"3cabd75d1fcbc1ffeddad121cee327abf4223d49","authors":[{"name":"Wenfei Fan","ids":["1777183"]},{"name":"Chunming Hu","ids":["1767378"]},{"name":"Chao Tian","ids":["1692159"]}],"journalName":"","paperAbstract":"The incremental problem for a class Q of graph queries aims to compute, given a query <i>Q</i> in 'Q, graph <i>G</i>, output <i>Q(G)</i> and updates &#916; <i>G</i> to <i>G</i> as input, changes &#916; <i>O</i> to <i>Q(G)</i> such that <i>Q</i>(<i>G</i> &#8853; &#916; <i>G</i>) = <i>Q</i>(<i>G</i>) &#8853; &#916; <i>O</i>. It is called <i>bounded</i> if its cost can be expressed as a polynomial function in the sizes of <i>Q</i>, &#916; <i>G</i> and &#916; <i>O</i>. It is to reduce computations on possibly big <i>G</i> to small &#916; <i>G</i> and &#916; <i>O</i>. No matter how desirable, however, our first results are negative: for common graph queries such as graph traversal, connectivity, keyword search and pattern matching, their incremental problems are unbounded.\n In light of the negative results, we propose two characterizations for the effectiveness of incremental computation: (a) <i>localizable</i>, if its cost is decided by small neighbors of nodes in &#916; <i>G</i> instead of the entire <i>G</i>; and (b) <i>bounded relative</i> to a batch algorithm <i>T</i>, if the cost is determined by the sizes of &#916; <i>G</i> and changes to the affected area that is necessarily checked by <i>T</i>. We show that the incremental computations above are either localizable or relatively bounded, by providing corresponding incremental algorithms. That is, we can either reduce the incremental computations on big graphs to small data, or incrementalize batch algorithms by minimizing unnecessary recomputation. Using real-life graphs, we experimentally verify the effectiveness of our algorithms.","inCitations":["68d3ada8bc4fb3de685cb870d9e72853d56b5c7d","24c0e93c284487857c7d0efd83411036291ec812","771610413f3654b8e4f38aab4dd970a481c7196f"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035944"],"title":"Incremental Graph Computations: Doable and Undoable","doi":"10.1145/3035918.3035944","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035944","venue":"SIGMOD Conference"},
{"entities":["Amazon Mechanical Turk","Crowdsourcing","The Turk"],"journalVolume":"","journalPages":"1447-1462","pmid":"","year":2017,"outCitations":["6c3c36fbc2cf24baf2301e80da57ed68cab97cd6","761115e9b9564f7ad1f5ca8fe531fabcad7dfbea","371fc532e70dc5a72c49eb3503ae1f707f38ea7d","04f39720b9b20f8ab990228ae3fe4f473e750fe3","6953420c593842697dd09bc2cf7ffbbaf67a6e8e","53ced1bf79a5ff0db025fee76a67a33f37e4286d","1ed3aea4af6986e5f5fc9fc4d596681bf10a9e67","7ac5425b837a5e889847afdaf04c0241b9b0b4ba","6ac7262028d905ad97bbabce37c610e5d84e4c6f","8d4594b4d4827f44b57863376d54536112b7aaca","ba24bd33caaa38127664f86d1bb486ac508b8a47","060bdc422872e375bbef9b1cd82fbf0f936d4691","74b42722aab4eea20f86a9fc6229e55db618e568","0cfec22c458e7ce41709dc07cc1408f9184bba7a","0aaa7e6b5fcd526f9e217dfa0133d338cca297d5","7783fd2984ac139194d21c10bd83b4c9764826a3","8a0b267493ac9510e47ceb4bcebb6d202b2f89a5","7bbdb1803788a0e0cf8b814ed12a8f87e544b6ec","b5e3beb791cc17cdaf131d5cca6ceb796226d832","7e402f75d09b2de259e14e07cdb88d40e3128e7c","22f516acc61967369ec29d4121c7b517d5f60e08","02df9340e08e1e5085f1257bb6ddda4cd225e1d3","f5d9c0182d8578f7c0a99ad9bdd4ff62e5f7c68d","40c6e880da4fa9d3266e2ce60342b20a1eca106e","743a4a699ef01786a7321291ff8ca94b7bde7780","71b76a4de9b1364be2905278b69e0912c5f70b3a","1456c5b5676f1353f0e2f794eef995bc10759682","ddff18418de90e64e2a56580ac2507a4322c59e9","307192581628f00315df9e088dca7cafc8f4f38e","79f9e562470ea00d1bba08fd1fba8cc46d96f211","151673abe01271dc3fc37725c02e95e7970f3bed","0c93701fdffd928cf1725e1ca3286bd031bcfeef","88cd4becf3587a8378e450a99ded801fbdb264e1","a84f8b5f6fc5af05564353e2fa5d456e34059aa0","ae1a0331abf71a21205d4c4971db30ab59f5f473","cb035d8eb21dd6641234c1120fff570cf93bac76","526ece284aacc3ab8e3d4e839a9512dbbd27867b","83b5d51ab2f0c526dbe640f3b3d9b3b257658dc8","1a7651308dbbdf91ccf07886b016b5fa8678fd27"],"s2Url":"https://semanticscholar.org/paper/09dcfd29a20858cc11866778afdf53da4cb6459b","s2PdfUrl":"","id":"09dcfd29a20858cc11866778afdf53da4cb6459b","authors":[{"name":"Asif R. Khan","ids":["38152002"]},{"name":"Hector Garcia-Molina","ids":["1695250"]}],"journalName":"","paperAbstract":"In this paper, we present CrowdDQS, a system that uses the most recent set of crowdsourced voting evidence to dynamically issue questions to workers on Amazon Mechanical Turk (AMT). CrowdDQS posts all questions to AMT in a single batch, but delays the decision of the exact question to issue a worker until the last moment, concentrating votes on uncertain questions to maximize accuracy. Unlike previous works, CrowdDQS also (1) optionally can decide when it is more beneficial to issue gold standard questions with known answers than to solicit new votes (both can help us estimate worker accuracy, but gold standard questions provide a less noisy estimate of worker accuracy at the expense of not obtaining new votes), (2) estimates worker accuracies in real-time even with limited evidence (with or without gold standard questions), and (3) infers the distribution of worker skill levels to actively block poor workers. We deploy our system live on AMT to over 1000 crowdworkers, and find that CrowdDQS can accurately answer questions using up to <b>6x fewer votes</b> than standard approaches. We also find there are many non-obvious practical challenges involved in deploying such a system seamlessly to crowdworkers, and discuss techniques to overcome these challenges.","inCitations":["0bcb4ab04e1ebabbf67a38bd7b20b8c660018add"],"pdfUrls":["http://ilpubs.stanford.edu:8090/1152/1/CrowdDQS_032117.pdf","http://doi.acm.org/10.1145/3035918.3064055","http://ilpubs.stanford.edu:8090/1148/2/CrowdDQS_11112016.pdf"],"title":"CrowdDQS: Dynamic Question Selection in Crowdsourcing Systems","doi":"10.1145/3035918.3064055","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064055","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Bioinformatics","Bioinformatics","Biological network","Database","Experiment","Gene regulatory network","Hoc (programming language)","Microarray","Network analysis (electrical circuits)","Synthetic data"],"journalVolume":"","journalPages":"359-373","pmid":"","year":2017,"outCitations":["20b5fc20821968a2e990183ee4613c591951597c","3a19613b19af47305a73d35830773bef47e606ed","774db16a3f25a73ceda9e6ab4d5a8b8f3c40605d","11e77315e127fa7196173cfa8296ebe0de83f026","36c0b81a2ef2505e5c1c763c1abc25cdd72903f2","36898244a91ddbae7bece6aad471889c0f2a2c83","786a1ef5a7aebc0b50767802a0ef73c20838b6c0","1e7c43bff2a19aeecab9ec0871e527ebb0a38f09","262fe7be566e77c22ca09ee7b48201075d548293","5198b8b18713f831e321b3b9ac9bbb21c9a03e86","fe1fa4d0d0fcc0dee27f203a5ecf49debe94945e","0d557c7a7d6b50c3ccdb6a9f48e4c552541f5930","ded1ab521c9839145040cb45c1f0c353536de8d5","023d91d9a451523b550c60f12490d832e313b08f","a80df730dbe0f90c752a9a4411bb4e4f375fda1d","37af9a2655a6ecddfda65be1fbcf7ddd43e21446","3fe077f1aba99d12c48c2b60de4736a65bff771c","11fc1be0025f006a41304a1c2973358483c860e6","26096f25cc8ebfefd71194644fa9fe7ae84f9b74","362922ae8ce306b8f3fc3465072dd703b8bd5edb","92e6e67b81528c2c4e1b70803847907d6b251ecd","17ae114d87f8483f4cb4d7443614e9fe07c0b89b","13145221ed525c4c77325db4377a6818e2f41e1f","6eccbba04f448fa5bc93ed94bc63bb03d36e114c","e49269783b1561bf936a3767747c3b2cf059533a","bbac86e074504ca060553bfdb7953b0531ab4f2a","71fb410156fd52066e00eb1d0670bee3720b4b72","4f20828f487b093898c989f1043cb0d81b583d5e"],"s2Url":"https://semanticscholar.org/paper/87c6db39af058f542183ad7f126f46c38366aba6","s2PdfUrl":"","id":"87c6db39af058f542183ad7f126f46c38366aba6","authors":[{"name":"Xiang Lian","ids":["1800925"]},{"name":"Dongchul Kim","ids":["5570760"]}],"journalName":"","paperAbstract":"In many real applications such as bioinformatics and biological network analysis, it has always been an important, yet challenging, topic to accurately infer/reconstruct <i>gene regulatory networks</i> (<b>GRNs</b>) from microarray data, and efficiently identify those matching <b>GRNs</b> with similar interaction structures for potential disease analysis and treatment tasks. Motivated by this, in this paper, we formalize the problem of <i>ad-hoc inference and matching over gene regulatory networks</i> (<b>IM-GRN</b>), which deciphers ad-hoc <b>GRN</b> graph structures online from gene feature databases (without full <b>GRN</b> materializations), and retrieves the inferred <b>GRNs</b> that are subgraph-isomorphic to a query <b>GRN</b> graph with high confidences. Specifically, we propose a novel probabilistic score to measure the possible interaction between any two genes (inferred from gene feature vectors), and thus model GRNs by probabilistic graphs, containing edge existence probabilities. In order to efficiently process <b>IM-GRN</b> queries, we propose effective reduction, pruning, and embedding strategies to significantly reduce the search space of <b>GRN</b> inference and matching, without materializing all <b>GRNs</b>. We also present an effective indexing mechanism and an efficient <b>IM-GRN</b> query processing algorithm by the index traversal. Finally, extensive experiments have been conducted to verify the efficiency and effectiveness of our proposed <b>IM-GRN</b> query answering approaches over real/synthetic <b>GRN</b> data sets.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035929"],"title":"Efficient Ad-Hoc Graph Inference and Matching in Biological Databases","doi":"10.1145/3035918.3035929","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035929","venue":"SIGMOD Conference"},
{"entities":["Experiment","Interaction","Synthetic data"],"journalVolume":"","journalPages":"527-540","pmid":"","year":2017,"outCitations":["7f0a29a89655d7998efc7bb53e695b3b950bf7fd","72d61c7a81aed8f4aeacdf7db2d4536b4684483f","5be592ae66953d1c96ed54f1e0036c5647c00d50","460f2594a20ed190b9b3c1d1bcd47b08a2315433","3ff09a021ebed8dfd23b6faeba04d901625e5fa6","5becff7d8db7907df2b29b3e9a9c3b8cafe2caf7","3fca4ed6ded83281a9b6ed46a0a4e6a3b1a23164","1bbb160a886b61113f3ce494af055d1568e30594","6920a43dc904b8e7d3868c9f906b10aaf3fd72b3","9512f52337338232e1ed692748d9f069398ca545","b4266adb19b472422dc722c53c76b8ce6336781e","cccbc3da776de497ca9d0dde2d4a76dc6c1b0fc4","4c815e21c909211d7c047a2437938b24217e0a22","9a94e1981c4ed1429ac66e244dc0c042e31097ca","156e7730b8ba8a08ec97eb6c2eaaf2124ed0ce6e","dc39c68a00e38f2993b450eb01c96e1d032ab850","131a422dcad1ba3c89fc56f4b5255aed32c65d2e","e03fcae87b049671f979106c215bd985475e3f7e","6bbe1d686263fee388c16ee6bb84b8f378e38e47","27db63ab642d9c27601a9311d65b63e2d2d26744","0546c441944e76b2ebf1da5736264cd7b27890db","402f68ac3e61bea7b15c82d7290a57c44f4b9afa","2ab43be33b606176d6cd40dd2993fe4d28ff2313"],"s2Url":"https://semanticscholar.org/paper/e57bf28b32346e3e97da0bab925b5c831dcb3b30","s2PdfUrl":"","id":"e57bf28b32346e3e97da0bab925b5c831dcb3b30","authors":[{"name":"Zheguang Zhao","ids":["3361009"]},{"name":"Lorenzo De Stefani","ids":["34627565"]},{"name":"Emanuel Zgraggen","ids":["1945956"]},{"name":"Carsten Binnig","ids":["2691974"]},{"name":"Eli Upfal","ids":["1735099"]},{"name":"Tim Kraska","ids":["1746961"]}],"journalName":"","paperAbstract":"Recent tools for interactive data exploration significantly increase the chance that users make false discoveries. They allow users to (visually) examine many hypotheses and make inference with simple interactions, and thus incur the issue commonly known in statistics as the \"<i>multiple hypothesis testing error</i>.\" In this work, we propose a solution to integrate the control of multiple hypothesis testing into interactive data exploration systems. A key insight is that existing methods for controlling the false discovery rate (such as FDR) are not directly applicable to interactive data exploration. We therefore discuss a set of new control procedures that are better suited for this task and integrate them in our system, QUDE. Via extensive experiments on both real-world and synthetic data sets we demonstrate how QUDE can help experts and novice users alike to efficiently control false discoveries.","inCitations":["88cb7136cfcd87d9b93ec039359d2fbab158f3de","4119c775ac55f9400d5f2e183d5dd1723bb9d0f0","a979f050861b341c3bf4eb7be12d5ee0d87b44d0","7f75690619d23375011b658e67994284fa030477","a6613fc6e0f8dd9a538ea901db2317b4ce3644bb","ad8c152b67cdd6ad302414f1fa89824f1b92638b"],"pdfUrls":["https://zheguang.github.io/research/risk-sigmod.pdf","http://arxiv.org/abs/1612.01040","https://arxiv.org/pdf/1612.01040v1.pdf","http://doi.acm.org/10.1145/3035918.3064019"],"title":"Controlling False Discoveries During Interactive Data Exploration","doi":"10.1145/3035918.3064019","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064019","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Automatic parallelization","Binary space partitioning","Computation","Dynamic problem (algorithms)","GRAPE","Incremental computing","List of algorithms","MapReduce","Parallel algorithm","Parallel computing","Partial evaluation","Programming model","Real life","Sequential algorithm","Simulation","Synthetic data"],"journalVolume":"","journalPages":"495-510","pmid":"","year":2017,"outCitations":["1e8c283cedbbceb2a56bf962bc0a86fd40f1cea6","628b470c664be4eaf9ae3f75ecb630d64353bc4c","c2977a77e6578b3635ad893c481b50b0636735c4","1156f60e40548096df49528b1342bb3e88b0f378","3cabd75d1fcbc1ffeddad121cee327abf4223d49","ff71759a3efa271670c1e7820873df872b4ca3b9","30d963e87c462606793d229dbdf0786ac38ede6e","308002cca6afdfd4f751a382357b027dd94d2de4","0541d5338adc48276b3b8cd3a141d799e2d40150","6384234e698f793cfba0cbf890b1c2a2209d06b7","be94c5051438209816397be214ee8c1bdda94165","2b9e6181502369199bd89691a27f89bdbaac36e4","0ad8e89091eed09217e66adc98136126addc2619","87507a498558ed6ed23115a42f42376c0884f7f2","3726c60552263e648c6856679e672de2e1c110e5","b9c5678100693e00b59e58f3368f4797b9f11e77","87b7f6f406259c03b96412bbecde9711a9b8fccf","80527e7595530951081494d1b98f3f13da3033a2","322846e81eaf2b2a0783b54efcd9ea1dad767ccb","b78c04c7f29ddaeaeb208d4eae684ffccd71e04f","0975baea2e5a34f75c06284ac355af7f2de2499b","0a3b2d2ddf6e832a0b282380abb9b2eeb7d97177","f3a39750bc525e9a7fb42b130c2ee58f5faa188e","569d3fc080c3c2610f28506827d8fa67795524e1","0e33dd74064b3d7659d9ab6301c21c0480cfda72","87f931f4d8aad3b71b8261703bbcfa18c1293181","4ffce047b0189e30e51665f0c8872d05f383a962","202e33581369f6050fc800ebc31615eb65649e78","080f44d89bf6f4404f476ffec8d2f8ad3f60e07d","3793cd493c6b59bdb39593e370a542af84bf8a56","4066409e187467ae5ee989112b07aa9ce263732a","9aa88a8a354f1d322e242376d27d0474e50252f8","35eb3c956949bae34ea041be657920513df1b995","8fe315a467db4ee7f93d51ef6e32b8213189ed5d","75e217284d18901ce8b1fc4a389d3c1152b544fb","159efe23527149666be1b2b1c08853d74d413c1b","01ce82e98be37424e0456e2653d1ec8a0938b018","94c20561f102ede79c461c6aeee74eb7a55d5eb4","3bb6d5834bfb355553588e382ac5f9fa8a8d831d","38f0f2ddccad42c482066fecb4f0440516020241","c827d2267640a7a913250fa5046a16ff078a5ce4"],"s2Url":"https://semanticscholar.org/paper/68d3ada8bc4fb3de685cb870d9e72853d56b5c7d","s2PdfUrl":"","id":"68d3ada8bc4fb3de685cb870d9e72853d56b5c7d","authors":[{"name":"Wenfei Fan","ids":["1777183"]},{"name":"Jingbo Xu","ids":["2724949"]},{"name":"Yinghui Wu","ids":["2948541"]},{"name":"Wenyuan Yu","ids":["37681774"]},{"name":"Jiaxin Jiang","ids":["2969767"]},{"name":"Zeyu Zheng","ids":["34418171"]},{"name":"Bohan Zhang","ids":["2903546"]},{"name":"Yang Cao","ids":["1740511"]},{"name":"Chao Tian","ids":["1692159"]}],"journalName":"","paperAbstract":"This paper presents <b>GRAPE</b>, a parallel system for graph computations. <b>GRAPE</b> differs from prior systems in its ability to parallelize existing sequential graph algorithms as a whole. Underlying GRAPE are a simple programming model and a principled approach, based on partial evaluation and incremental computation. We show that sequential graph algorithms can be \"plugged into\" <b>GRAPE</b> with minor changes, and get parallelized. As long as the sequential algorithms are correct, their <b>GRAPE</b> parallelization guarantees to terminate with correct answers under a monotonic condition. Moreover, we show that algorithms in MapReduce, BSP and PRAM can be optimally simulated on <b>GRAPE</b>. In addition to the ease of programming, we experimentally verify that <b>GRAPE</b> achieves comparable performance to the state-of-the-art graph systems, using real-life and synthetic graphs.","inCitations":["2514dccd3a63999fc10396ee1866062d7cd4be2f","3cabd75d1fcbc1ffeddad121cee327abf4223d49","771610413f3654b8e4f38aab4dd970a481c7196f","0c7b88c4ea95081e99307700d3bf7eb08e790550","691e4fcf559e9d19ee6354715a8ccdcc4416c47b"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035942","https://people.csail.mit.edu/jshun/6886-s18/papers/GRAPE.pdf","http://eecs.wsu.edu/~yinghui/mat/papers/Parallel%20Sequential%20Graph%20Computations.pdf"],"title":"Parallelizing Sequential Graph Computations","doi":"10.1145/3035918.3035942","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035942","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Castor","Data dependency","Data quality","Database","Machine learning","Relational database","Usability"],"journalVolume":"","journalPages":"929-944","pmid":"","year":2017,"outCitations":["3474820cd8a15bfa3d38a3cf7ff71881c5d5786f","4735fc168eb72ef96817384aa5d40d5b6016d713","4ce09dee71cc7cb146751e68f12d18fa240dcfea","2749cb94f92170f79d0e8ad266605a871767f38a","554f3b32b956035fbfabba730c6f0300d6955dce","0f6fb65ab0ac654a1f8be07d134c8957a692a83e","43fc585a0d15a47e4b5a96559fd6fc13853cb21f","7f26b3e2fa06a193fcbf9243c1f9afcd5cbb9019","a97b77c8c3f9e8247c497d1b4c27c958a15f3a62","11d702bdd25dfdf368d9028693ea00dac25c8851","350f0f6e4a3db23897741b378da3c4f458625404"],"s2Url":"https://semanticscholar.org/paper/08ca316390729e26376836efb653e872f8184ec5","s2PdfUrl":"","id":"08ca316390729e26376836efb653e872f8184ec5","authors":[{"name":"Jose Picado","ids":["32563772"]},{"name":"Arash Termehchy","ids":["3192362"]},{"name":"Alan Fern","ids":["1791751"]},{"name":"Parisa Ataei","ids":["3454984"]}],"journalName":"","paperAbstract":"Learning novel relations from relational databases is an important problem with many applications. Relational learning algorithms learn the definition of a new relation in terms of existing relations in the database. Nevertheless, the same database may be represented under different schemas for various reasons, such as data quality, efficiency and usability. The output of current relational learning algorithms tends to vary quite substantially over the choice of schema. This variation complicates their off-the-shelf application. We introduce and formalize the property of schema independence of relational learning algorithms, and study both the theoretical and empirical dependence of existing algorithms on the common class of (de) composition schema transformations. We show that current algorithms are not schema independent. We propose Castor, a relational learning algorithm that achieves schema independence by leveraging data dependencies.","inCitations":["006b99c44bedd6bb9b0ebe27aea95f3a31f54c97","45e171871f642a6058b6558c385045b372b29131","0bbcce9821119777c0a2aa8302feb56dd979736a","05456a4ad95fa596781f3598bed9d18f7eb56310","1798c565cb393a461bbb87a243b7997926baa1c4"],"pdfUrls":["http://web.engr.oregonstate.edu/~termehca/SchemaIndep-LearningSys-15","http://arxiv.org/pdf/1508.03846v1.pdf","https://arxiv.org/pdf/1508.03846v1.pdf","http://web.engr.oregonstate.edu/~termehca/SchemaIndepLearning-2015.pdf","http://arxiv.org/abs/1508.03846","http://josepicado.com/papers/Castor_SIGMOD2017.pdf","http://doi.acm.org/10.1145/3035918.3035923","https://arxiv.org/pdf/1508.03846v2.pdf"],"title":"Schema Independent Relational Learning","doi":"10.1145/3035918.3035923","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035923","venue":"SIGMOD Conference"},
{"entities":["Arnold tongue","Attribute–value pair","Benchmark (computing)","Concurrency (computer science)","Concurrency control","Control system","Global concurrency control","IBM Tivoli Storage Productivity Center","Key-value database","Lock (computer science)","Throughput","Two-phase commit protocol","Two-phase locking"],"journalVolume":"","journalPages":"283-297","pmid":"","year":2017,"outCitations":["5c9793fa07fcaaae864eb89fd1c1b9f6905ec546","00ac447d02035c26c7e2852c2457fe812e89038f","8d1c0ae7bbe138bc19abf66ca918f46b244b1f5d","645f46933f49aa0ee730d7cac4af77c537a45950","ab310a105f6d5b04d798c4be0d6890ba385463c4","98cca67dfd0320d56030dd6637a733436d2b521e","17c6f330d854435e8d8faed245f79b94740a45f1","9ded1759123344a6a747641def78fb17a549f39a","0d35a84b3fade29ca52d2462d024da1ac313c800","dfe3731d484dba672b3b6ad5f94e58aa7b3e7f2e","9c98996b0654c88ca2ccdce3a3fc54ea957dde56","27682071ccc226220fdfafaed42d35826309d692","a33371ec053b61652f41d18e86dae07fe04a616b","408b8d34b7467c0b25b27fdafa77ee241ce7f4c4","8cf80fc67e804c88867b6faafafeb842d26227c6","2e50af2320dab632d8046b6d4c130ae6cce8903f","1a74681e1b9317d86c0f6d0567315322be0d2548","35f751e46799e3a91425267819f40dce273abec1","6460e782a12649a478bbaeb9c149f59e206d9540","095a3cee30d64d3a6f22caadd58c45c5cd0b83e9","578636359b81d9db02475231016d788e5d4d4ccc","412a9e54bbb31e12d008a9579994e009c5b40b46","56f6aec0132e56769e2036bbeff791dfa137d107","507a4cfc0e6a2f03ff0fabd0115739970c1f68fc","2146a0384f58500ad7c0865c8518b15bb84918a2","861fbac82ae5ec0ea654d0d95ce4d48de62419ea","3702d6e0c78050f3261fdbf0eb1aefbac59fb8cf","33457f49553d918e912c2d8c54b81f4fd8a4c234","0bddbe35fa6e3cf625d15553365a690d3a6bf7aa","09ecdb904eb7ae8a12d0c6c04ae531617a30eafa","c40d14cde10a9220185f9250a11f2ace45b1d668","10551c91b4d36d1009b23b4d2b88a9e1733fe029","05885dbd3ccbbe744a2ee1c39126bd263140e741","643a5ea2791f56ed58dcf50141301216de10bb9d","136eefe33796c388a15d25ca03cb8d5077d14f37","0804ed47a40fbe6deb5ce93efe551086695ae393","1ae507f38fbe2301f4f7fbcd64e2f49afe00a59c","43ae9dc5aef08698c90700bc55049f7a9a8cb68a","6f2f219a4f6d64843efe35f868ed919ce8b3a031","50600eeb8698ddac8136c67ceb776faafa35c8ca","08d1cedbbaa798855e30fa7dc9ddbf88060b1399","9748241beb02ef1e2d0e6dc877c04b354033a838","2888c136064ff5527a0bb370ac1d9bf71939e066","1664b784dd7d446ee8838e0eec5b980f61792007","2543a986d875f86119cb4ad9b1e287873ac4bce2","13e6aa5f61267b2814fa9b32f47c17c0fcdef2d5","4827cc74dba0c39172554cf0116eb111797f0d1b","5dd350cee6ecfd097b57772f89e6341ff05b5725","624cb175af600b7749bce00c0932e2a10f72e564","62d66e4f8d7fe942facae6566453dab3e2f75a91","07d847f310d5fa9138f461f0a25c5e0024f1c4af","a05ca97c7128fe9b74b550896291797f1573dcd2","26f747596560040c908d7f453149338460923445","742c641506ac9efc3281af2effb31f2fb31b2dd4","bb91368e1dd77d99176a6d08b3bd98be7ab23d12","5c0ee5e71daead36b7ac3ca13812b341499c5a62"],"s2Url":"https://semanticscholar.org/paper/5787330b0fb8d73d60e17ec462fa6022a6c62399","s2PdfUrl":"","id":"5787330b0fb8d73d60e17ec462fa6022a6c62399","authors":[{"name":"Chunzhi Su","ids":["2812070"]},{"name":"Natacha Crooks","ids":["2174285"]},{"name":"Cong Ding","ids":["40499672"]},{"name":"Lorenzo Alvisi","ids":["2445753"]},{"name":"Chao Xie","ids":["35386249"]}],"journalName":"","paperAbstract":"This paper presents Tebaldi, a distributed key-value store that explores new ways to harness the performance opportunity of combining different specialized concurrency control mechanisms (CCs) within the same database. Tebaldi partitions conflicts at a fine granularity and matches them to specialized CCs within a hierarchical framework that is modular, extensible, and able to support a wide variety of concurrency control techniques, from single-version to multiversion and from lock-based to timestamp-based. When running the TPC-C benchmark, Tebaldi yields more than 20&#215; the throughput of the basic two-phase locking protocol, and over 3.7&#215; the throughput of Callas, a recent system that, like Tebaldi, aims to combine different CCs.","inCitations":["af941012dcc736a55f5b9ba0d409d9fad1843eb4","e0c0d646f7107bb07aac3deacb1e63009740a80d","fab01f80c9e03d94f6e58520c92de620a426ce07","8c17cb64a2153ed38d7a2517ac6b57083e0a0eff"],"pdfUrls":["http://www.cs.utexas.edu/~lorenzo/papers/Su17Bringing.pdf","http://doi.acm.org/10.1145/3035918.3064031","http://cding.org/papers/su2017bring.pdf"],"title":"Bringing Modular Concurrency Control to the Next Level","doi":"10.1145/3035918.3064031","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064031","venue":"SIGMOD Conference"},
{"entities":["Database engine","High-level programming language","IBM Tivoli Storage Productivity Center","In-memory database","Online analytical processing","Online transaction processing","Replay attack"],"journalVolume":"","journalPages":"37-50","pmid":"","year":2017,"outCitations":["cd4b958bf9dda5f44fbb457f7bf0eca96d6563e7","3c6be4c9ea5c56d4ab97aabb4e7c9d5ced57bea8","2e50af2320dab632d8046b6d4c130ae6cce8903f","92e0243e1a73c77ef8b90292e3798f765b38f269","05eddbc2d37cf994fb7c6a4558e2679e5f40d23e","cf855ba4a09c2181d0166705717b5788454fcfa5","9748241beb02ef1e2d0e6dc877c04b354033a838","2610745375939fee88e556858344ab9344c47871","09ecdb904eb7ae8a12d0c6c04ae531617a30eafa","24c3330d34d640945e0eb99fe4a0b1c31695a8cb","00ac447d02035c26c7e2852c2457fe812e89038f","e9664a7b5b35be268180e45563cc5971df86404d","e75c5d1b7ecd71cd9f1fdc3d07f56290517ef1e5","13e6aa5f61267b2814fa9b32f47c17c0fcdef2d5","817da34922f767e11715f5aca7743e8d2388c68d","08150fd93c906fd8a882af537ea184d709e98264","97f18a7fd4a91a28c93545930a913e481425d57e","5046a718f92447642939f5c93414dc97225d726a","3542254ecc9f57d19f00e9fcc645b3d44469a6ba","145b46a0b1f8dc8f2182290655b9597fba087e78","14390fd81841cc4bb3d3764042481fc0a0e89e7b","463bec3d0298e96e3702e071e241e3898f76eff2","1ab74d44982409beeca21efb2dbcb97a5c7de4b2","41f8af6e2fafbf65f4f84534cb905c8824d7854d","8865ba2b6b169246ed0a1600bd7f9d447c4bd47f","ddf313f6fcc0520c716c54873164ded8e31703da","33ef71ebd67ed2dfffe14d73408173e6e8e94e5b","86daff3998005e12c963124e61f7c9cfd598a3cf","0997037e940df06ed7a6d19f7501579aab01e829","2525c025f11aec60cff428271ca851381b92008f","6033797f241a3687aab939db1d88b5184d32c0fb","2451dc6bb08d2668f4a876ce94d0c15227ccab7a","afda6470dd16dc0a865dbb6fc291e5806132379b","ef47742e72bd64fb1ae5359cd6d5dd6dfad34dc8","0eb1eba6a5bcf54391fcceecd431591d03a6df3a","12b71edea3a3cd18b507e4f0e20297d77f0f986f","9e5f18b528416025473bcab6082b51cf7ab60dcf","29f6129a8b8f80b547ed3394d2ada9ba10b95952","12c356a40e63af45aa6b0a63af38676a0dfe2b3e","afc4e448edba15519b5ea054d7b47af1a5aab93d","c8e6dd5bffa931f1252fd6a62dd267283cd85f69","35f751e46799e3a91425267819f40dce273abec1","b8d04f5a56f72aa39c1fd58db33c850c477862c5","13d350d63b88061db3b63355e90a05ef270972d6","45ac2218b74fd28ff170dc93cf4390649466c491","5c9d62f348c7ed09ee51e1d56643ced039ec1121","73f31354cc9058ddc2e47a1c585b753e1592c1bf","5ad1dd1aa78ba772c969aa01ee5e8ee0d255ce3d","1f4fac99af2d8a6d9471eb3cad7b5ae0365c0933","174148018456e391ee06adc21ea0535c825e8df3","0ad5ed5a0a7b9210993753d7594c7285d5e9b179","4f05a78c2e2abf932915c33c6a2bb9c726ce4ac2","028101c16b995cae0430fd52707cb91878a3b1d3","6479bc321dd7859eb6b6b8cca100bade86940526","06545f48a6b25a3cafd76e514b2310254972888b","412a9e54bbb31e12d008a9579994e009c5b40b46","8c6631f7a857e167406207c42ec47d7610a365b2"],"s2Url":"https://semanticscholar.org/paper/959a93bca92aafba2d1fc33fda530a50bf95fa69","s2PdfUrl":"","id":"959a93bca92aafba2d1fc33fda530a50bf95fa69","authors":[{"name":"Darko Makreshanski","ids":["1897378"]},{"name":"Jana Giceva","ids":["2811717"]},{"name":"Claude Barthels","ids":["3188030"]},{"name":"Gustavo Alonso","ids":["1687400"]}],"journalName":"","paperAbstract":"In this paper we present BatchDB, an in-memory database engine designed for hybrid OLTP and OLAP workloads. BatchDB achieves good performance, provides a high level of data freshness, and minimizes load interaction between the transactional and analytical engines, thus enabling real time analysis over fresh data under tight SLAs for both OLTP and OLAP workloads.\n BatchDB relies on primary-secondary replication with dedicated replicas, each optimized for a particular workload type (OLTP, OLAP), and a light-weight propagation of transactional updates. The evaluation shows that for standard TPC-C and TPC-H benchmarks, BatchDB can achieve competitive performance to specialized engines for the corresponding transactional and analytical workloads, while providing a level of performance isolation and predictable runtime for hybrid workload mixes (OLTP+OLAP) otherwise unmet by existing solutions.","inCitations":["5bd6f82d3d61270401d8284dc95437512e77d02f","264a5e7a5230b228b86f63a75546738a66454c56","077eb0de78522a25420fe0c0ab4e864a82ac7177"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035959"],"title":"BatchDB: Efficient Isolated Execution of Hybrid OLTP+OLAP Workloads for Interactive Applications","doi":"10.1145/3035918.3035959","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035959","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Data structure","Directed acyclic graph","IBM Tivoli Storage Productivity Center","Program optimization","Time complexity"],"journalVolume":"","journalPages":"1259-1274","pmid":"","year":2017,"outCitations":["312a3291a0e7c03d67968e2b72539d6a17ca8013","006ca7d3571497c73062b67ab1ab20a4b09b0972","49c9b55fe6998f51705d824e36ab2b093b9aa552","b0a064eb9437ba23b13c6886bf6a0ba49d6d31d5","4b8fbe5e18af87ce47b728bf7b4e644c9de0c95e","006b5b58e8d8475ab9295b3336beae102416444f","889ad7aa3b60a815bc20681aa648ebf97519c235","2c54a88235637dc950c4e799f9d24a0b34585df8","df321914b83d0af02a8a3938325907462d6ded95","ef9ecdfa98eba6827ba0140981fd0c259a72c877","01538cba7e35da5c58d9e8dac235c1a2d5d453fe","97fe4f19b3074756214e3d7cc03f5b40a2a48cf2","b9e38f58108ee6ec4859a021813b3fdce8ae3c3b","380d7d4863a57bc6a5109edcc77c352d91a485da","168de446821c0de9ebfa6d2145ca69837bd92671","0e8933300a20f3d799dc9f19e352967f41d8efcc","25c58a8925ade1a8746b7c24d9a11f04617c4684","076aee8e0b13704adb60ae212df22fea64613861","c2ae1b0acd281a2fff041f3098e7aef9a2f5c794","18ff3f799e8d16b89d07c6252efe6edbe33ec68c","2321a150c84d771d81fd81759757795dcda25750","f42314091a6bfcf180e81b080bfd4034aa886fac","31181e73befea410e25de462eccd0e74ba8fea0b","3ba66b7716d2f93ae39b2bb79427038e449f5a7c","495578719ddd89eaa817a92c0988e01dc44393c8","05a26b5deeed6f6f7e9584555b73c5af3905063b","03a666995669ebb66f3a8e7cd3b6e0f07a0f8d6a","1f75eec6c4967eace44cfd0bff3d736a05a53e2a","001ab484e44bf365eb2c9532e21a42f9cbcbe5f2","25ac757c975185450da0b49530df3c1471ebc6b0","c935242e20209b3e89aad72838a702d33efbf356","0f48c76228e3f17ce5766614800121c767b72cbb","a97b77c8c3f9e8247c497d1b4c27c958a15f3a62","431f89d5a702be51916016861b9d053044006064","10723678d19bab6a52c8ee9b89f9118536044033","1c918798bbfd2caa2335c5cd9f15c08e56ed2cde"],"s2Url":"https://semanticscholar.org/paper/d29f2dbb39936e9be8e32421919d48b7601c4ee7","s2PdfUrl":"","id":"d29f2dbb39936e9be8e32421919d48b7601c4ee7","authors":[{"name":"Muhammad Idris","ids":["27639137"]},{"name":"Martín Ugarte","ids":["2920800"]},{"name":"Stijn Vansummeren","ids":["1709642"]}],"journalName":"","paperAbstract":"Modern computing tasks such as real-time analytics require refresh of query results under high update rates. Incremental View Maintenance (IVM) approaches this problem by materializing results in order to avoid recomputation. IVM naturally induces a trade-off between the space needed to maintain the materialized results and the time used to process updates. In this paper, we show that the full materialization of results is a barrier for more general optimization strategies. In particular, we present a new approach for evaluating queries under updates. Instead of the materialization of results, we require a data structure that allows: (1) linear time maintenance under updates, (2) constant-delay enumeration of the output, (3) constant-time lookups in the output, while (4) using only linear space in the size of the database. We call such a structure a Dynamic Constant-delay Linear Representation (DCLR) for the query. We show that DYN, a dynamic version of the Yannakakis algorithm, yields DCLRs for the class of free-connex acyclic CQs. We show that this is optimal in the sense that no DCLR can exist for CQs that are not free-connex acyclic. Moreover, we identify a sub-class of queries for which DYN features constant-time update per tuple and show that this class is maximal. Finally, using the TPC-H and TPC-DS benchmarks, we experimentally compare DYN and a higher-order IVM (HIVM) engine. Our approach is not only more efficient in terms of memory consumption (as expected), but is also consistently faster in processing updates.","inCitations":["2734e7f6da7d841d7d8d3fd6aff857443083ef9c","86ffd2eeef909416825df85974ee04ab72be6193","0a424fcdcfd55ff0f80a193848547b5e5f434614"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064027"],"title":"The Dynamic Yannakakis Algorithm: Compact and Efficient Query Processing Under Updates","doi":"10.1145/3035918.3064027","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064027","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Apache Hadoop","Approximation algorithm","Arbitrary-precision arithmetic","Big data","Cache (computing)","Central processing unit","Data item","Data parallelism","Database","Fairness measure","Game theory","Multitenancy","Parallel database","Pareto efficiency","Polynomial","Proportionally fair","SPARK","Time complexity"],"journalVolume":"","journalPages":"219-234","pmid":"","year":2017,"outCitations":["3c6be4c9ea5c56d4ab97aabb4e7c9d5ced57bea8","18ea18ad0e7adb2fc1e123c0c13d95a99ebeb312","87d47502bf40a4bfa7a0ded26c3efb2426250808","2077c3787e5a1545df312d51f9a7b8cd05e2c7f0","30fffc671f9d6911da230b17d68ec4c2984a0890","009523862551ecec0da53dfd0365892cb9cb430b","5c6ab0726c1b2e680b7d8147d9d3a45d11fe289a","0d62a556f60fcf144a171c3b522b253f8bd443b9","1be315723e77916d1ce398dcc4157cae66e68b41","578979a22a6bfb915c85acb42a6297e996f9c45e","298239c297d781496f2988c804339bd4f1e17308","a7a7110ca7fe9eec39f4c709920f9cad45dafb19","213c5d93b11c6f7620e91369290b0711876e0751","624073f9a3053217afb1dbd8adfc44d1052ba282","23a4971ea1a47a827df398cbabc26e0e05132203","8d1aa2db67f214bf4b396d26240330a2ea00bd9a","291470e5e557ac526f79a59c83e98fbf53406401","4a0bb4eece00f3e9445d1a0d933422aa408ce8d1","30a13879770a420ab1499de4ee06aef54d7ee256","4b4ee1ee9bbfd9527fba0bbd761bd61a59f96a48","0ca45c8a2d16a949586c8b86a73047a9f5cfa71f","363116c764453d9b740c46d23b1f5a3c5801d76e","277fdd6dbd792fd41e401b13e0fd897bfd911378","2b781818dedf1f31ed4cfa0c6150e020d89d0d05","2988e34168fa91398fa397baf823af2063893e9c","1df0f37e87b542d62a7a30607aea96693d84fdcc","1e954c5cf302d76483ec0cc0049b4b1220077750","08c30bbfb9ff90884f9d1f873a1eeb6bb616e761","c3c262b8e56536d14826926b69af59eaefc29bc2","41e0ef45114deff41d92c8b235393cfe4d9a94f4","72f91b486b8b867e5825d82db1cca5a5172f376b","04085d8281bf3e9b0493c7e4441671cbd23d9ac2","980773ca869fc17562e4fbcf4202a8f21893b114","07add9c98a979e732cfa215c901adb1975f3f43a","50e1460abd160b92b38f206553f7917cf6470324","5c0985b9b699d94c697a9a835e76d52ba916ca0b","f465e873cb9d9e5cd74cc759c2b015da06385a86","e6400e666809149ce3ec9bca67f7a6d1074728a0","bbc2a698c2fb2b76e256cc51a9d7c37765ab51b6","0d2f3f6abd86368a2eb9a6d0b37d1299ec5939a6","4a81486f7f1d03d547e78046fc154a6890d8eabd","2f52cbef51a6a8a2a74119ad821526f9e0b57b39","12ab5f0813dd557057c68359ae12cd18a4213b9e","9ad46d3a4d32b11e3654c5df490db520dde9e110","cd8231a86589d205c64167ad462671c357f56d8d","947955f1d97505638fc01d24642904df7071588d","d2ceab98e96695ea58f919e1141e7aff5d6088ab","eaf2bccd82bf4cffcf1ef85487d6722f6a04716c","5dd36ed50668b5cc1c95ce6cf83b1b9b21a5f560","2a72118cc2581f0a4e7fe323e67305f2742e0563","0dafdc7debdcae528b2549489a03509cb4ecb9fe","82ce0158c14708b01153ac0fe7d6dc9688dfbb18","049a69b03ff4af9999e1ace889d5f6864f481ccc","0648bd696a4b80f251dc6f4da210bdf94f208a93"],"s2Url":"https://semanticscholar.org/paper/3eb0660f970a76a078d2db96c4e6714d5f0c1484","s2PdfUrl":"","id":"3eb0660f970a76a078d2db96c4e6714d5f0c1484","authors":[{"name":"Mayuresh Kunjir","ids":["3094459"]},{"name":"Brandon Fain","ids":["2605019"]},{"name":"Kamesh Munagala","ids":["1679666"]},{"name":"Shivnath Babu","ids":["1778813"]}],"journalName":"","paperAbstract":"Systems for processing big data---e.g., Hadoop, Spark, and massively parallel databases---need to run workloads on behalf of multiple tenants simultaneously. The abundant disk-based storage in these systems is usually complemented by a smaller, but much faster, <i>cache</i>. Cache is a precious resource: Tenants who get to use the cache can see two orders of magnitude performance improvement. Cache is also a limited and hence shared resource: Unlike a resource like a CPU core which can be used by only one tenant at a time, a cached data item can be accessed by multiple tenants at the same time. Cache, therefore, has to be shared by a multi-tenancy-aware policy across tenants, each having a unique set of priorities and workload characteristics.\n In this paper, we develop cache allocation strategies that speed up the overall workload while being <i>fair</i> to each tenant. We build a novel fairness model targeted at the shared resource setting that incorporates not only the more standard concepts of Pareto-efficiency and sharing incentive, but we also define envy freeness via the notion of <i>core</i> from cooperative game theory. Our cache management platform, ROBUS, uses randomization over small time batches, and we develop a proportionally fair allocation mechanism that satisfies the core property in expectation. We show that this algorithm and related fair algorithms can be approximated to arbitrary precision in polynomial time. We evaluate these algorithms on a ROBUS prototype implemented on Spark with RDD store used as cache. Our evaluation on an industry-standard workload shows that our algorithms score high on both performance and fairness metrics across a wide variety of practical multi-tenant setups.","inCitations":["bf22e7a56929fa0bee305022d7d229449fe26a81"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064018"],"title":"ROBUS: Fair Cache Allocation for Data-parallel Workloads","doi":"10.1145/3035918.3064018","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064018","venue":"SIGMOD Conference"},
{"entities":["Computer data storage","Data mining","Data pre-processing","Experiment","Iterative method","Preprocessor","Running with Rifles","Scalability","The Matrix"],"journalVolume":"","journalPages":"789-804","pmid":"","year":2017,"outCitations":["eb82d3035849cd23578096462ba419b53198a556","468c3b2bf358d07cc625b075f91595d825299948","1a4edf228e648b54fab3f25df82817cfd0a5bb42","07ad62b6b5da5f226c88549378886ca062e207a0","9ebf0f5f36d1504e96d147f38e5b9e21d7d28825","6c15b76f9018e24cbb16909a9d77df24da948ab9","607c8ae7b868015ea2deb61969d7e38988de8ca1","4ad0595b7af6c4041bfd89ccf74d94f154a39762","3ad743e436bb8749b7f750e4b316550a9d124bac","fec9ce47524e65b89c20d4dc1671c5b1a7a0a41d","4f9df283f1dac228fbbd3efd50765ecb317efe6c","1b348075d02cc532b1a01955e21ba3062e769113","3f789c5902f6094fe2db402d73cf81aeb3bacc69","2eed842c2cf908df5c5d9c1c1e0a160ecd881679","631e721376e844a016ffe18a8a9af3d75766f91c","3e1e5a5edd5858d906b49363984a3e3659fb9478","408cd9103f2d7cdafce2f6b984035b2be0ed9b7d","62ffd399b939f09430b987d59afcf1c8b5ba28a7","a1b297de50f1678dd97e36b13559627640354914","b3ca8fb21ef2e12b4aba555230559d632c1e3ea3","0d06de003e8ca949b3b39f9a51750c050addb997","cd73fb6b77c94842e58486cd40cd85d40b18b4a3","41a70062d260feb62e0ae64acf252a839c0bbd61","45f615637d9bdbc1c20b5ac2440dd5271be55a9d","7664b703efab1eb2815b94b02f2ec31e534ca9cb","7bb9bab74df4d2939bbdf41fc33027b59e0f229e","14815c67e4d215acf9558950e2762759229fe277","183c44d2b9ac64e8c795464f91ef98f1e3ba2ea3","0ecdf0d9e33ae993d5f789c6e1bb410ba2fca0b8","7fd78d448539d94e250aa9c08fe6a2a031f44f3f","6f4c0ae207ec857e51cefc049de65c55ad61bb98","1000dd39d230109762404983eb5666da4a777e72","237dc6e66cc6691bf2245c02cc19a6e0c077fde9","41e62b05a64225d209e9cd37775c3303fc6ce3c5","050befa33b96aeec92f98cfe74b6b10702bc1250","3105c03f6ee3135ac6b649ed6313ae0e6c0eb8fc","1781fcd66c25d303a66eb980728b0da6ed1febbf","f580162b0f1ca6e7cf03eb3c9cab1c10907a3a9c","080ff994ebb101ac340e446344215f834eae0f6c","b2de9228510f30df18d53c259ab67c977bdfea87","735209db0198821865444ebc664d0571f9d9d19a","13cc53a512ca45d229e9fe514ad0b30441d324d8","acf2c6c0caa98461ae784a4054aa66968e7b6c58","318567451fc86c9a02afd1172aba6d0ab2d5d814","2c29b9a1b511219bc564c9b0deada00b50f5c79a","871f43a70f3171768734e0c2add1f263b8f47a70","29efbdf3f95cee97405accafdebd3bd374f1f003","15244f9eb5af689f7a2ef9f746300db92bf79f39"],"s2Url":"https://semanticscholar.org/paper/5bf2414cb01317cd1664c896f1f1da735443a0f5","s2PdfUrl":"","id":"5bf2414cb01317cd1664c896f1f1da735443a0f5","authors":[{"name":"Jinhong Jung","ids":["3214124"]},{"name":"Namyong Park","ids":["2867343"]},{"name":"Lee Sael","ids":["3130706"]},{"name":"U. Kang","ids":["1734930"]}],"journalName":"","paperAbstract":"How can we measure similarity between nodes quickly and accurately on large graphs? Random walk with restart (RWR) provides a good measure, and has been used in various data mining applications including ranking, recommendation, link prediction and community detection. However, existing methods for computing RWR do not scale to large graphs containing billions of edges; iterative methods are slow in query time, and preprocessing methods require too much memory.\n In this paper, we propose BePI, a fast, memory-efficient, and scalable method for computing RWR on billion-scale graphs. BePI exploits the best properties from both preprocessing methods and iterative methods. BePI uses a block elimination approach, which is a preprocessing method, to enable fast query time. Also, BePI uses a preconditioned iterative method to decrease memory requirement. The performance of BePI is further improved by decreasing non-zeros of the matrix for the iterative method. Through extensive experiments, we show that BePI processes 100 times larger graphs, and requires up to 130 times less memory space than other preprocessing methods. In the query phase, BePI computes RWR scores up to 9 times faster than existing methods.","inCitations":["eba4a67229413f9eb703d26f64ef530899150ad5","816ff95fe2f1d0e9234348164fa31bcf271e8be9","33cd7edfd054cf1d724884dc301e96a10be532cf","40cb86ffbc0c127bcae3137138da10f217716779","73916c66a9e409f1636935ed37699242f035a0f2"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035950","http://www3.cs.stonybrook.edu/~sael/paper/Jung%20et%20al.%20-%202017%20-%20BePI.pdf"],"title":"BePI: Fast and Memory-Efficient Method for Billion-Scale Random Walk with Restart","doi":"10.1145/3035918.3035950","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035950","venue":"SIGMOD Conference"},
{"entities":["Approximation","Approximation algorithm","Database","Experiment","Programming paradigm","SQL"],"journalVolume":"","journalPages":"587-602","pmid":"","year":2017,"outCitations":["ed3249f83fafbf2b0224a664e4617c614ff410d5","0beca56d0260ffa0c68d17b7e90ccff42b820076","38050cf2f8289da85efada8baa0933ba5224ac7e","115ac1e107a0a1da87e12455de7e3f645fd00836","1367718ca1be8161667d2880ed4eb19a7beba058","b41761392859fdc7a4345e8b5d259c3c62c94740","4e3c1f3904d4b5404a03b6101370841f7c4798d5","0c88a6f41374306058ea8f19a3eeac5b6ce6650e","1dde3f45a23efe5c7fa9b400e81388296527c6da","483015dc170d20e1a19828d493eff364cd7a42ce","0c0cfae57d32de295292fff6e67b2a22001bde23","78f9ce506df537b8c36b49857123d90bf819a860","21cc08ddc2644290c3c9bad27321ba7187a0b0b0","4969f8f0feeb77128bd96cd15fc6ee323fb0f653","22fa7b136662f51f712bdc9ccbb811a08327805f","2d03baec8ac1568e6813aa43d625d552524f977e","0dafdc7debdcae528b2549489a03509cb4ecb9fe","30c70576767b3b8c1612891b98f43212e690e61c","0d1f1d0984b3e8d6b8e9169c05e2a7d29e2a32d0","37861bb8d8daeab11d379a012ab526222a3f9990","1ad1019d9eb5fb0f1833b8a98a52aee4a14fecdd","617e05daeaee61af81dfa4413e3b1d5e0c077523","4c815e21c909211d7c047a2437938b24217e0a22","2889dbb1e5770e1eb6e5e3087be5be5841b11fa8","37601bb6e655f2392ba1ca2086da0d1e03e19edc","1a1280a047c380ddf281d486f7fe644c7fc95fbb","6017608b32421ce761c2baae98dc752ec22a0dbf","b55b8fcafc62be1ca5db4864200cf0dec0a9941e","da696840f88ae88eb15828e5a22518447e756aab","ad45ffbf9ba7e7c223b4f4b24c56f31e965eeea2","01f6f9e17988133989b39da37801f6c674df1040","5ccb180e8142da6c1a04fb1e1477d7f1c4867c0d","2069e42716f16b01e0085b8715e40f8609357485","8631ae4a69f409ed09f451867c3ef4bf17129b79","1b19eb5c3ed02dcda18b9300f2804bda0a4c94e6","266907e673944ff0bd4486fe6f8b4f14a3c8c9f6","1317f7e3d1de6ffd0888303ca95d9c8c6bae2af3","c372964be3e6482d714d2be716da6f6f80f43575","5f3f9223c5c9f896be099bc177929febad508407","4af182338ee63754d4569c26cb6a5c3bbdd8cf2a","999b2f918f4a68b7d71d90a10a18e3af08dafc24","5bfcf932d67b8abc128f41d57d10ea6292615599","7a278ee0578f194700cadc3811cdda4ec751f88a","148b83a379a549e3e88fc9506e91e14b09756c7d","080ed793c12d97436ae29851b5e34c54c07e3816","b63eaa5aab7788f783bc0f25c94c4eca7f19313b","3f14887cc4e65aecd6fc571eef2774a19e6ecb6a","cc2bc224cc1c8ef3d5e644f971b02ea30e1a4ca6","26337762b9b06c7d8a952bebab6408a5e7f9935d","3357eede86832c2344e9a255e0520a01b6189393","4f280d6f6b2af06bc7c7a34e4f610608e9f82156","65c46b04244c194aafe5cff074e824b4aad081ce","7535340c5c62f40d5eccce082537a16cb8e03b27","0f466df201a4ae105724cf16c868024134a96727","7e209751ae6f0e861a7763d3d22533b39aabd7eb","9d774d272dc7627abeca901a35b2c92958ee002e","6a912e2c1f818a047bc620f475b6b6e3b0dbacfe","1948575f4cedf689f708d1f0880e79de9ec4c4a5","4b163245cdc7a1d80ded5e26424fb382910965b9","befb28484716491fa8e06454a3b92c14ed4ed039","37e0d25940bd49022c41e63909532acd88eb16b9","d89131b5939b51f191d5efef3f18258e1135845c","4b66ce55c4a8b5c6dfa804146ad32a5a0797d7ec","a5afa88e7ae2c9a455e7a006e6380f25b3d3728f","00aa614734a26a19b09a0a3bdee2adc77bdac5e4","eed62d36d1b976ac3873c83645f1c25f5096f89c"],"s2Url":"https://semanticscholar.org/paper/40b2652cf3bdee159dacb6e18c761003c31f4205","s2PdfUrl":"","id":"40b2652cf3bdee159dacb6e18c761003c31f4205","authors":[{"name":"Yongjoo Park","ids":["40155297"]},{"name":"Ahmad Shahab Tajik","ids":["9949978"]},{"name":"Michael J. Cafarella","ids":["1725561"]},{"name":"Barzan Mozafari","ids":["2198667"]}],"journalName":"","paperAbstract":"In today's databases, previous query answers <i>rarely</i> benefit answering future queries. For the first time, to the best of our <i>knowledge</i>, we change this paradigm in an approximate query processing (AQP) context. We make the following observation: the answer to each query reveals some degree of knowledge about the answer to another query because their answers stem from the same underlying distribution that has produced the entire dataset. Exploiting and refining this knowledge should allow us to answer queries more analytically, rather than by reading enormous amounts of raw data. Also, processing more queries should continuously enhance our knowledge of the underlying distribution, and hence lead to increasingly faster response times for future queries.\n We call this novel idea---learning from past query answers---<i>Database Learning</i>. We exploit <i>the principle of maximum entropy</i> to produce answers, which are in expectation guaranteed to be more accurate than existing sample-based approximations. Empowered by this idea, we build a query engine on top of Spark SQL, called Verdict. We conduct extensive experiments on real-world query traces from a large customer of a major database vendor. Our results demonstrate that database learning supports 73.7% of these queries, speeding them up by up to 23.0x for the same accuracy level compared to existing AQP systems.","inCitations":["39b62c7fc926127d11f6d60d78066ef9d9564a55","18217d68fca6b1f5305c80a733a4a717e3e35052","2b6a2ec50b841f435a89b1711001ee8bf776a760","140de9a2a670d2468cfeb4d0c5c677cf64c80866","ad64649f20cc20a2d1584cbc4b859d9fa9920538"],"pdfUrls":["http://web.eecs.umich.edu/~mozafari/php/data/uploads/dbl_techreport.pdf","http://web.eecs.umich.edu/~mozafari/php/data/uploads/sigmod_2017_dbl.pdf","http://arxiv.org/abs/1703.05468","http://web.eecs.umich.edu/~michjc/papers/ypark_sigmod17.pdf","http://doi.acm.org/10.1145/3035918.3064013","https://arxiv.org/pdf/1703.05468v2.pdf","https://arxiv.org/pdf/1703.05468v1.pdf","http://yongjoopark.com/resources/dbl-sub.pdf"],"title":"Database Learning: Toward a Database that Becomes Smarter Every Time","doi":"10.1145/3035918.3064013","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064013","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Critical path method","Database","Enterprise software","Lazy evaluation","MariaDB","MySQL","Open-source software","Oracle Database","PostgreSQL","Programmer","Scheduling (computing)","Throughput","Transaction processing","VoltDB","Web service"],"journalVolume":"","journalPages":"745-758","pmid":"","year":2017,"outCitations":["990ba8f4f4af23ab60e9b9f1bfd5aabf485a4fa1","24c3330d34d640945e0eb99fe4a0b1c31695a8cb","992f075efa000d5c6bd9ae9318b6bb427d3c4b45","1cc643b82f19a3774901d0500b4352e9ce388f5f","92e0243e1a73c77ef8b90292e3798f765b38f269","15c80ec5104e98d6f84b5ed348ba0276c0739862","d743e2ed7f9070fcadad2887e4b9071538981b83","c6c50988d5d38806225061b5956f8ec0fb3c698a","8c8b44029fbdac1572ae47b8eaab3929c9987098","8be83d658648bbc5d4e48edb3f3503fd86f791c6","741b93a649af7deb9db97980fdbdec02dafc2eb7","408d77abb094e0125e39cf6e5f5d9dfcbe6c3595","2b27047d0ad4a0b233525b074a0f5b35b9e1ba30","00e85aa90893b7ec09d04eac72f9122620e82e8e","7df1de1c9663c2dfaefc1277a7d1cb3366b8c358","242af20794ea044f72ccbc944d621c356e260bc7","2d01d0eddedfa573dfe39104172df5099d3587c3","1df0f37e87b542d62a7a30607aea96693d84fdcc","48544327a793badc608d7c5153aa7bcd3d2b5173","6033797f241a3687aab939db1d88b5184d32c0fb","c1fccf186ccce685fed39745557fce804452669d","578667cbc39c6bfc1c89fe6a54506643c3b097f8","7d67a72caeec8ee123b748a59b263014278d5db4","157352f39ed5ba9a571dd4c27b48786ac8be90cf","30d430bfab63c8981fce10b403e25c6bf1a30d6b","3c457cec00499e41dd05516db79c4daf836102ad","a0b1b8ee4a9e6ae68ce6a712ad0a66ddb4a12117","718c1aee5db0471cd1014840e774b4fec4655aa9","4f089c183d486d6f21a57cbaa8754849e05fb45d","10551c91b4d36d1009b23b4d2b88a9e1733fe029","029f5fdbcbd621e2795f9dcd9b7b0a440a69e251","3c77787fbaf5cb17cd600cd6e66534be490a26ee","19601c8db1f2c750f468f1ecbfa3b258c25be472","7cc137c213e0f4fb1e1a6a3df499d8dc044ea114","9aa0d7253574e50fe3a190ccd924433f048997dd","28ecdc50beb098d9176d992fed80eb2bac5963a4","72f91b486b8b867e5825d82db1cca5a5172f376b","214fbc64cb1aed66af3dc948eceb35760c06e788","85e5a0a9fa82339964042c512c8576b9f959fc27","4d0ff88dd2970cbe26e98364c8243087e24d0d63","4f05a78c2e2abf932915c33c6a2bb9c726ce4ac2","430611bb598deb44861324f75da01a612979bafb","fcfc9da7c8b72421849f001b2a220c0b0a7e7d76","41f8af6e2fafbf65f4f84534cb905c8824d7854d","55af531059610139bdba4f2ac4b1e63062712d6d","3709ec18aa09b58cc45133d39b4f4f930249d042","4e6ba973d4023f7463301180c294fffcde535e1c","5c9d62f348c7ed09ee51e1d56643ced039ec1121","ca05684712ef959cf707c085f1cfa731c1a86d3d","22d3fc87f5d9ea17a3bb21f885655a1f9f2deb65","130c96e94a9d8374da2c17752fcd5bdd9db2974f","62f1ec11da850fa2ffab031757d226c1fa67ecb9","22a3f0837bd6a913f516ba497469176be641c7d4","ba4ee2b3d5cb97c8551658d38874c330a3016ba9"],"s2Url":"https://semanticscholar.org/paper/4f5dd5c31143e4813b195ae74318bea712302e49","s2PdfUrl":"","id":"4f5dd5c31143e4813b195ae74318bea712302e49","authors":[{"name":"Jiamin Huang","ids":["1930940"]},{"name":"Barzan Mozafari","ids":["2198667"]},{"name":"Grant Schoenebeck","ids":["1710013"]},{"name":"Thomas F. Wenisch","ids":["3334450"]}],"journalName":"","paperAbstract":"While much of the research on transaction processing has focused on improving overall performance in terms of throughput and mean latency, surprisingly less attention has been given to performance predictability: how often individual transactions exhibit execution latency far from the mean. Performance predictability is increasingly important when transactions lie on the critical path of latency-sensitive applications, enterprise software, or interactive web services.\n In this paper, we focus on understanding and mitigating the sources of performance unpredictability in today's transactional databases. We conduct the first <i>quantitative study</i> of major sources of variance in MySQL, Postgres (two of the largest and most popular open-source products on the market), and VoltDB (a non-conventional database). We carry out our study with a tool called TProfiler that, given the source code of a database system and programmer annotations indicating the start and end of a transaction, is able to identify the dominant sources of variance in transaction latency. Based on our findings, we investigate alternative algorithms, implementations, and tuning strategies to reduce latency variance without compromising mean latency or throughput. Most notably, we propose a new lock scheduling algorithm, called Variance-Aware Transaction Scheduling (VATS), and a lazy buffer pool replacement policy. In particular, our modified MySQL exhibits significantly lower variance and 99th percentile latencies by up to 5.6&#215; and 6.3&#215;, respectively. Our proposal has been welcomed by the open-source community, and our VATS algorithm has already been adopted as of MySQL's 5.7.17 release (and been made the default scheduling policy in MariaDB).","inCitations":["3709ec18aa09b58cc45133d39b4f4f930249d042","209443f19f5742a18efb19d4d8fea307e6e6d56a","7254ad8940dc3ea502ef65fd9b71a9a2952daf81"],"pdfUrls":["http://web.eecs.umich.edu/~mozafari/php/data/uploads/sigmod_2017_predictability.pdf","http://web.eecs.umich.edu/~schoeneb/papers/sidm384-huangA.pdf","http://web.eecs.umich.edu/~mozafari/php/data/uploads/Predictability-SIGMOD2017.pdf","http://doi.acm.org/10.1145/3035918.3064016"],"title":"A Top-Down Approach to Achieving Performance Predictability in Database Systems","doi":"10.1145/3035918.3064016","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064016","venue":"SIGMOD Conference"},
{"entities":["Benchmark (computing)","Crowdsourcing","Database","Experiment","Mathematical optimization","Money","Multi-objective optimization","Program optimization","Query optimization","Relational database management system","Simulation","Unified Framework"],"journalVolume":"","journalPages":"1463-1478","pmid":"","year":2017,"outCitations":["49ceba7f32b3d440f20b7b35d4c7462016666ef9","a44b2fbd07d6d17e968afc240ac212f9070b95c3","cd48760a142830b796b8a85a158cd469f3e5feb0","4033104e3a37324df023fec7e95d852e962617de","1a7651308dbbdf91ccf07886b016b5fa8678fd27","0eb3d04dae51367b735c021054792a71e621095a","bb0620f3e15a1c6bea44f0720ec56aa0ccd0a84c","1b189d721adbf1d2bab93b7ed6ce826e188b0b99","422d9b1a05bc33fcca4b9aa9381f46804c6132fd","1c2e8d2d63312c18944c9477797e65a0975361da","199dcbb1e5287eedb458c867b171cc83c06b0d2a","af1e1bee41d004a6c1fa608a9fe2a884f48c6e5f","4f739534a366799e170599d3ff3d65597f0118db","08f51a9138458f667f0c00d40b6a820c451c7d36","0894c223858b5b40ed6ee256d5378030a82bded2","37c0234b8c699fcb0b9c7b5b45bdb0112514aaac","cbd45b97b5332e4b955cd54f090baed9d2ec5a72","0536a29e450f736fa98db5cec8b398d518f0f7d4","0ee10b695a90d7699b0518436d9bac53410c2d0b","5144ce3943d6dce07db0fa7469b54e1f3aea80ab","1ab69d3c63d92460d0eb09e0cf493d4eec18209a","35c71faec5506d8fe79bb997f6e9e3743dc436a6","29eb9e82b7a3aa02b9af5f0f1b6d7c6a4c6e2917","5b55010d6aa8b909ff588dccf1e4693e156cf41e","b7e44eb637356570af6e980657d461d0d3266bfa","7bbdb1803788a0e0cf8b814ed12a8f87e544b6ec","66d87d19a9e7d559aedcb843127fda9cda5ce417","7ac5425b837a5e889847afdaf04c0241b9b0b4ba","882ea179c692c9ed7bbeee115302631dc014b199","f5d9c0182d8578f7c0a99ad9bdd4ff62e5f7c68d","1aecd54c380632d2d12b6bf8688f1167b61d6127","1d8b0494623cd7d041b42e6518994b8e21367b8a","6953420c593842697dd09bc2cf7ffbbaf67a6e8e","16c36a0ab390553d77877ee634607899e4eececf","0b65d7a55a1541f99e0686844e2129527e7702e0","20d90871bc0dc7956bf2557d91d8d96deb0a4520","86d2add9aa90014a6330e3eb59277562adaeeda4","0d0f7b0456472116a3fa8cbc87a3bcb00dd432aa","79f9e562470ea00d1bba08fd1fba8cc46d96f211","8d4594b4d4827f44b57863376d54536112b7aaca","8a0b267493ac9510e47ceb4bcebb6d202b2f89a5","76db421d3ff172ca679f2c680d3b4f161718c194","71b76a4de9b1364be2905278b69e0912c5f70b3a","213cb7593934bc675c336f53dd6c61a3c799be80","151673abe01271dc3fc37725c02e95e7970f3bed","71a83e1747bfcd8022d3b8e31acb01765055af9d","6a35c6aead0796373bbdcc6c8c3371d8c25146b0","325413859d5bf180dd08352b07a09fd714ec3db9","7a84a82a45c0e10e485c4fcf3afa9158caf20b1c","2378e4de465227e44978f6259ac97f763448ea82","64591361f2f39a1c0418141c4795e43573637739","02df9340e08e1e5085f1257bb6ddda4cd225e1d3","5f11f3d958581f53b20577da69c9f7bc25c2ff2b","32be67f8fb5b21554b950fb49f3c81098d5d23c7","24c48b97725d84246f6dbd39c055648a305e1df4","743a4a699ef01786a7321291ff8ca94b7bde7780","788253d23de39a81305d72d47eda33d4d27495d6","88cd4becf3587a8378e450a99ded801fbdb264e1","d84af7f39033a084d9ae95fe895d39b9ec5246dd","632eca15ed20f87490c60a6005c4c58f06bee61b","6ac7262028d905ad97bbabce37c610e5d84e4c6f"],"s2Url":"https://semanticscholar.org/paper/ccc68bb05f3433f287de4f66fe9814760ebcafb3","s2PdfUrl":"","id":"ccc68bb05f3433f287de4f66fe9814760ebcafb3","authors":[{"name":"Guoliang Li","ids":["23492509"]},{"name":"Chengliang Chai","ids":["3416315"]},{"name":"Ju Fan","ids":["3232294"]},{"name":"Xueping Weng","ids":["39163188"]},{"name":"Jian Li","ids":["26846526"]},{"name":"Yudian Zheng","ids":["2985907"]},{"name":"Yuanbing Li","ids":["4769653"]},{"name":"Xiang Yu","ids":["38438821"]},{"name":"Xiaohang Zhang","ids":["2285128"]},{"name":"Haitao Yuan","ids":["34825854"]}],"journalName":"","paperAbstract":"Crowdsourcing database systems have been proposed to leverage crowd-powered operations to encapsulate the complexities of interacting with the crowd. Existing systems suffer from two major limitations. Firstly, in order to optimize a query, they often adopt the traditional tree model to select an optimized table-level join order. However, the tree model provides a coarse-grained optimization, which generates the same order for different joined tuples and limits the optimization potential that different joined tuples can be optimized by different orders. Secondly, they mainly focus on optimizing the monetary cost. In fact, there are three optimization goals (i.e., smaller monetary cost, lower latency, and higher quality) in crowdsourcing, and it calls for a system to enable multi-goal optimization.\n To address the limitations, we develop a crowd-powered database system <b>CDB</b> that supports crowd-based query optimizations, with focus on join and selection. <b>CDB</b> has fundamental differences from existing systems. First, <b>CDB</b> employs a graph-based query model that provides more fine-grained query optimization. Second, <b>CDB</b> adopts a unified framework to perform the multi-goal optimization based on the graph model. We have implemented our system and deployed it on AMT, CrowdFlower and ChinaCrowd. We have also created a benchmark for evaluating crowd-powered databases. We have conducted both simulated and real experiments, and the experimental results demonstrate the performance superiority of <b>CDB</b> on cost, latency and quality.","inCitations":["1dedeaa3cda8a50d6f7f6980fc573a5d4a70e265","843b86e94ee75f40f458b73de6efb4b125e8e4ee","60737db62fb5fab742371709485e4b2ddf64b7b2","aa96a257c28225901006502266aa65877897dc5d","e4792a28cec6ac4fcc3c4ebdd3931483f660fa79","2b89301f592033f0001f5d79ce33163d9249caab","4d96002263faa311fa61d7fefda7361061356f26","f87c7779f7cf430d8f72a204bc6a39065bea3631","31d6b211735d7e93fbc7629a731403c9e4644b7c","b3530b8eda702a53023281a1c744c2d1f6c1b5b4"],"pdfUrls":["http://dbgroup.cs.tsinghua.edu.cn/ligl/papers/sigmod17-cdb.pdf","http://doi.acm.org/10.1145/3035918.3064036"],"title":"CDB: Optimizing Queries with Crowd-Based Selections and Joins","doi":"10.1145/3035918.3064036","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064036","venue":"SIGMOD Conference"},
{"entities":["Computation","Experiment","Online analytical processing","Program optimization","Scoring functions for docking","Synthetic data"],"journalVolume":"","journalPages":"1509-1524","pmid":"","year":2017,"outCitations":["62a29c2179d244c38b7b5fd4e53d760c32fec860","a0203b4a547a6d172a053d39d1d618ee47ce3e31","9833c197cc28947d9ad411849a9fecf9c4f57a01","b6eb482777d1686f6ea2b0e2d05cb0ec9431a6b3","e87a36d7455ef16fb17752f02c305d696dee9e15","a6078ad365012c1f527c192894a9184daab8e597","4e3c1f3904d4b5404a03b6101370841f7c4798d5","8a394cff2d0ee0607cbcf3d94bf65743fd858731","ac091df499518a3fe5918ad66a74a9e7b5b260f4","3b86fe77c59c0ad615773b3898cf9f17df4fa3a3","2962a76dc7ffb53e7fa8a6a251b07be206c86476","7b35afd47433b635ce090e87997cb2dfdc79da5a","3f419db6f66c32bbb7ea887b139abd4e088a0405","88bc09e1505da44f05a96cdffcbee232000af549","a401596b7c337afefe0ea228ef9cd4908429b43a","8631ae4a69f409ed09f451867c3ef4bf17129b79","475266810bb4aacd984b3863eb0ee4bd20e8dc55","ae9192b19dc64d2dd3954674d1c33b2f61fe993b","fd37acd0204d55738acb7cf28b32fb56f9ebb6db","10e4cd0d4f1dbf0accdedc5261555499a2e0c34d","1317f7e3d1de6ffd0888303ca95d9c8c6bae2af3","6f4db26ef56717c7cfe3baad61667a82dc70a6f6","008b18ee86a04bf65e461c9d77f56bcbc28c3788","a24d39e7c504a5705e4a480f99c1461992931934","71fcfabb8c284be5acd1bd3aea0d7d602fb1d03d","65e0af21793f0dc748a1755b736db4fbeb9bb4e8","4dcce6c317aedc617533710f40c084ca86ee8386","299613bc57efd6e4bb590878220ecdd1d222d7b1","08639cd6b89ac8f375cdc1076b9485ac9d657083","e5208097b88a4f0d73c28c3c669b17ed8f369c22","794fd8c71e8d70f2d74b7877729b6f6966053c3a"],"s2Url":"https://semanticscholar.org/paper/9b4f7a1a1a749cce6f797bbaa9719db4e3569c51","s2PdfUrl":"","id":"9b4f7a1a1a749cce6f797bbaa9719db4e3569c51","authors":[{"name":"Bo Tang","ids":["40351860"]},{"name":"Shi Han","ids":["1715843"]},{"name":"Man Lung Yiu","ids":["1722082"]},{"name":"Rui Ding","ids":["1879091"]},{"name":"Dongmei Zhang","ids":["1711277"]}],"journalName":"","paperAbstract":"OLAP tools have been extensively used by enterprises to make better and faster decisions. Nevertheless, they require users to specify group-by attributes and know precisely what they are looking for. This paper takes the first attempt towards automatically extracting top-<i>k</i> <i>insights</i> from multi-dimensional data. This is useful not only for non-expert users, but also reduces the manual effort of data analysts. In particular, we propose the concept of <i>insight</i> which captures interesting observation derived from aggregation results in multiple steps (e.g., rank by a dimension, compute the percentage of measure by a dimension). An example insight is: ``Brand B's rank (across brands) falls along the year, in terms of the increase in sales''. Our problem is to compute the top-<i>k</i> insights by a score function. It poses challenges on (i) the effectiveness of the result and (ii) the efficiency of computation. We propose a meaningful scoring function for insights to address (i). Then, we contribute a computation framework for top-<i>k</i> insights, together with a suite of optimization techniques (i.e., pruning, ordering, specialized cube, and computation sharing) to address (ii). Our experimental study on both real data and synthetic data verifies the effectiveness and efficiency of our proposed solution.","inCitations":["389f93511963d4e0032bc79be3ce1a340aedbeed","7f75690619d23375011b658e67994284fa030477","d9f320601fc7bcff3aed567f06c0bb4014efaf72","4f34a05ba6ab9cdaab97656ed1cb44fb2e112f4a"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035922"],"title":"Extracting Top-K Insights from Multi-dimensional Data","doi":"10.1145/3035918.3035922","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035922","venue":"SIGMOD Conference"},
{"entities":["Bitcoin","Cryptocurrency","Distributed computing","Ethereum","Fault tolerance","Peer-to-peer","Relational database management system","Scalability","Smart contract","Solution stack","Synthetic data","Systems design","Throughput"],"journalVolume":"","journalPages":"1085-1100","pmid":"","year":2017,"outCitations":["6fc9cd15134cdd282e25b8ea58b38240e96bfe90","155ca30ef360d66af571eee47c7f60f300e154db","9748241beb02ef1e2d0e6dc877c04b354033a838","35516916cd8840566acc05d0226f711bee1b563b","401680ef12c04c247c50737b9114c169c660aab9","75d83792b880757a09e9a72978cc29beb57c4ad5","226cfb67d2d8eba835f2ec695fe28b78b556a19f","1f102935cc21d54f91ae70c09d84157b6011e6dd","1220e4a011c46804d4369b5580dc7fb6e387af54","33457f49553d918e912c2d8c54b81f4fd8a4c234","3fad56eb0379f9684af608bd6c9ad4de706b4cad","165d99c9d30be5d301b998dc23c1a6a28fd0c425","40a98bed1d10248d30e86304315df07280dad93e","10551c91b4d36d1009b23b4d2b88a9e1733fe029","261893f4c8a7c311a97249a8f42071c566372493","02b1103e592fa6bf0499e27f1519692441fad557","43fb74fc45ea844ad087c770fa9be747fbd03b19","17c6f330d854435e8d8faed245f79b94740a45f1","9aa0d7253574e50fe3a190ccd924433f048997dd","136eefe33796c388a15d25ca03cb8d5077d14f37","e0a854efc5b966f2ac2f7bbcda092ef63d627871","138ab4913b7218c5835527296e87defb8dfaf206","b02c6b00bd5dbdbd951fddb00b906c82fa80f0b3","06b7f3156ef8f0d66fe05e504c0bb908ab288c03","12d854f326b43232d906eb323db5d282786acb9d","7be14a23d26a19786ed97807fa8bfbf11b299984","20f5f8733134d87041b95b742d613051a1fb3fdb","095a3cee30d64d3a6f22caadd58c45c5cd0b83e9","4ab6b28bb3342cb4f65555a37418b6a25297425e","5e86853f533c88a1996455d955a2e20ac47b3878","0d2c4723e9e5925cde74bd879611fda6f6e3980b","efb1a85cf540fd4f901a78100a2e450d484aebac","88a603ffe828c503b6818410bdb3dae435f90ebe"],"s2Url":"https://semanticscholar.org/paper/5fdf836f5ff96b96433f18464926103a29114552","s2PdfUrl":"","id":"5fdf836f5ff96b96433f18464926103a29114552","authors":[{"name":"Tien Tuan Anh Dinh","ids":["3088916"]},{"name":"Ji Wang","ids":["5107518"]},{"name":"Gang Chen","ids":["39076756"]},{"name":"Rui Liu","ids":["1684598"]},{"name":"Beng Chin Ooi","ids":["1693070"]},{"name":"Kian-Lee Tan","ids":["1688848"]}],"journalName":"","paperAbstract":"Blockchain technologies are taking the world by storm. Public blockchains, such as Bitcoin and Ethereum, enable secure peer-to-peer applications like crypto-currency or smart contracts. Their security and performance are well studied. This paper concerns recent private blockchain systems designed with stronger security (trust) assumption and performance requirement. These systems target and aim to disrupt applications which have so far been implemented on top of database systems, for example banking, finance and trading applications. Multiple platforms for private blockchains are being actively developed and fine tuned. However, there is a clear lack of a systematic framework with which different systems can be analyzed and compared against each other. Such a framework can be used to assess blockchains' viability as another distributed data processing platform, while helping developers to identify bottlenecks and accordingly improve their platforms.\n In this paper, we first describe BLOCKBENCH, the first evaluation framework for analyzing private blockchains. It serves as a fair means of comparison for different platforms and enables deeper understanding of different system design choices. Any private blockchain can be integrated to BLOCKBENCH via simple APIs and benchmarked against workloads that are based on real and synthetic smart contracts. BLOCKBENCH measures overall and component-wise performance in terms of throughput, latency, scalability and fault-tolerance. Next, we use BLOCKBENCH to conduct comprehensive evaluation of three major private blockchains: Ethereum, Parity and Hyperledger Fabric. The results demonstrate that these systems are still far from displacing current database systems in traditional data processing workloads. Furthermore, there are gaps in performance among the three systems which are attributed to the design choices at different layers of the blockchain's software stack. We have released BLOCKBENCH for public use.","inCitations":["24bb8328ad26f21ca2e2322ec2c5da16586dccac","d66add194ef618c4573604261cf6e52758a73fb0","77d484b0194698366ba118e28287896829cf6dfe","1c7f5288f4a2ca577d4232be9b8ff6ec5ce6cfd9","71c5bc722f575665878dc3ca47953f384426899a","ba83474ac983727ad9436891653fff68ebbd35f2","3ea55098cf9e8216139f30d64b5c737a726d466c","4a2816c8311329ad3c438f752b751652408c82f3","919e32847097416aada92dff7c8274cd9ca55582","0a9f9398aa1af2a3f61755ed299d6c7d036dd3ba","fda96fc9a88b4527804aa47a5442767bd99d90f8","7744387e05e44276a52769cb2a42c1bec1aa293d","5ef21885ff7a4b29d07d65663bc669a324f46c51","a22f52c7555f955cfc6720f7c1b89eb4af613a4d","64cf3131b34719f624d3cc47855d859059c4cbaf","901c0c68e0cf0dc84d3f1f4ac7195b9a667da4bd","beb6c6bc12e3756046fd5cc911b17d5d214d4a63","c6724504d239409210284f203706a4600ff3c91b","5b9c203dbe31cff3ec1c12b7e80e7b4fc5a1994d","17b84f0e092401b88b2505c145890d1d0db91219","18f806215ccbf797ad38bbc2ed465d3b1c8ade08"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064033","http://www.comp.nus.edu.sg/~ooibc/blockbench.pdf","http://www.comp.nus.edu.sg/~ooibc/blockbenchp.pdf","http://arxiv.org/abs/1703.04057","https://arxiv.org/pdf/1703.04057v1.pdf"],"title":"BLOCKBENCH: A Framework for Analyzing Private Blockchains","doi":"10.1145/3035918.3064033","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064033","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Experiment","Interface (Java)","User interface"],"journalVolume":"","journalPages":"1133-1148","pmid":"","year":2017,"outCitations":["762aa12db17ecc3ed8320e1d88bef063214b595b","5f11f3d958581f53b20577da69c9f7bc25c2ff2b","060bdc422872e375bbef9b1cd82fbf0f936d4691","370b5757a5379b15e30d619e4d3fb9e8e13f3256","632eca15ed20f87490c60a6005c4c58f06bee61b","45254b2dda5bcb0ed069a58c1173cced4d776660","00e95e8491f4c3ae1d6e7a05da1afb132f3f4e45","28015578d74becc4e34789de6b22d2d6321547c7","3d359fca5a3b632d890f1640d78defc09a561d8d","445e4442ce33a04d5c4d45eb191f431e0bc2444c","ac773c345d751659d1c249dd5f2d6fe7ab13afcb","2dec6e69f42b22d03208ce01afc103a7d702f276","8a0b267493ac9510e47ceb4bcebb6d202b2f89a5","86e9134ff5e144d4f4d4243ec66351cc068ab409","151673abe01271dc3fc37725c02e95e7970f3bed","213cb7593934bc675c336f53dd6c61a3c799be80","6621bbf82c49abe99bb49ea03c8789af67b58c20","10ae68dea2ce4426eb0d87c99c1094504469752a","08f51a9138458f667f0c00d40b6a820c451c7d36","c921482cb0048738284aa66e531b83f64ce46bf5","20d90871bc0dc7956bf2557d91d8d96deb0a4520","4f819589fd2931333326ad7deec58f628f7d2644","15904f4fb558e33fbd607c0289a2a0deb746d73d","009b37cf7dbc9da978d4fa604257e2e6020fd478","af1e1bee41d004a6c1fa608a9fe2a884f48c6e5f","3d24e2327a0ba1cb2f3b5b2bf41dd450703f8e56","708b3c509e2ffee76918faeac18692f9ca527582","4033104e3a37324df023fec7e95d852e962617de","04272a11aa0a8c8a9fe1d47b4e64f7578211fdde","47203943c86e4d9355ffd99cd3d75f37211fd805","d84af7f39033a084d9ae95fe895d39b9ec5246dd","2a8969bf0a02a2fa28e3784fd6025828859a7f67","2a8a3e00b978e4ae12da7fe536b7a5a719c0f0ef","88cd4becf3587a8378e450a99ded801fbdb264e1","8bc23235070ce181d34002e2a44e4b233beaa732","0cdfc808cec0254f1037909e8955c07bc7755842","b9e43395663f74c581982e9ca97a0d7057a0008c"],"s2Url":"https://semanticscholar.org/paper/c0a8c0e6ccf9882969ba0eda0b898affa015437b","s2PdfUrl":"","id":"c0a8c0e6ccf9882969ba0eda0b898affa015437b","authors":[{"name":"Vasilis Verroios","ids":["2912732"]},{"name":"Hector Garcia-Molina","ids":["1695250"]},{"name":"Yannis Papakonstantinou","ids":["1786049"]}],"journalName":"","paperAbstract":"In Entity Resolution, the objective is to find which records of a dataset refer to the same real-world entity. Crowd Entity Resolution uses humans, in addition to machine algorithms, to improve the quality of the outcome. We study a hybrid approach that combines two common interfaces for human tasks in Crowd Entity Resolution, taking into account key observations about the advantages and disadvantages of the two interfaces. We give a formal definition to the problem of human task selection and we derive algorithms with strong optimality guarantees. Our experiments with four real-world datasets show that our hybrid approach gives an improvement of 50% to 300% in the crowd cost to resolve a dataset, compared to using a single interface.","inCitations":["b672d76d09d076ea148ea4b22e4fe907f2dc4a47","0bcb4ab04e1ebabbf67a38bd7b20b8c660018add","7e59154a0446de99a18400a43e65c0905f248cd4","a18ed9b20cc855088151f6edc04bbd51edbffb00"],"pdfUrls":["http://stanford.edu/~verroios/papers/waldo.pdf","http://doi.acm.org/10.1145/3035918.3035931","http://ilpubs.stanford.edu:8090/1137/1/ERMultiItemTechRep.pdf"],"title":"Waldo: An Adaptive Human Interface for Crowd Entity Resolution","doi":"10.1145/3035918.3035931","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035931","venue":"SIGMOD Conference"},
{"entities":["Expectation–maximization algorithm","Experiment","LU decomposition","citation"],"journalVolume":"","journalPages":"","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/93fa87cb34f0acd595b1c755ab9b716507c5dc31","s2PdfUrl":"http://pdfs.semanticscholar.org/93fa/87cb34f0acd595b1c755ab9b716507c5dc31.pdf","id":"93fa87cb34f0acd595b1c755ab9b716507c5dc31","authors":[{"name":"Akhil Arora","ids":["2644814"]},{"name":"Sainyam Galhotra","ids":["2663974"]},{"name":"Sayan Ranu","ids":["1699732"]},{"name":"Amit Goyal","ids":["1770151"]},{"name":"Wei Lu","ids":["37782777"]}],"journalName":"","paperAbstract":"Before we start, let us give the following background information that sets the context. 1. CELF++ is a paper (more than 260 citations) authored by Amit Goyal, Wei Lu, and Laks V.S. Lakshmanan. CELF++ claims to be 35%-50% faster than CELF. In our study, we firmly establish that this claim is not true. 2. We are currently in the process of submitting our experimental environment to SIGMOD 2017 reproducibility committee. This will enable validation of the integrity of our experiments by neutral third parties.","inCitations":[],"pdfUrls":["http://www.cse.iitd.ac.in/~sayan/refutation.pdf"],"title":"Refutations to \"Refutations on Debunking the Myths of Influence Maximization: An In-Depth Benchmarking Study”","doi":"","sources":[],"doiUrl":"","venue":""},
{"entities":["Algorithm","Approximation algorithm","Data item","Deployment environment","Feedback","Social media"],"journalVolume":"","journalPages":"603-618","pmid":"","year":2017,"outCitations":["cd48760a142830b796b8a85a158cd469f3e5feb0","04f39720b9b20f8ab990228ae3fe4f473e750fe3","1b763ec4c21c799eef00ca26f6afc6c01b45a82c","579e1e9217cfed6d563cedf8f8fdcd1604fc0917","208b70d2cb06b17b8d48a907dc2ad2f4272a8588","4fd6f95aca0da395078d63c4f3be5a51f3ffef55","4f84bcbddad1e931b0328be6e0a96ca731c538f8","762aa12db17ecc3ed8320e1d88bef063214b595b","09c7a7213053784e2b1487de5a08c22f6a0daef0","25f9f4f10d8d1818746e57283d7b1a0fb4c44ff0","561b0881fb83c7182bca4aec70bd287ea0f5be28","d641ce8fe01ba5ae0ade43feaa1e1e2a7f4839b8","0a2ca1578c006796da813e9d16ccdd1d3b737565","6b81212ebb2d83c8c35b00016a7e9e36d99f62ac","20d90871bc0dc7956bf2557d91d8d96deb0a4520","422d9b1a05bc33fcca4b9aa9381f46804c6132fd","af1e1bee41d004a6c1fa608a9fe2a884f48c6e5f","12653dc3882f76c6933d7543bd5e033dd18b56e0","4f819589fd2931333326ad7deec58f628f7d2644","baf499e0b0ebe4985cdf1a4c08a4a4e465ce3e59","17714c1a50e306227cd5cd56af0bc203c7e43db7","0ac93570bab7aec97bf01eb5387372ee5cb7f94a","a12cd3d9ae5530a90302a6e4af477e6e24fa0f95","dbe98d292cc8d69f0673cc5c524c9bc282067bf8","1ec2d02bd12f3a357449cf1bbc67b6adf7cd6296","1b189d721adbf1d2bab93b7ed6ce826e188b0b99","006336b4082bbba1ab1e5e2e6c633a44971a7dc3","009b37cf7dbc9da978d4fa604257e2e6020fd478","e1d2ea5d876a526b915a450e2cb23581600e3750","371fc532e70dc5a72c49eb3503ae1f707f38ea7d","2cca87876d142c75626304700fb599e7944cf338","44cb3d4193fadcea42a3a657ddd67b18d6ddc87e","0e5ebc2eb31b6c78ee0dee10246efeeaf587f7f4","e541c475457a731d7d434c4302867fc45af5876f","af2a807c5e32a35765850c6b6891f471d7bc7aea","22f516acc61967369ec29d4121c7b517d5f60e08","796510d962c5abf8c6436b64946506d6234ae506","453c5a0ff2b97746de65153a2ea39799458585e7","4359e7b1bba1e7a37a591111cd5c719fdb4857c8","65821014abe934029310cb10d4e329645acd4817","4f739534a366799e170599d3ff3d65597f0118db"],"s2Url":"https://semanticscholar.org/paper/68716519c7d3d6b2e1fabc0cf40f0a3fcfdecab0","s2PdfUrl":"","id":"68716519c7d3d6b2e1fabc0cf40f0a3fcfdecab0","authors":[{"name":"Romila Pradhan","ids":["10787402"]},{"name":"Siarhei Bykau","ids":["2147072"]},{"name":"Sunil Prabhakar","ids":["1771369"]}],"journalName":"","paperAbstract":"In domains such as the Web, sensor networks and social media, sources often provide conflicting information for the same data item. Several data fusion techniques have been proposed recently to resolve conflicts and identify correct data. The performance of these fusion systems, while quite accurate, is far from perfect. In this paper, we propose to leverage user feedback for validating data conflicts and rapidly improving the performance of fusion. To present the most <i>beneficial</i> data items for the user to validate, we take advantage of the level of consensus among sources, and the output of fusion to generate an effective ordering of items. We first evaluate data items individually, and then define a novel decision-theoretic framework based on the concept of value of perfect information (VPI) to order items by their ability to boost the performance of fusion. We further derive approximate formulae to scale up the decision-theoretic framework to large-scale data. We empirically evaluate our algorithms on three real-world datasets with different characteristics, and show that the accuracy of fusion can be significantly improved even while requesting feedback on a few data items. We also show that the performance of the proposed methods depends on the characteristics of data, and assess the trade-off between the amount of feedback acquired, and the effectiveness and efficiency of the methods.","inCitations":["80c7ad5e1d47a7acca3c886c426bb5f1efeaa7a4"],"pdfUrls":["https://www.cs.purdue.edu/homes/rpradhan/p603-pradhan.pdf","https://www.cs.purdue.edu/homes/rpradhan/romila_userFeedback_poster.pdf","http://doi.acm.org/10.1145/3035918.3035941"],"title":"Staging User Feedback toward Rapid Conflict Resolution in Data Fusion","doi":"10.1145/3035918.3035941","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035941","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Baseline (configuration management)","Discriminative model","Logistic regression","Machine learning"],"journalVolume":"","journalPages":"1399-1414","pmid":"","year":2017,"outCitations":["ba24bd33caaa38127664f86d1bb486ac508b8a47","8a0a50fba24e68117ca95dba8028ef4e98093684","cd48760a142830b796b8a85a158cd469f3e5feb0","1af0851efa40686b6d06e8678967d8140fd7bc68","3bbfc62fc13ca27c6e58e42167a6aef593a1365e","41f1ebd4c8486614f5830794220df217281d507c","f440916284dae249d26d195458f084fe08aa3aec","579e1e9217cfed6d563cedf8f8fdcd1604fc0917","1a0f8261d8384bfefbf2d561d446c3a687a5febe","e01c4177fb9ffff49891b995418ec67be922bb7a","1d604a0a5b17db632a4b77df35f62be129822e25","1354ba1b6567f869065e9515a488bc031a00e25a","79f9e562470ea00d1bba08fd1fba8cc46d96f211","2234eb38be155cdc19bcce79bc8d54b188c8a3a2","2433ef214583e369426c7755f396b417b4caa32a","a12cd3d9ae5530a90302a6e4af477e6e24fa0f95","79a4ce582dae39b2cbb0fab5de1179fe2581ce95","af2a807c5e32a35765850c6b6891f471d7bc7aea","0790c77c1eaf2368b55c6a0def09a43690eeb848","117da44f01ef45ef8223bec8f9c2346b131321f4","04b314e6ab6f3139c89d8c7735359026afe09c3b","4607f09a348c87f95aedd7711b24d8bf614fe58c","4f84bcbddad1e931b0328be6e0a96ca731c538f8","2c37666634d2e50b998f68dcbef42aae16e02645","27d6326993f80269595b2a594657754bf748927c","208e395593f6a0d8e0325bc1a3ddfac1aa54df80","1b65af0b2847cf6edb1461eda659f08be27bc76d","0e5ebc2eb31b6c78ee0dee10246efeeaf587f7f4","1b189d721adbf1d2bab93b7ed6ce826e188b0b99","0f5c9968fe2cdb0f52c55b2d5b3dec7accf91306","e37dc8a58f39ca8f159e4a71af3766381ea18356","0a508835d4e9ae700fb056c4c0c7774255b1179f","65821014abe934029310cb10d4e329645acd4817","0e1b90fd2e39e6c9aa3bcf7e8ccacc30d724ab58","4c7779938bd80f62f80d6964c89a97476eef7c69"],"s2Url":"https://semanticscholar.org/paper/4fb3c6d92273a976ad4cfd08060bcc164ab7516d","s2PdfUrl":"","id":"4fb3c6d92273a976ad4cfd08060bcc164ab7516d","authors":[{"name":"Theodoros Rekatsinas","ids":["2652697"]},{"name":"Manas Joglekar","ids":["2185778"]},{"name":"Hector Garcia-Molina","ids":["1695250"]},{"name":"Aditya G. Parameswaran","ids":["1801540"]},{"name":"Christopher Ré","ids":["1803218"]}],"journalName":"","paperAbstract":"We focus on data fusion, i.e., the problem of unifying conflicting data from data sources into a single representation by estimating the source accuracies. We propose SLiMFast, a framework that expresses data fusion as a statistical learning problem over discriminative probabilistic models, which in many cases correspond to logistic regression. In contrast to previous approaches that use complex generative models, discriminative models make fewer distributional assumptions over data sources and allow us to obtain rigorous theoretical guarantees. Furthermore, we show how SLiMFast enables incorporating domain knowledge into data fusion, yielding accuracy improvements of up to 50% over state-of-the-art baselines. Building upon our theoretical results, we design an optimizer that obviates the need for users to manually select an algorithm for learning SLiMFast's parameters. We validate our optimizer on multiple real-world datasets and show that it can accurately predict the learning algorithm that yields the best data fusion results.","inCitations":["74eb71bd943149764f54f411905bf6607bb91c39","fa099d45212e0b0e6486b6bd378e6f4fd06c222d","04898f9bfdfedf6ee63310f324949caffb9c6b29","715bae3cbbb2c3d13b0d128f3ff323815bb59495","3729ef7703006d2b17a3d5215654cc3e7bb694a1"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035951"],"title":"SLiMFast: Guaranteed Results for Data Fusion and Source Reliability","doi":"10.1145/3035918.3035951","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035951","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Baseline (configuration management)","Data model","Data structure","Geocaching","JSON","Missing data","MongoDB","PostgreSQL","Program optimization","Protocol Buffers","Relational database management system"],"journalVolume":"","journalPages":"883-896","pmid":"","year":2017,"outCitations":["3a134bc11a5805bcf45fdcb88a91321a1b1b63c3","2cfbdfcf3f590cbd7a6c9c4299eb42569e77697c","0c8288f4a91bdf129491370cd3919959207b2dcb","1156f60e40548096df49528b1342bb3e88b0f378","03363ed04e9d4d2e8c9348551815e80615969611","cd4b958bf9dda5f44fbb457f7bf0eca96d6563e7","43715cdc52b75ffaaff701852deafc4736a89081","85ee4bc37077c3809fc220a94994bef6a8bc4391","22725ce33c721a6e75052ac5a39e567a8b363719","33f9d19cdb5f3df4c5c36237290449d6dc0f8746","8dbe22a1987448c3fb6470de2fe7e5976a62824b","235864238ef9cea6a0bea7e31fbbc712dfadfb5e","55e4ae822a9ec7ac4e07dae07877392b7045ae92","13f6bbc21047ce4eba895c9ed308d947eca8fbee","7400fd9304f1b4b7bfb9f4150adc5e1745afca9c","0997037e940df06ed7a6d19f7501579aab01e829","1455be30b0bb364ffc4c35d2cf1ee05cfb32595f","0558c94a094158ecd64f0d5014d3d9668054fb97"],"s2Url":"https://semanticscholar.org/paper/0a5e40e7f9b754882d2096598e0080ee2b40b2f1","s2PdfUrl":"","id":"0a5e40e7f9b754882d2096598e0080ee2b40b2f1","authors":[{"name":"Zhiyi Wang","ids":["8491987"]},{"name":"Shimin Chen","ids":["3329563"]}],"journalName":"","paperAbstract":"Tree-structured data formats, such as JSON and Protocol Buffers, are capable of expressing sophisticated data types, including nested, repeated, and missing values. While such expressing power contributes to their popularity in real-world applications, it presents a significant challenge for systems supporting tree-structured data. Existing systems have focused on general-purpose solutions either extending RDBMSs or designing native systems. However, the general-purpose approach often results in sophisticated data structures and algorithms, which may not reflect and optimize for the actual structure patterns in the real world.\n In this paper, we aim to better understand tree-structured data types in real uses and optimize for the common patterns. We present an in-depth study of five types of real-world use cases of tree-structured data. We find that a majority of the root-to-leaf paths in the tree structures are simple, containing up to one repeated node. Given this insight, we design and implement Steed, a native analytical database system for tree-structured data. Steed implements the baseline general-purpose support for storing and querying data in both row and column layouts. Then we enhance the baseline design with a set of optimizations to simplify and improve the processing of simple paths. Experimental evaluation shows that our optimization improves the baseline by a factor of up to 1.74x. Compared to three representative state-of-the-art systems (i.e. PostgreSQL, MongoDB, and Hive+Parquet), Steed achieves orders of magnitude better performance in both cold cache and hot cache scenarios.","inCitations":["add330e246b1f4886c94e73cd53e1e95cae9dee3"],"pdfUrls":["http://www.cs.cmu.edu/~chensm/papers/steed-sigmod17.pdf","http://doi.acm.org/10.1145/3035918.3035956"],"title":"Exploiting Common Patterns for Tree-Structured Data","doi":"10.1145/3035918.3035956","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035956","venue":"SIGMOD Conference"},
{"entities":["Byte","Data deduplication","Database","Delta encoding","NoSQL","Online and offline","Throughput"],"journalVolume":"","journalPages":"1355-1368","pmid":"","year":2017,"outCitations":["218dd67596de2ca4846ef8a3c8e86231f7d8e84c","3437a7e23e3f97b58f4cf73e7e5b711131e6706c","045943438dd45f25f0127d97ed9116b3b05914a7","206d1ddfd889dd5b7b49177f15ea328bccac3ad2","4c664c7015285ce14063204d0790dffbb7bbf46c","f458bd30b0f27959b1147ea8afa08ec8fef94ad5","0ce479229630e55e732597cf9b2aeb5018aae4c2","0133126c02871c8ff00ac42a13f74e756d076cb0","a6b9d9ee907bbe398918364107747c6dac097590","511461524439a32df5cfaa5b3230e7330b5b9153","233960d0d4351869ba179f2aa7d89405977ab00e","a1330395dda0d0174926f5152778ead7925983f7","caa4063e08a1f7b0365b435c0b629fe319f4277f","924276d95d1bdaf087beb0ccf699443b9bf855ec","a040e419355efde5d32101658f0b12f62e49760f","6bccf2ba321177023d0f1d83484ae81fba687d97","b2ec74c72d99b755325dc470dec2949d69cd4d57","207def18c67fa8024741b7ae3cdc655b57f2053f","bb90aa0bd362d615e3598f52504d06b20125512d","caa8b09412fc11c4963a744dae82d6d50beb8df7","2c5b8766a1dae62b86ba38013253ab8673f6ec44","6d5cfe7723c61149d9cf905fe173268075b8c976","4913df252b4cb41a83d3f2376c8b1dbb1317b57d","21318da2ea08c1f7b8c77701f67483882950df96","a611f2c3b7a4b1ab6db8d4fbf6584edbe78e86ff","511c5d949e6966e5c2f152f2312c6081fb97a614","92a6961f076307d5b4778fd45d5f01f6d5d84e12","0a27bcc0733a3fd4dd7e14b4796c854f73d9465d","24fbb6a0817965f76812902e8b822030f6c5a6cb","24cef48316f1e73414b50ab4f702414b2778d49b","44607270754f8521d6c4d42297aa881393f4f8e0","05d9391c61fd6b3ae92f852a7bb12257cc86800d","488495c644d90c32ef7b58ec3e4ffc7b40f25b36","088bd567f0fafc6db9310820629d75ee1dd5ea9c","3a134bc11a5805bcf45fdcb88a91321a1b1b63c3","333617a8bd0d54f70b234afe385e59c660731135","044a9cb24e2863c6bcaaf39b7a210fbb11b381e9","6d1ca1108d9d96e5607571502552ad04464d7f15","fb1c77d492576d52173a56730a4dc5991217db6f","42e4fd620dab3d6b77ce2e0e19aeaa234c434c5b","0c279813f1dba545c50c237f69b89c6496117015","38a4d429f9e96ae37489e6b56b560ad24048b4b4","481086af0ac174dc0416bc7daf33100fab5c649b","898b60ae12a855ac9ad91f93543d82ce00ee76ff","00f149a044b76834b69a05e4ed46cabb81e47e85","55443845d561f05a864bcf8a2cb90af32bed89c3","04f020a4ab2134db6f9e98eadf216d94d440414a"],"s2Url":"https://semanticscholar.org/paper/525cd0a3f46f3d7427a2282aec5c97e92d2f0308","s2PdfUrl":"","id":"525cd0a3f46f3d7427a2282aec5c97e92d2f0308","authors":[{"name":"Lianghong Xu","ids":["2184366"]},{"name":"Andrew Pavlo","ids":["1774210"]},{"name":"Sudipta Sengupta","ids":["1690586"]},{"name":"Gregory R. Ganger","ids":["1707164"]}],"journalName":"","paperAbstract":"dbDedup is a similarity-based deduplication scheme for on-line database management systems (<b>DBMSs</b>). Beyond block-level compression of individual database pages or operation log (oplog) messages, as used in today's <b>DBMSs</b>, dbDedup uses byte-level delta encoding of individual records within the database to achieve greater savings. dbDedup's single-pass encoding method can be integrated into the storage and logging components of a <b>DBMS</b> to provide two benefits: (1) reduced size of data stored on disk beyond what traditional compression schemes provide, and (2) reduced amount of data transmitted over the network for replication services. To evaluate our work, we implemented dbDedup in a distributed <b>NoSQL DBMS</b> and analyzed its properties using four real datasets. Our results show that dbDedup achieves up to 37x reduction in the storage size and replication traffic of the database on its own and up to 61x reduction when paired with the <b>DBMS's</b> block-level compression. dbDedup provides both benefits with negligible effect on <b>DBMS</b> throughput or client latency (average and tail).","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035938","http://www.pdl.cmu.edu/PDL-FTP/Database/xu-sigmod17.pdf","http://db.cs.cmu.edu/papers/2017/p1355-xu.pdf"],"title":"Online Deduplication for Databases","doi":"10.1145/3035918.3035938","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035938","venue":"SIGMOD Conference"},
{"entities":["Approximation theory","Column (database)","E-commerce","Experiment","Full table scan","Latent variable","Lossless compression","Recommender system","Singular value decomposition","Social media"],"journalVolume":"","journalPages":"835-850","pmid":"","year":2017,"outCitations":["05cd61c2172e4c25f43ddb0b0927ffec19643d84","d77f241856426005313e17ff9927c3396cb0d340","9ba53f53a55f22626e9496f2ddb7e58266640c37","5fa10e1a3ebaee27ce015f406508f82f8dcf5be8","8724631b1b16469fb57df1568d41d1039067c717","3ae4e53bcaa8f949184dfd6118a85c79c01053e7","9aa88a8a354f1d322e242376d27d0474e50252f8","1e96b0c0ac74070a984fec94f085109839d842a9","4e8f82b0741c2151d36f2201fc11b0b148beab60","c32e8d3d86695d2da36ccfce60d51956e2e4818c","0d338e5bc70e81ea54fbd2c7535e21728fe7deb1","63eaeb0c48175065ffd096aad10aed712c6d7bbb","ebade6ec686beb98fa1e1962442841ee543c6d76","d5fdc3c0b2049a025091179a73e0e4174105fcd4","c6c5b2c0eea2912b8a099cfa190875c6e616c217","44f4cd28486c4730fbfb262f099cb5df30637211","031854648e0688c1bfc991e7597e54947928fb74","1c799eca7983c62f7815ac5f41787b3e552567b6","00df20e5bf5d9d645184191a34c43a4108e92723","14f264a888912d2bb0defc2ba554e784e4e31fe6","1d03698a46ff12fdfaf4811528b3e7961dfd2fe6","637ab11fdb719115ccc4e36110d7139435181d20","24c48b97725d84246f6dbd39c055648a305e1df4","dc66c34ce9e477f67eaf847fc331244b562d8fea","530d53d8a1828e73ff0d731cd2d2cf8a8f8ecae4","1662ea4412e019883ac6c02dce63929808fd73d3","794157feebd12d23a852ce83c40e851d94559915","6907047e7cd11e9885ba2deb37d44a92cfce6136","5ae98595bba7eb02ba95df2989871bfa86fb02cf","1f2de093c64679c99437c3031ede4fd4e32c66cc","064fb3a6f2666e17f6d411c0a731d56aae0a785e","09849ca4b8159ff69721ebb2f25a81025188937e","091aded505b84cf87c197875ccfde24d98a300c9","89d27fc4c5bf15762d001a39f0a74f84c89d3681","582003042f767f22e4119040909823f94f3cbea9","5d67a05724b0eeba4e3e9d91fd63cfd03548cf23","1000025264ef85af0b116b3c12d5b283504d36eb","1697a4188b9f75ff5324eb9957b8317f459bbf59","2ebf3b1c0084cf6e57dd8ef921c2ca36d72d6a75","1b7944d00948f4a1826763cecd3452ba2da89873","91b4a69f89e9b6677c8775f9f84a5924af8e7fa7","7765adf12035ead4b0e8ab7aece41b3f549f8def"],"s2Url":"https://semanticscholar.org/paper/5f926eab40abdd9895e4eb4c8c07f240b9096427","s2PdfUrl":"","id":"5f926eab40abdd9895e4eb4c8c07f240b9096427","authors":[{"name":"Hui Li","ids":["1703309"]},{"name":"Tsz Nam Chan","ids":["2610571"]},{"name":"Man Lung Yiu","ids":["1722082"]},{"name":"Nikos Mamoulis","ids":["1718168"]}],"journalName":"","paperAbstract":"Recommender systems have many successful applications in e-commerce and social media, including Amazon, Netflix, and Yelp. Matrix Factorization (<b>MF</b>) is one of the most popular recommendation approaches; the original user-product rating matrix <b>R</b> with millions of rows and columns is decomposed into a user matrix <b>Q</b> and an item matrix <b>P</b>, such that the product <b>Q<sup>T</sup> P</b> approximates <b>R</b>. Each column <b>q (p)</b> of <b>Q</b> (P) holds the latent factors of the corresponding user (item), and <b>q<sup>T</sup> p</b> is a prediction of the rating to item p by user q. Recommender systems based on <b>MF</b> suggest to a user in q the items with the top-<i>k</i> scores in <b>q<sup>T</sup> P</b>. For this problem, we propose a Fast and EXact Inner PROduct retrieval (FEXIPRO) framework, based on sequential scan, which includes three elements. First, FEXIPRO applies an SVD transformation to <b>P</b>, after which the first several dimensions capture a large percentage of the inner products. This enables us to prune item vectors by only computing their partial inner products with <b>q</b>. Second, we construct an integer approximation version of <b>P</b>, which can be used to compute fast upper bounds for the inner products that can prune item vectors. Finally, we apply a lossless transformation to <b>P</b>, such that the resulting matrix has only positive values, allowing for the inner products to be monotonically increasing with dimensionality. Experiments on real data demonstrate that our framework outperforms alternative approaches typically by an order of magnitude.","inCitations":["245151f44f461eb5153514d5184cae7e6feec22d"],"pdfUrls":["http://www.cs.uoi.gr/~nikos/SIGMOD17.pdf","http://doi.acm.org/10.1145/3035918.3064009"],"title":"FEXIPRO: Fast and Exact Inner Product Retrieval in Recommender Systems","doi":"10.1145/3035918.3064009","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064009","venue":"SIGMOD Conference"},
{"entities":["Apache Hadoop","Clustered file system","Computer cluster","Computer data storage","Data-intensive computing","Distributed File System (Microsoft)","Expectation–maximization algorithm","Fault tolerance","Load balancing (computing)","Multi-objective optimization","Network-attached storage","Program optimization","Requirement","SPARK","Throughput","Web storage"],"journalVolume":"","journalPages":"65-78","pmid":"","year":2017,"outCitations":["5f3f9223c5c9f896be099bc177929febad508407","01e9ddf1062f9a7d7847bb9bcd2371ce6e0d3e29","6cbcd4239345787caff1884bf8029acfac87354f","2da760f90c3d2bf6598becdde9063093f488548c","bd80556653a915f53b932ad13189b9fa10453436","0558c94a094158ecd64f0d5014d3d9668054fb97","313e8120c31fda6877ea426d8a3be9bcf1b6e088","2f6af58c7905fb8367652fe62fbb1f6ec7e28be0","332f77fd05703c1607e3b57884ad31fb1fad0104","1455be30b0bb364ffc4c35d2cf1ee05cfb32595f","059eb34d95c73e37dca8e35b0ac5a2fb0142f3ee","0d2f3f6abd86368a2eb9a6d0b37d1299ec5939a6","4124e17cf8c45c4fd9eb7d6ba3ce807f52c5645d","3c454dd92dd3a2736f78e97e1f1cb671c472f97d","130ee77295f5f95e9c8a45c9c56bbc650258dba0","2cdcddb08ae6060e94cba6c9b2b58b87324e686f","65ad9178eb3e3bb6ef01df6ced56e389e911376c","f19870a1b4847ca61beed722d557a50189479d27","0541d5338adc48276b3b8cd3a141d799e2d40150","9ee6209432316baf6776838917e06bca4d874747","26c4c1dd27fdb449fe0267eac595930766917878","87b5b79b89e5d7c4ea3f7cfaffe23350dca1c891","3033df10e73f3061d21e58de6c141383815c0420","b0b2f180faa09e7bfcb6bb8e57288c3b61f11116","3358850706a8ad2eb8489bb7790e8bbd3a5b6dba","18c241f9333c5b6590184b0d5f218b3ccd51a605","00fc19647ca1aa9a3910abe7cf3414af2f811e64","b7014a268c35e377366634d6b8370a8a7db285a5","0a5e20769fc8306a24d4426278493a999438dd42"],"s2Url":"https://semanticscholar.org/paper/c5399265946e67fff2e3806f4ecaf474333d7fe1","s2PdfUrl":"","id":"c5399265946e67fff2e3806f4ecaf474333d7fe1","authors":[{"name":"Elena Kakoulli","ids":["1732624"]},{"name":"Herodotos Herodotou","ids":["2013116"]}],"journalName":"","paperAbstract":"The ever-growing data storage and I/O demands of modern large-scale data analytics are challenging the current distributed storage systems. A promising trend is to exploit the recent improvements in memory, storage media, and networks for sustaining high performance and low cost. While past work explores using memory or SSDs as local storage or combine local with network-attached storage in cluster computing, this work focuses on managing multiple storage tiers in a distributed setting. We present OctopusFS, a novel distributed file system that is aware of heterogeneous storage media (e.g., memory, SSDs, HDDs, NAS) with different capacities and performance characteristics. The system offers a variety of pluggable policies for automating data management across the storage tiers and cluster nodes. The policies employ multi-objective optimization techniques for making intelligent data management decisions based on the requirements of fault tolerance, data and load balancing, and throughput maximization. At the same time, the storage media are explicitly exposed to users and applications, allowing them to choose the distribution and placement of replicas in the cluster based on their own performance and fault tolerance requirements. Our extensive evaluation shows the immediate benefits of using OctopusFS with data-intensive processing systems, such as Hadoop and Spark, in terms of both increased performance and better cluster utilization.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064023"],"title":"OctopusFS: A Distributed File System with Tiered Storage Management","doi":"10.1145/3035918.3064023","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064023","venue":"SIGMOD Conference"},
{"entities":["Approximation algorithm","Data mining","Database","Graph database","Model–view–controller","NP (complexity)","Polynomial","Structure mining","Time complexity","Vertex cover"],"journalVolume":"","journalPages":"391-402","pmid":"","year":2017,"outCitations":["2e10c5de97011d7a2929d5af7193ac2fa03310e4","9652b8f68d0a748560b52759982e3021284dcd04","157e33bc77be75f381e431c436641e8738f7bd3e","75d5e3b7c38ae7ba60aabda376fc03b25f5f49c8","8ac341c5070ec185fbde896cae997595b842868c","215aad1520ec1b087ab2ba4043f5e0ecc32e7482","a830582a1f1a85df58fd8808b0963e3aaae109bd","55d176b92d5740d039e1c8ebbad025d460de9ae0","7bb492a6794bd90e8eba049afc8283e8314d620c","7d51a0df30ad828d6953d0161ad91a3cae04af8a","0495df24e2bbd4c3d0f4bdcf6c70e71b0072a874","3190b6a0c421db3baf0613250cf0097eda0baecb","70079b69a162880740c1e47b4a6c403fec280574","dcfde37607cb953c8eabce88ad71efa66023adf5","9f5a3d870bdf2f72ab66560d31219b8580d9fe60","2caeae81beca7645c51c70bf21b69b3f9df76919","34cbc81259c59fc87a9a8818a076e69acd47b6c1","2ea4e47cdaf4a7d61e5caff957e26d2090b5f7fd","0ecc0140fde8f6c6137ddd5f4c13f35685f7f3e8","49b46d1e7f58dc49d4f61714cf2acc827538aa04","0b698cf866906498ade8a8c77111cf704491db22"],"s2Url":"https://semanticscholar.org/paper/553ff11bbe4329048fe1246ae8230e69f4c7f796","s2PdfUrl":"","id":"553ff11bbe4329048fe1246ae8230e69f4c7f796","authors":[{"name":"Jinghan Meng","ids":["3414165"]},{"name":"Yi-Cheng Tu","ids":["2812268"]}],"journalName":"","paperAbstract":"In recent years, the popularity of graph databases has grown rapidly. This paper focuses on single-graph as an effective model to represent information and its related graph mining techniques. In frequent pattern mining in a single-graph setting, there are two main problems: support measure and search scheme. In this paper, we propose a novel framework for constructing support measures that brings together existing minimum-image-based and overlap-graph-based support measures. Our framework is built on the concept of occurrence / instance hypergraphs. Based on that, we present two new support measures: minimum instance (MI) measure and minimum vertex cover (MVC) measure, that combine the advantages of existing measures. In particular, we show that the existing minimum-image-based support measure is an upper bound of the MI measure, which is also linear-time computable and results in counts that are close to number of instances of a pattern. Although the MVC measure is NP-hard, it can be approximated to a constant factor in polynomial time. We also provide polynomial-time relaxations for both measures and bounding theorems for all presented support measures in the hypergraph setting. We further show that the hypergraph-based framework can unify all support measures studied in this paper. This framework is also flexible in that more variants of support measures can be defined and profiled in it.","inCitations":["229bc76e592c751e88b4c44ac18399f0e8c9c855"],"pdfUrls":["http://www.csee.usf.edu/~tuy/pub/SIGMOD17.pdf","http://doi.acm.org/10.1145/3035918.3035936"],"title":"Flexible and Feasible Support Measures for Mining Frequent Patterns in Large Labeled Graphs","doi":"10.1145/3035918.3035936","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035936","venue":"SIGMOD Conference"},
{"entities":["Whole Earth 'Lectronic Link"],"journalVolume":"","journalPages":"683-698","pmid":"","year":2017,"outCitations":["b9addc8ce998f6892120c2c8b23ae183312bfa6c","0a030c2142dec882fea5f33b3f562e04d66d287a","0f7a7d9fbd8c898f0e56d91feb6acda2efaf006a","1126ceee34acd741396c493c84d8b6072a18bfd7","93048dc9441985260fdebaf3a9d2654696e98f87","31a816f4fef768f29772a003e534b1378611bfe6","6bbaf76d82968a4349f7f043ece649c8ac1fbc0c","8584bc6fb5fe616d338d5ae3d20d4848572b5578","156b07d3a2d8d744385f1e09ea49a04b09c612a5","379b242fcc606c2a43278630a97430f750654896","1ec7a6456958359132117635e12b682e39220b7c","47c27cd2c37ba331ced0b24fba43fd917d5f6d19","aee5234fa1f35155dc6021f6ff99ffb6d6262478","fa73764d62c016bc405da3393d5edd3be0ddb18e","515b9903cb55e548b6732e953a1bd51f457c6353","96693c88cdcf0b721e4eff7f4f426bc90f90d601","a1039f3239b2ac21c3e52e9b74e9b53f3327e306","da171cd0eb8942e1c1d1ad38f4382d38035aa094","079866b2ed52cc0a27b2ac96b1489dfd3e7b40df","224eff578c8ca0265e1ca8f36be79592a9367de5","7c889b839e99316f749c4d4bff45ccdd7dbd46ef","4acb56cfcb1e346fe6f87e5ea2583e33945f38cf","382e55821fbc7285395a33267e267f705e4a8d30","16ac4b7138e54c7c12aef23851cbe4e4ebb735eb","12af98b4fed2efc71fe850de3cbbd35191161967","26b9001cce4a7f2e838ef99d0e7593b18553a7e0","21b2e1056b7fedac3f2c61e563d19a1cc0784f81","0282e990528c6a9b4aa92cc196f46257fb4ccee1","99cc63730e3079ed58311a4ec88f4f0c891ed61d","58b2550804f24d5bb0b8cfe6815623be8760ffe1","1b00d8eab3ae0873f1fb693d172095736e4186ad","208e7934d900055b43b8b60e4a807ac00674ec4a","807b9c73800f59ac191c0a43c242ef79ba5ec253","e7cdc8f4d58bdefe4577da1b14d96a5754a1bd3a","01c5d324b2adab8a8017d48f3f7aed640cceb52e","23dadf25f3efacbc9c66f69093d656ad5b003529","238be0efe497fc297013ae16109fbbd2ee3d9733","637d02a269d632dee7a97454d469a783dba01bf6","2962b6e48aef7234b273d7849e63f5ac026d9a31","3ff96aff948c8f07ae5b2ce0a64e04d61a85291a","4928c7729d2ca4817529e3229769f1b856cdf80d"],"s2Url":"https://semanticscholar.org/paper/4c12369fdef1ac723b66586c9759fc7e9fb91fb4","s2PdfUrl":"","id":"4c12369fdef1ac723b66586c9759fc7e9fb91fb4","authors":[{"name":"Zhongjun Jin","ids":["2848828"]},{"name":"Michael R. Anderson","ids":["1758386"]},{"name":"Michael J. Cafarella","ids":["1725561"]},{"name":"H. V. Jagadish","ids":["1735239"]}],"journalName":"","paperAbstract":"Data transformation is a critical first step in modern data analysis: before any analysis can be done, data from a variety of sources must be wrangled into a uniform format that is amenable to the intended analysis and analytical software package. This data transformation task is tedious, time-consuming, and often requires programming skills beyond the expertise of data analysts. In this paper, we develop a technique to synthesize data transformation programs by example, reducing this burden by allowing the analyst to describe the transformation with a small input-output example pair, without being concerned with the transformation steps required to get there. We implemented our technique in a system, FOOFAH, that efficiently searches the space of possible data transformation operations to generate a program that will perform the desired transformation. We experimentally show that data transformation programs can be created quickly with FOOFAH for a wide variety of cases, with 60% less user effort than the well-known WRANGLER system.","inCitations":["984766d01b3427168167785584f5cd91c8cd8ac2","4e2a37c1554afccc30b9cabbed0cb3d7fde26a17","9712068318cb9ada3c26c06f5d0352f96206e2c1","2274f61d00020b0e596b61e113ed16f23f8c0403","33de4502da805dd10769d2412fd04ba5ad7867f7","72f3753ea7e5e81b9bde11a64ebe65bed9e0bcbd","20f49d1100663f1049572910099cf172fb140a3c"],"pdfUrls":["http://web.eecs.umich.edu/~michjc/papers/jin_foofah_sigmod17.pdf","http://web.eecs.umich.edu/~mrander/pubs/foofah-full.pdf","http://doi.acm.org/10.1145/3035918.3064034"],"title":"Foofah: Transforming Data By Example","doi":"10.1145/3035918.3064034","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064034","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Algorithmic efficiency","Data deduplication","Data store","Database","Database schema","Domain-specific language","In-memory database","Interconnection","List of algorithms","Memory footprint","Relational database","Synthetic data"],"journalVolume":"","journalPages":"897-912","pmid":"","year":2017,"outCitations":["0ad8e89091eed09217e66adc98136126addc2619","10aa9ee7caaf9381b6a0468ae899a9729824a6b7","0c0800259bd40b1ac96cc437629c5ea0ad729f22","165d9bd7e9c4a030b09cf21e35ea0bf96090d8cb","3bb6d5834bfb355553588e382ac5f9fa8a8d831d","3d985a05e4a49be71d497e7a2ff3fcbeb74c4bc8","05d6e0185bcb48d396fe778ceedb2078e37e72ef","78ad867eb6176d4e2f1cec4f7517f65d90a660f8","1156f60e40548096df49528b1342bb3e88b0f378","43ea93b01be7d3eed2641b9393c6438d19b825a0","9f3583769b9226c59ca2469f230d2db0d6499647","3486aeaf540c48952120fe853d672af984f40a6a","5ee35281c2c5345e13890b7dcef3d17ee0506023","a97b77c8c3f9e8247c497d1b4c27c958a15f3a62","7f598b081df60565014cd943e4512710b682b734","1452f20140dba52b928c9be5f385b5ac35537a2c","47602a67f2f4ec905df9f0151e2da2366a90424c","c8c4a820973364d5f39f49e24686154d504755bd","080f44d89bf6f4404f476ffec8d2f8ad3f60e07d","1fc5dc2fe308c9eadd15f1a1d18ed298d4d343ff","1359d01962b882c95607a75aeafeb532188cb159","24e8be45a2b2a30a01b7e9f1502e7bd6a7870e7a","2138776f89bccc9362b239a6d33018ca2a847960","05f7c10bac0581e13b75554197a4d6f0059f2481","3ad21b253652d1778308b1531e5ba775084d150e","49c820d33ef7f94e166a4e88ac052b49e1f54362","ac5c1088151c8f9fbe9419415709c5c8b945a129","4b573416043cf9cff42cbb7b753993c907a2be4a","b2bf34c0c0007145a389e014b7ddaa3daa76f332"],"s2Url":"https://semanticscholar.org/paper/19d4a2340a887d61dfbf446a693af660a5432dcd","s2PdfUrl":"","id":"19d4a2340a887d61dfbf446a693af660a5432dcd","authors":[{"name":"Konstantinos Xirogiannopoulos","ids":["2343790"]},{"name":"Amol Deshpande","ids":["2313625"]}],"journalName":"","paperAbstract":"Analyzing interconnection structures among underlying entities or objects in a dataset through the use of graph analytics can provide tremendous value in many application domains. However, graphs are not the primary representation choice for storing most data today, and in order to have access to these analyses, users are forced to <i>manually extract</i> data from their data stores, <i>construct</i> the requisite graphs, and then <i>load</i> them into some graph engine in order to execute their graph analysis task. Moreover, in many cases (especially when the graphs are dense), these graphs can be <i>significantly larger</i> than the initial input stored in the database, making it infeasible to construct or analyze such graphs in memory. In this paper we address both of these challenges by building a system that enables users to <i>declaratively</i> specify graph extraction tasks over a relational database schema and then execute graph algorithms on the extracted graphs. We propose a declarative domain specific language for this purpose, and pair it up with a novel <i>condensed</i>, in-memory representation that significantly reduces the memory footprint of these graphs, permitting analysis of larger-than-memory graphs. We present a general algorithm for creating such a condensed representation for a large class of graph extraction queries against arbitrary schemas. We observe that the condensed representation suffers from a duplication issue, that results in inaccuracies for most graph algorithms. We then present a suite of in-memory representations that handle this <i>duplication</i> in different ways and allow <i>trading off</i> the memory required and the computational cost for executing different graph algorithms. We also introduce several novel <i>deduplication</i> algorithms for removing this duplication in the graph, which are of independent interest for graph compression, and provide a comprehensive experimental evaluation over several real-world and synthetic datasets illustrating these trade-offs.","inCitations":["7b845167dd41349cafc9aab147822b9abcedeb2c","034ba5fe35895db2b046633dc527115e29bd37a4"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035949","https://arxiv.org/pdf/1701.07388.pdf","https://arxiv.org/pdf/1701.07388v2.pdf","https://webcourse.cs.technion.ac.il/236826/Winter2017-2018/ho/WCFiles/Extracting%20and%20Analyzing%20Hidden%20Graphs%20from%20Relational%20Databases%20(2).pdf?7277=","http://cs.umd.edu/~kostasx/files/SIGMOD_Poster_final.pdf","https://arxiv.org/pdf/1701.07388v1.pdf","http://www.cs.umd.edu/sites/default/files/scholarly_papers/Xirogiannopoulos.pdf","http://arxiv.org/abs/1701.07388","https://www.cs.umd.edu/sites/default/files/scholarly_papers/Xirogiannopoulos.pdf"],"title":"Extracting and Analyzing Hidden Graphs from Relational Databases","doi":"10.1145/3035918.3035949","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035949","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Erdős–Rényi model","Experiment","Inferential programming","Privacy","Provable prime","Requirement","Table (information)"],"journalVolume":"","journalPages":"1339-1354","pmid":"","year":2017,"outCitations":["0ccbd0b421022170cdb3773cad5e946f860624a1","1eddbbbdec587b0906013de1d377346cb7f8884b","258cc5f2121fe05244f2dc8b2d6a6ade8719780c","644d02d3aa28537635a1a247aa75b9e926dfda53","7dbf444259ca7f999908c2edfdab81cfce77c324","12d5e1c0cb4280730f174668803b8d0a32b002ff","2f3acd94bfe590d425cae8d9558f38188d4e91eb","004b439ff1e6a15deedc7a7c4c6685f5ceafd237","ca5bf9c6f993bb6ce2883fbda35e0c37a4dfbce4","0a43db07094d742aa731d81eada0d4a89c9331c9","02c20353e2db867eac0952215b2e4edc718a2f2b","451a8f7a1ac7bafcfd30db62fedf946f59d0f0d9","0a10f3dfa73c6901aad886a7966999e6f889116a","360d4003511682c5f5b5f82f6befdda88ca3fa73","37bcd8bbe2cddd48f0ec152fc5ffa4fca93f3828","b532099ff8b67049f292cd62700dca37fc2be623","7412088f10be2032600f98e4e0347fa69222f16f","283ecc8622694c070fa53aee7a1c37dadc603f8d","0fcaa5d69913b2601fb4fac3a16ba384e5f1883b","1cf08cc1e0aafd6d783eec70add7e0875b7cd32a","17fac85921a6538161b30665f55991f7c7e0f940","9407fda128b185bdb0ced615ad8107381b831071","34e7390fc54ba9b29ae88f7a135e2bb79b4ca714","09026b3e5d73b5986a8ba311c2ed1f4f7501732d"],"s2Url":"https://semanticscholar.org/paper/2b69a2e2b6be64678b3fad96d96c561abd878892","s2PdfUrl":"","id":"2b69a2e2b6be64678b3fad96d96c561abd878892","authors":[{"name":"Samuel Haney","ids":["39284749"]},{"name":"Ashwin Machanavajjhala","ids":["2357165"]},{"name":"John M. Abowd","ids":["2959751"]},{"name":"Matthew Graham","ids":["1865055"]},{"name":"Mark Kutzbach","ids":["10791164"]},{"name":"Lars Vilhuber","ids":["3026156"]}],"journalName":"","paperAbstract":"National statistical agencies around the world publish tabular summaries based on combined employer-employee (ER-EE) data. The privacy of both individuals and business establishments that feature in these data are protected by law in most countries. These data are currently released using a variety of statistical disclosure limitation (SDL) techniques that do not reveal the exact characteristics of particular employers and employees, but lack provable privacy guarantees limiting inferential disclosures.\n In this work, we present novel algorithms for releasing tabular summaries of linked ER-EE data with formal, provable guarantees of privacy. We show that state-of-the-art differentially private algorithms add too much noise for the output to be useful. Instead, we identify the privacy requirements mandated by current interpretations of the relevant laws, and formalize them using the Pufferfish framework. We then develop new privacy definitions that are customized to ER-EE data and satisfy the statutory privacy requirements. We implement the experiments in this paper on production data gathered by the U.S. Census Bureau. An empirical evaluation of utility for these data shows that for reasonable values of the privacy-loss parameter &#949;&#8805; 1, the additive error introduced by our provably private algorithms is comparable, and in some cases better, than the error introduced by existing SDL techniques that have no provable privacy guarantees. For some complex queries currently published, however, our algorithms do not have utility comparable to the existing traditional SDL algorithms. Those queries are fodder for future research.","inCitations":["cc01bd29a0503a63f4273441a2a53cc018c580dc","03103f0f545bed8c21791af9af215edf1bd9db86"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035940","https://users.cs.duke.edu/~ashwin/pubs/Haney-UtilityCost-SIGMOD2017.pdf"],"title":"Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics","doi":"10.1145/3035918.3035940","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035940","venue":"SIGMOD Conference"},
{"entities":["Computational complexity theory","Database","Differential privacy","Information privacy","Personally identifiable information","Privacy","Social network","Synthetic data"],"journalVolume":"","journalPages":"1291-1306","pmid":"","year":2017,"outCitations":["451a8f7a1ac7bafcfd30db62fedf946f59d0f0d9","644d02d3aa28537635a1a247aa75b9e926dfda53","9e45b00297f9481020f1c4fcd59486c867f00d3b","2f207e27cad923b81253542a6f76439d49d87925","58bcb1a4f429da03590c5622fb6e7f3c11d05f77","bbcf437efe0d037dc1224365961caac724a68d6b","763afb9dc8650101be06053e2eb612d9e3a1ce18","8726139a30434175795fe924188bd5c6e0b0740d","3e732c08e17e802d6c2f2144735cff5dc83ddad9","fc2b51b1ca0460ad747e11cca6517ed7482f31b1","3cefca055656278e4b54d3dc89ec29438d0c98d0","009d284fe935b5f421d24321073097a0cd34e21f","d921036a6cb7e340b019afa557a19bc65586a1ad","fa7e9af14a46e07db867d9d01cd885e02a06fd62","6154ce8c02375184f7928e41c4fae532500f7175","633d82be7fe9a58bfe2cbbd55b86968d8b0329bb","13d635d04e6d44f976ba713768789f8da14d5a6f","06f0a2e1678b4d849286c92249908ac5d1ed8b55","17fac85921a6538161b30665f55991f7c7e0f940","b532099ff8b67049f292cd62700dca37fc2be623","63b88452574095639ef9a1f692eef3c1ec386b0a","31afd0a18126720eeef5880bcaa14768c4005387","9407fda128b185bdb0ced615ad8107381b831071","bcecf29525971fa388091fe153a1ff1f73ad96c4","49934d08d42ed9e279a82cbad2086377443c8a75","360d4003511682c5f5b5f82f6befdda88ca3fa73","04f39720b9b20f8ab990228ae3fe4f473e750fe3","1ecfe23503600b7a6a6ed3dcce86542420e36a06","2c47904cda5134e8b2862dfa93ecbf283b6e8724"],"s2Url":"https://semanticscholar.org/paper/3c37fb4ebd7a167e1c0d25994169a4dd8826e04c","s2PdfUrl":"","id":"3c37fb4ebd7a167e1c0d25994169a4dd8826e04c","authors":[{"name":"Shuang Song","ids":["6970155"]},{"name":"Yizhen Wang","ids":["39475599"]},{"name":"Kamalika Chaudhuri","ids":["38120884"]}],"journalName":"","paperAbstract":"Many modern databases include personal and sensitive correlated data, such as private information on users connected together in a social network, and measurements of physical activity of single subjects across time. However, differential privacy, the current gold standard in data privacy, does not adequately address privacy issues in this kind of data.\n This work looks at a recent generalization of differential privacy, called Pufferfish, that can be used to address privacy in correlated data. The main challenge in applying Pufferfish is a lack of suitable mechanisms. We provide the first mechanism -- the Wasserstein Mechanism -- which applies to any general Pufferfish framework. Since this mechanism may be computationally inefficient, we provide an additional mechanism that applies to some practical cases such as physical activity measurements across time, and is computationally efficient. Our experimental evaluations indicate that this mechanism provides privacy and utility for synthetic as well as real data in two separate domains.","inCitations":["6e62afd47ded1fcc8fc9e4de1c95c25cd54adfd2","1665dfa9d948aae7cd024f0df186a8e0e235c4d3","74205b80dff21b1f21205b7564080dc8cdaf3e70","35ceec0f14213fbd9da4c62f856181346bad821b","eec0bc4c3fddbaf78feb0872a195fb3aeb01010e","add09610b18960a797690ccd758e4eefdb7d54b3","061a0f2232aaa5d9a60e2976f0d331c13c12dd59"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064025","https://simons.berkeley.edu/sites/default/files/docs/5679/simonsuncertaintyincomputationworkshop.pdf","http://cseweb.ucsd.edu/~shs037/pufferfish_slides.pdf"],"title":"Pufferfish Privacy Mechanisms for Correlated Data","doi":"10.1145/3035918.3064025","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064025","venue":"SIGMOD Conference"},
{"entities":["Benchmark (computing)","Common Platform","Computer science","Expectation–maximization algorithm","Instant messaging","Social network"],"journalVolume":"","journalPages":"651-666","pmid":"","year":2017,"outCitations":["1da59fb230f7fb495befb9d04e4338fd55757cd3","6eb45da9c8582c2e426a4896ff399987b73558b3","637aa0c0214cb6783e4ae4d076eb5fadcfcd82e7","36c0b81a2ef2505e5c1c763c1abc25cdd72903f2","b790f9ae49cdee5354eacfc7897ab9752acd5e2a","1b82d160a3b69345f88879ca59454e1cd230c848","eb82d3035849cd23578096462ba419b53198a556","4bb0f607c1f6be38ca720ad6913577a778cc2f15","048a42699d9991ec18b34bdb484ef244830e1d71","706c83309fa09454a136d4e607364b27be66172c","28bf0df09f97e7ef9108e71b45fe1b9a7aa201e2","23d85a0008429845870780c6db3640c05165acaf","4cd73382dc17561cd276f276c61d5ebf39bf69ad","7febcbdf1b86ff38d19d65927f83bab185f44e1d","72465eb427490619a5a625a45dda81c92a8cfe14","3d84a02dfe4fc904aa729b8b7ca51fd8c97a9dc7","b9e43395663f74c581982e9ca97a0d7057a0008c","184cbf767d2f5501ddab3babe7be8ba93321e14c","21968ae000669eb4cf03718a0d97e23a6bf75926","4b983a1a0b370a4ea87c2be4f2c7c53b13edb4f6","abb152802d5b4686a394e221abe951187ea06158","2d49ad12e22313a82e7f14dd41efe20ecd5daf43","18d215f2c5a4b372a7d2d71cc115a1e808bfa437","d7f9c3253552e13f24c3b73bc055ef60388af57c","a6d73877be2b91e8b6c9c0896e58942c93086ff8","8cdafae1951cc054421361a444cf6401038f473e"],"s2Url":"https://semanticscholar.org/paper/8476714438669d5703690d4bbee9bfe751f61144","s2PdfUrl":"","id":"8476714438669d5703690d4bbee9bfe751f61144","authors":[{"name":"Akhil Arora","ids":["2644814"]},{"name":"Sainyam Galhotra","ids":["2663974"]},{"name":"Sayan Ranu","ids":["1699732"]}],"journalName":"","paperAbstract":"Influence maximization (<b>IM</b>) on social networks is one of the most active areas of research in computer science. While various IM techniques proposed over the last decade have definitely enriched the field, unfortunately, experimental reports on existing techniques fall short in validity and integrity since many comparisons are not based on a common platform or merely discussed in theory. In this paper, we perform an in-depth benchmarking study of <b>IM</b> techniques on social networks. Specifically, we design a benchmarking platform, which enables us to evaluate and compare the existing techniques systematically and thoroughly under identical experimental conditions. Our benchmarking results analyze and diagnose the inherent deficiencies of the existing approaches and surface the open challenges in <b>IM</b> even after a decade of research. More fundamentally, we unearth and debunk a series of myths and establish that there is no single state-of-the-art technique in IM. At best, a technique is the state of the art in only one aspect.","inCitations":["4788acab3002f6943e213e6a519dc9e0b6704641","b4d849c28c91c3b664e996020b6f8517f78d8266","c51924c480547768355ed8ca814f9200a36cbab4","97ed889c7b5bc5786001863b4763c64e62f5ddfa","560fa3d7c66d8d02a88d9f447a3e051ee2bb654f","1f0d3c04153e41ea2865437fcd9c05875aa4a7e0","a31964b8281008ad2611845654462240e9688a89","42b0fb834260a07be0a358ecaabd822a148a5f3c"],"pdfUrls":["http://people.cs.umass.edu/~sainyam/papers/SIGMOD17_im_benchmarking.pdf","http://doi.acm.org/10.1145/3035918.3035924"],"title":"Debunking the Myths of Influence Maximization: An In-Depth Benchmarking Study","doi":"10.1145/3035918.3035924","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035924","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Experiment","Gradient","Gradient descent","High- and low-level","Iteration","Machine learning","Mathematical optimization","Program optimization","Synthetic data"],"journalVolume":"","journalPages":"977-992","pmid":"","year":2017,"outCitations":["17e1bb7fc17b45fe5ad8724a635d285ed000efa8","4954fa180728932959997a4768411ff9136aac81","51463d7d66e2c703561225efc9ae2b9abd768db6","45619a2b7b41fea02345badf880530519d3d4c8f","36d858eb19bba43244b92f7faabfce47b13f2403","67d9fe9856d590e566c9b3aa549541129bb92117","0f5c9968fe2cdb0f52c55b2d5b3dec7accf91306","0790c77c1eaf2368b55c6a0def09a43690eeb848","01e1fa7924b3eb76b73f1828c93805f3ba028bae","36f49b05d764bf5c10428b082c2d96c13c4203b9","5b1c8b1ad5d7f18df6124e5dcb7833bfba027901","75284ed9e49898e3367ecc99b6cd13948671e078","065e808aa05fe23de00ab4510d1607ddff04c232","17f70b9d1fcf3b31948ffa578ac89399751fe73d","290c735c8e3e2ffe896d80ea379e48b8177a7f39","43aac4922fc82c1e8062d4d22b670701b93d980a","244f7c483b1035144f04f7c58f20c3f806d3f1b3","2ea7b6224ebd9267cfc37ef21f3761452d24cc93","341a08d1854b5ecf871bbb4c7833a435927abbda","8a7e4164d954eb55617362dcb18ca1359b4b753b"],"s2Url":"https://semanticscholar.org/paper/ab811cf9bdc9b1c7aca3cec965d212d4d4ddf1bc","s2PdfUrl":"","id":"ab811cf9bdc9b1c7aca3cec965d212d4d4ddf1bc","authors":[{"name":"Zoi Kaoudi","ids":["2827559"]},{"name":"Jorge-Arnulfo Quiané-Ruiz","ids":["1712430"]},{"name":"Saravanan Thirumuruganathan","ids":["2934941"]},{"name":"Sanjay Chawla","ids":["1756323"]},{"name":"Divyakant Agrawal","ids":["1724045"]}],"journalName":"","paperAbstract":"As the use of machine learning (ML) permeates into diverse application domains, there is an urgent need to support a declarative framework for ML. Ideally, a user will specify an ML task in a high-level and easy-to-use language and the framework will invoke the appropriate algorithms and system configurations to execute it. An important observation towards designing such a framework is that many ML tasks can be expressed as mathematical optimization problems, which take a specific form. Furthermore, these optimization problems can be efficiently solved using variations of the gradient descent (GD) algorithm. Thus, to decouple a user specification of an ML task from its execution, a key component is a GD optimizer. We propose a cost-based GD optimizer that selects the best GD plan for a given ML task. To build our optimizer, we introduce a set of abstract operators for expressing GD algorithms and propose a novel approach to estimate the number of iterations a GD algorithm requires to converge. Extensive experiments on real and synthetic datasets show that our optimizer not only chooses the best GD plan but also allows for optimizations that achieve orders of magnitude performance speed-up.","inCitations":["05233cf6194ddee6427f0bb76cb8749cc220d2bb"],"pdfUrls":["https://arxiv.org/pdf/1703.09193v1.pdf","http://arxiv.org/abs/1703.09193","http://doi.acm.org/10.1145/3035918.3064042"],"title":"A Cost-based Optimizer for Gradient Descent Optimization","doi":"10.1145/3035918.3064042","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064042","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Computer data storage","Datalog","Fixed point (mathematics)","Graph (abstract data type)","Hierarchical and recursive queries in SQL","List of algorithms","Multi-function printer","Recursion","Relational algebra","Relational database management system","Semantic Web","Social network"],"journalVolume":"","journalPages":"1165-1180","pmid":"","year":2017,"outCitations":["465c5a68c3c62f6fb949acfd7921a9072a29841b","43ea93b01be7d3eed2641b9393c6438d19b825a0","78ad867eb6176d4e2f1cec4f7517f65d90a660f8","b149cd8a742848c3b1f86edc43590f475386445d","4d98e7aed4fce86e0ddd92bd4455b6f41fc4c780","ad585974e2d05758cd36e2ab2e346f38b4de4a0f","8c4f6168509c0439cb29f40d705c42d182431e26","7c1a0f7054d496e71cc697202b84d8a5c652328a","19dd6efece0de4e26e400d63f52dbf5f62453272","165d9bd7e9c4a030b09cf21e35ea0bf96090d8cb","43ae665066bfa1c52bfc83e95dadcb5fcabcee41","7724172425879e96bd4deee1c175ba840ebac5a6","b7c2bdfad548cbd06b06d27be3bd226d4a3ee075","1907bb75c65a46184871d3c582fa0fa1f4a52fda","e69870dac824d819d7b359906beff6b43d01d1a5","60105db6a5cce5eb7bcec56b87d95ef83a5e58e0","26a2b94a118334585f5d717b24ef06b6f9014ba8","ac5c1088151c8f9fbe9419415709c5c8b945a129","148edd9ac0ed0485f14f470949f64a9d92cbbc10","863da712ef344460cdb5b3d92ea2d4cc28d860de","6cdda58b54d24280e144e34fcee1df5de8fa9b5d","323db86b818e7dff6639aa0b5c6d83a275a0d5cd","71a14c91426af347409b047a0361256c35279f55","e741b677759b94aaa5f3162e3a3b01d396a43aaa","2d1d0ee6e21c288d96577b24656cd3398082f857","244f7c483b1035144f04f7c58f20c3f806d3f1b3","17152bd58eaa134ea0b56407a942c8ff97a16237","f26feb25eb3ff2c5016700a77104740dd65a0169","7ec3de9aeb436f3230f4c6bae92832958ffadb28","4e8b20a55afa5a53655a73c59cc32ccc13eea76a","eb07721a38f6bd3a9e06f95ce65ec8ca63cadb2a","ee8c9d3ba6446f4c2cd63ec6a2fd3c82389f43e2","061188d388cd91a8090f3106c78621bc7cb8cb07","6099814c55861b15467d26010631124bea5dfbda","4949f1caaf36b540f5b65f28d787bdfdaef30bf7","1492b478e94bfbead7ff458a60c25616e44c5eb7","0b944c6b28d4b87d8b64767955201cadf987f558","1359d01962b882c95607a75aeafeb532188cb159","040678daf6a49a88345ee0c680fccfd134f24d4b","6a80af5bf2e89907ad9e60e1b6055d4d935c86a1","6b343dd1814738da2d01edf5d81332701f005bcb","5ee35281c2c5345e13890b7dcef3d17ee0506023","a97b77c8c3f9e8247c497d1b4c27c958a15f3a62","243230d5b623f79c22750b42447e902ab07a2db9","31181e73befea410e25de462eccd0e74ba8fea0b","a000e3a2f34444ee62351ffa443f5fc65731a110","bacd622d373745a2cc5300231f0780c4871d16ad","63a75a7abd9a4701e3d88a7f54c2d263a0ddb0c3","5c78f68fd6f56acf5832b095cb190b83aacf9c37","f3a39750bc525e9a7fb42b130c2ee58f5faa188e","18c241f9333c5b6590184b0d5f218b3ccd51a605","009dbf3187862352aac542bf7d61e27bce6b27f5","351cb36f5c1489358330263d224574449c2e5d83","1b4474be934290872e9c03fc084d940e9a51a360","2c688c44c7a102014ffac63bc2b5213ffb9ea405"],"s2Url":"https://semanticscholar.org/paper/c08de1c411aec1129f530f609044d6fc1e2bb1f4","s2PdfUrl":"","id":"c08de1c411aec1129f530f609044d6fc1e2bb1f4","authors":[{"name":"Kangfei Zhao","ids":["8599669"]},{"name":"Jeffrey Xu Yu","ids":["1718849"]}],"journalName":"","paperAbstract":"To support analytics on massive graphs such as online social networks, <i><b>RDF</b></i>, Semantic Web, etc. many new graph algorithms are designed to query graphs for a specific problem, and many distributed graph processing systems are developed to support graph querying by programming. In this paper, we focus on <i><b>RDBM</b></i>, which has been well studied over decades to manage large datasets, and we revisit the issue how <i><b>RDBM</b></i> can support graph processing at the <i><b>SQL</b></i> level. Our work is motivated by the fact that there are many relations stored in <i><b>RDBM</b></i> that are closely related to a graph in real applications and need to be used together to query the graph, and <i><b>RDBM</b></i> is a system that can query and manage data while data may be updated over time. To support graph processing, in this work, we propose 4 new relational algebra operations, <b>MM</b>-join, <b>MV</b>-join, anti-join, and union-by-update. Here, <b>MM</b>-join and <b>MV</b>-join are join operations between two matrices and between a matrix and a vector, respectively, followed by aggregation computing over groups, given a matrix/vector can be represented by a relation. Both deal with the semiring by which many graph algorithms can be supported. The anti-join removes nodes/edges in a graph when they are unnecessary for the following computing. The union-by-update addresses value updates to compute <i><b>P</b>age<b>R</b>ank</i>, for example. The 4 new relational algebra operations can be defined by the 6 basic relational algebra operations with group-by &#38; aggregation. We revisit <i><b>SQL</b></i> recursive queries and show that the 4 operations with others are ensured to have a fixpoint, following the techniques studied in DATALOG, and enhance the recursive WITH clause in <i><b>SQL'99</b></i>. We conduct extensive performance studies to test 10 graph algorithms using 9 large real graphs in 3 major <i><b>RDBM</b></i>s. We show that <i><b>RDBM</b></i>s are capable of dealing with graph processing in reasonable time. The focus of this work is at <i><b>SQL</b></i> level. There is high potential to improve the efficiency by main-memory <i><b>RDBM</b></i>s, efficient join processing in parallel, and new storage management.","inCitations":["e5c17deddc0a69c5bd3f9d1eeb515946277f76a1"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035943"],"title":"All-in-One: Graph Processing in RDBMSs Revisited","doi":"10.1145/3035918.3035943","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035943","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Approximation algorithm","Baseline (configuration management)","Heuristic","Independent set (graph theory)","Iterated local search","Iteration","Local search (optimization)","Search algorithm","Speedup","Time complexity","Vertex (geometry)"],"journalVolume":"","journalPages":"1181-1196","pmid":"","year":2017,"outCitations":["17b4fddfa17610d764e667ffe237f978dde9462f","1a4edf228e648b54fab3f25df82817cfd0a5bb42","88c8983ee14198c318ca948deccb5b6ee0abb40f","fb39b3a5dd7eac30066036603ff4f5129186b193","3b487f66bfcdb4569aa9c77bbeed382d1d1390a2","ee3869ae9a27a10f8f50f221a54a2c5674ba67f1","a5de2180bb83fe9e7b2633f0bfefa3c50942aecb","7aa85143fb0aad0e6c81e157776774384a63c405","cbce38ea34c90b8a53f35f10b2235e65fc5fe167","482c0f4d4b72a499d0f56d046f4e05469dc0f037","7c710aafc93a57d937eb3244994ad513b84c7ebe","37999ab3c76d82a990e28fb499cc1ffdbdacd401","5611b606c6680cb5b99e7a41965934b01b0641e9","ca1c2798e187c2b411b37c2b49a020fdbe6581c0","850ad780b38b11a633f7e1aacc065e19f01b770c","c9e80e72f7de24ff01276348a7eceadcf7cf0823","0050d4029afcdca251d96462ef6d3a98129bc957","927b7fbfb53fafb56a4097d6193c7cdd625794e6","b4932747aaa90cc201135dabe88ea45c0236f4ae","6035d6123b94d65ce7cc25d0fa95680f550bdc31","8858200fb69a050304e74e59df91d46a6013d3df","1f0612de1f191abadf250b78cd78f884203cca5e","acff8ef872ae2e143449bd2bed41eedf4d1b2f87","23dadf25f3efacbc9c66f69093d656ad5b003529","ff1a1fcbc579287fcb2add2d1e9aaf1220f188a9","2ea4562a7e69e5306fdf3c5a3ae40ac2242b4096","9c7252e8cc8896d58885847b5d14d27489300c1c","3f7dd60fa461fecf9e34013c81ccf50a3e5397d2","7bcc53f1baf3358517a602d856192faea9442c91","97ea45e5be07159ace0da7420ebee343d7b1f0cc","265a01450168f186348640003f55b11fbd0c4f2b","159483560ab822a0a8fbea69278e40c81348e847","1e92b690b17d7f590adbb3fd7d28bbf5c193aae5","3ddac15bd47bc0745db4297d30be71af43adf0bb","c4188fcd1f383608e55e8c17e830dc75f079017e","636fc4193126dd7810a90ad6c0cdf22f4b03d747","f2d4b6b2048279f5c56e8febfd3473fcbf294710","07d78543ea3987754113c23d1d49f0d7d36a2c5d"],"s2Url":"https://semanticscholar.org/paper/a6735253c13b7084ef852588344a29770a01ddf6","s2PdfUrl":"","id":"a6735253c13b7084ef852588344a29770a01ddf6","authors":[{"name":"Lijun Chang","ids":["38736958"]},{"name":"Wei Li","ids":["1688012"]},{"name":"Wenjie Zhang","ids":["19262604"]}],"journalName":"","paperAbstract":"This paper studies the problem of efficiently computing a maximum independent set from a large graph, a fundamental problem in graph analysis. Due to the hardness results of computing an exact maximum independent set or an approximate maximum independent set with accuracy guarantee, the existing algorithms resort to heuristic techniques for approximately computing a maximum independent set with good performance in practice but no accuracy guarantee theoretically. Observing that the existing techniques have various limits, in this paper, we aim to develop efficient algorithms (with linear or near-linear time complexity) that can generate a high-quality (large-size) independent set from a graph in practice. In particular, firstly we develop a <b>Reducing-Peeling</b> framework which iteratively reduces the graph size by applying reduction rules on vertices with very low degrees (<b>Reducing</b>) and temporarily removing the vertex with the highest degree (<b>Peeling</b>) if the reduction rules cannot be applied. Secondly, based on our framework we design two baseline algorithms, <b>BDOne</b> and <b>BDTwo</b>, by utilizing the existing reduction rules for handling degree-one and degree-two vertices, respectively. Both algorithms can generate higher-quality (larger-size) independent sets than the existing algorithms. Thirdly, we propose a linear-time algorithm, LinearTime, and a near-linear time algorithm, NearLinear, by designing new reduction rules and developing techniques for efficiently and incrementally applying reduction rules. In practice, LinearTime takes similar time and space to BDOne but computes a higher quality independent set, similar in size to that of an independent set generated by <b>BDTwo</b>. Moreover, in practice <b>NearLinear</b> has a good chance to generate a maximum independent set and it often generates near-maximum independent sets. Fourthly, we extend our techniques to accelerate the existing iterated local search algorithms. Extensive empirical studies show that all our algorithms output much larger independent sets than the existing linear-time algorithms while having a similar running time, as well as achieve significant speedup against the existing iterated local search algorithms.","inCitations":["b7502ee674310ee4466b598708851f6caf73e9db","6a94ff28e78b6953ec8fd06a3850110ec428604f"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035939"],"title":"Computing A Near-Maximum Independent Set in Linear Time by Reducing-Peeling","doi":"10.1145/3035918.3035939","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035939","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Database","Expectation–maximization algorithm","Probabilistic Turing machine","Probabilistic database","Scalability","TI-BASIC"],"journalVolume":"","journalPages":"573-586","pmid":"","year":2017,"outCitations":["67286943f8f2ca5ba482dc02092ce2d7951d19ff","be7dbfcb5a69b8a20eaf5036a511469e565c6ee7","2749cb94f92170f79d0e8ad266605a871767f38a","0b2ba9da35baf58775d1707b48218501cd596bc9","6bbd273f9f274d5a3e5dade5e202be809e707647","5a308819821cf81f21cc68ddff3698217be36b6d","9d7463fff8b50e491662d490752136a3312991fa","2077cc18da002721390a23392ce4a25d19c3e2a2","99539f92c634a586a99f583ff1bad2989a9d5f74","395d96c34a22c3f0a11ac75e95a03663d6f20ea0","38ec3d6ec09a9a5a3dffd1df4a1c45c7abd79484","378cd5ccb49d9fedff9c0c926b91192acc300313","bdda4bfc82d4e07d48020483d0364511b8e4fb34","752a9f7b0d8e1205d86a21ff8acf46435993dd53","2f3902d4e4b793c74fd368ce9b6f3f28a2a1206f","4268cb59768556d29ff4f8586277bee4183c4afc","2889dbb1e5770e1eb6e5e3087be5be5841b11fa8","03d9e06a8bbf15edf1e59664456ad95ba6ef6ad1","54c133bc5b6b372d0b9d9d6acd7b3319b77abe7f","24b1dff7e0d9bd36b58d192d2a290fde0ac41133","177f84bedb6b4ca31750ad7cf3a171d1014199c6","1f9af2489db58ef12d37b0228d60b630fc047a33","26f1f4512e5228ed162a27a8051cb91160325799","5a499e1d1b42093e1b8c0bc3d74200e183f32392","3a910967232526c862418e7b01448c48694624e1","330b3187fd07339f609f403155c3bddaa5f0e8c8","04c73e4f13a19a2ce270a0aa391bd7842aa113ae","1116b96e668c0dbf5a8b539d66baaf61bedc9dba","ded1ab521c9839145040cb45c1f0c353536de8d5","d641ce8fe01ba5ae0ade43feaa1e1e2a7f4839b8","2654970f704c7c450a05c41c8d4adc2f8b0a5028","0f48c76228e3f17ce5766614800121c767b72cbb","a97b77c8c3f9e8247c497d1b4c27c958a15f3a62","8d9274823441be0e76bab445414b6381bcd3ca0a","1fe41b1240a0eddec736b675e914b4858a955876","2e49f21a1e38f7def51ab2db26186d0a3759c5e2","f2aed2478e13a76b0b80f0366a9e2bef59f043a7","1b19eb5c3ed02dcda18b9300f2804bda0a4c94e6","02df9340e08e1e5085f1257bb6ddda4cd225e1d3","0a62aa358438f52e36f37836c6f42f4015850e56","1ec2d02bd12f3a357449cf1bbc67b6adf7cd6296","29312721c03293237bfb41e4000dcbdbc0486b68","2a89cb2ff3597b49f4e0927e749652fdc635260b"],"s2Url":"https://semanticscholar.org/paper/5fcfc33e55a5a46ecd670f77252dc0ebc1876a1c","s2PdfUrl":"","id":"5fcfc33e55a5a46ecd670f77252dc0ebc1876a1c","authors":[{"name":"Niccolò Meneghetti","ids":["2131252"]},{"name":"Oliver Kennedy","ids":["2043556"]},{"name":"Wolfgang Gatterbauer","ids":["2000882"]}],"journalName":"","paperAbstract":"Tuple-independent probabilistic databases (TI-PDBs) handle uncertainty by annotating each tuple with a probability parameter; when the user submits a query, the database derives the marginal probabilities of each output-tuple, assuming input-tuples are statistically independent. While query processing in TI-PDBs has been studied extensively, limited research has been dedicated to the problems of <i>updating or deriving the parameters from observations of query results</i>. Addressing this problem is the main focus of this paper. We introduce <i>Beta Probabilistic Databases</i> (B-PDBs), a generalization of TI-PDBs designed to support both (i) <i>belief updating</i> and (ii) <i>parameter learning</i> in a principled and scalable way. The key idea of B-PDBs is to treat each parameter as a latent, Beta-distributed random variable. We show how this simple expedient enables both belief updating and parameter learning in a principled way, without imposing any burden on regular query processing. We use this model to provide the following key contributions: (i) we show how to scalably compute the posterior densities of the parameters given new evidence; (ii) we study the complexity of performing Bayesian belief updates, devising efficient algorithms for tractable classes of queries; (iii) we propose a soft-EM algorithm for computing maximum-likelihood estimates of the parameters; (iv) we show how to embed the proposed algorithms into a standard relational engine; (v) we support our conclusions with extensive experimental results.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064026","http://odin.cse.buffalo.edu/papers/2017/SIGMOD-BetaPDBs-final.pdf"],"title":"Beta Probabilistic Databases: A Scalable Approach to Belief Updating and Parameter Learning","doi":"10.1145/3035918.3064026","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064026","venue":"SIGMOD Conference"},
{"entities":["Experiment","Graph (abstract data type)","Graph database","Recursion","Scalability","Synthetic data","Time complexity"],"journalVolume":"","journalPages":"913-928","pmid":"","year":2017,"outCitations":["e2462bde978023a9069cc08326f626135a95cb89","5f3f9223c5c9f896be099bc177929febad508407","2b1ec3fdf5b695de2d7ec17393ec0ad9445ceb61","3c7beb9cc66257a1434a0ce662fc74ba25919871","09050b5922d97e98c385c7dcfd2ce12f94c291a2","420a0e5fc398f197bca3dfe40291a82b2c65655a","1e557937f418accc13f9c5edb33a3d48259d80e5","71affe0d9489be0ecba667f568b1a0bcd9ee3af3","ef9d9821df55442f039b128bb5cef2b41ab2cadc","34aff134ba0d25b146721b35ec58a9c1c1abe2ac","62bfdedb87d1fed25eb5aa1bc6ff546c70a0ba6a","741f4bd8a0d1d01ff4be38bbaba10fc9ea6412c6","40eb1f990ac292b14b56ea06e61d9aeb9bfa28c3","01c1f0e97ce5c74c714dc7aa43cb064f45cc3b04","18808d821b83148f09eca1c426ac6fa86b3665c9","08d4da77c489d550c3e215725551481310719893","49c841a57970309a31c439b1b30262487f6068d2","1f0612de1f191abadf250b78cd78f884203cca5e","d1c21c34936f587779c216ed79ca33883845caa1","31b63d505dbf6f2b9a60d0c45976f2cbd5cd9619","080f44d89bf6f4404f476ffec8d2f8ad3f60e07d","e3ef3a0d4207048faa1936780ae51042eb5620c5","0acc31039de608f2ac51f59b6848a48d50c919a5","ce18973fb7c23cb4fc1c1a61c1c1c4333f4abad1","ddc843dcccd5e1ebcc01c7b3dba5ccebd0a1cc06","c3fbbd9c1fc5e53c6a9e3fe27e1bfce4755c8ef3","2def083fb7fd8f887c507c0b0b32bd921a26df9b","23f5a0dc63c467b1259ebe6319979a492ca55fc0","6a888f3dd0a17b0241be61daa378ba6caffa6617"],"s2Url":"https://semanticscholar.org/paper/77956a4289b1c62a8639ddf073590de945c88007","s2PdfUrl":"","id":"77956a4289b1c62a8639ddf073590de945c88007","authors":[{"name":"Himchan Park","ids":["2021341"]},{"name":"Min-Soo Kim","ids":["31959062"]}],"journalName":"","paperAbstract":"As many applications encounter exponential growth in graph sizes, a fast and scalable graph generator has become more important than ever before due to lack of large-scale realistic graphs for evaluating the performance of graph processing methods. Although there have been proposed a number of methods to generate synthetic graphs, they are not very efficient in terms of space and time complexities, and so, cannot generate even trillion-scale graphs using a moderate size cluster of commodity machines. Here, we propose an efficient and scalable disk-based graph generator, <i>TrillionG</i> that can generate massive graphs in a short time only using a small amount of memory. It can generate a graph of a trillion edges following the RMAT or Kronecker models within two hours only using 10 PCs. We first generalize existing graph generation models to the <i>scope-based generation</i> model, where RMAT and Kronecker correspond to two extremes. Then, we propose a new graph generation model called the <i>recursive vector</i> model, which compromises two extremes, and so, solves the space and time complexity problems existing in RMAT and Kronecker. We also extend the recursive vector model so as to generate a semantically richer graph database. Through extensive experiments, we have demonstrated that TrillionG outperforms the state-of-the-art graph generators by up to orders of magnitude.","inCitations":["60fd8b9ce88b7550174119fcdb3a19d5663d2cc9"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064014"],"title":"TrillionG: A Trillion-scale Synthetic Graph Generator using a Recursive Vector Model","doi":"10.1145/3035918.3064014","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064014","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Foreign key","Many-to-many","Program optimization","Query optimization","Sampling (signal processing)","Selection bias","Unique key"],"journalVolume":"","journalPages":"759-774","pmid":"","year":2017,"outCitations":["06e49a2331745a33eca328b6883fed63ae2ac5b3","11eb8c2027e0422f3ef8de7720525bbe4897ff36","280b697a7acd66f2835ef4220984fafd79b8e96e","ca0b88a7f00fb55448436abe01a725df7517f060","4b163245cdc7a1d80ded5e26424fb382910965b9","7a278ee0578f194700cadc3811cdda4ec751f88a","77ec1a0ec386e019022933e8a19da59715f39e29","6922e7fce434b841c1666fc6f7f5fc029269f7ad","dbe3720c170f39241ccf07a8f64dd0a176c7ec83","27341f28a56ec5d37ac81835d9ab2a8bb8864be3","00aa614734a26a19b09a0a3bdee2adc77bdac5e4","24763030fb1e9813dad51d28bea9c5d1414f9cda","2a365b450f8610a25d32b966612dcf0359b39a72","076354ae1ff33fc9efbe916d3ca5b6463d1533f0","23c5939aaf3828f5201120543dc0da4227b5a77d","043cf6a9e18cb499da540ffd58b37086158ffd68","0026eee31421ce11c665c8a5de319f1f492f4060","c8bd4caf0fc9c8a4fbffc7e05416901d4fd7a41b","37e0d25940bd49022c41e63909532acd88eb16b9","da01f7fcc5c7eeba75bc09a41fdd946e65210090"],"s2Url":"https://semanticscholar.org/paper/7db7a5152c5dec4a5871ea64cf246c9076cb98a3","s2PdfUrl":"","id":"7db7a5152c5dec4a5871ea64cf246c9076cb98a3","authors":[{"name":"Yu Chen","ids":["1698602"]},{"name":"Ke Yi","ids":["1683893"]}],"journalName":"","paperAbstract":"Join size estimation is a critical step in query optimization, and has been extensively studied in the literature. Among the many techniques, sampling based approaches are particularly appealing, due to their ability to handle arbitrary selection predicates. In this paper, we propose a new sampling algorithm for join size estimation, called <i>two-level sampling</i>, which combines the advantages of three previous sampling methods while making further improvements. Both analytical and empirical comparisons show that the new algorithm outperforms all the previous algorithms on a variety of joins, including primary key-foreign key joins, many-to-many joins, and multi-table joins. The new sampling algorithm is also very easy to implement, requiring just one pass over the data. It only relies on some basic statistical information about the data, such as the &#8467;<i><sub>k</sub></i>-norms and the heavy hitters.","inCitations":["5911afa17128e62c1acd352cd7e943566601755a","6072cf5f9e7f1b4ed590717cee1d62d437e2e5f4","2b6a2ec50b841f435a89b1711001ee8bf776a760","20a60403555b21eadc38bfe95ad1f0baf13ac13b"],"pdfUrls":["http://home.cse.ust.hk/~yike/sigmod17.pdf","http://www.cse.ust.hk/~yike/sigmod17.pdf","http://doi.acm.org/10.1145/3035918.3035921"],"title":"Two-Level Sampling for Join Size Estimation","doi":"10.1145/3035918.3035921","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035921","venue":"SIGMOD Conference"},
{"entities":["Adversary (cryptography)","Anomaly detection","Application programming interface","Bitcoin","Concurrency (computer science)","Database transaction","Denial-of-service attack","E-commerce","Isolation (database systems)","Language-independent specification","Programmer","Self-hosting","Serializability","Web API","Web application"],"journalVolume":"","journalPages":"5-20","pmid":"","year":2017,"outCitations":["0ea92d9b60792714e3a13fd5c47a19d4741a11d1","22d3fc87f5d9ea17a3bb21f885655a1f9f2deb65","182c0524aa353b6f4f4cb75a88ff3f5fc3bd86e0","a62f2bcc232a295ed92cc93d9b02469f5f6e3a5c","ab0458e4e7dcad49c9aae98dab5bd2dc8c099af4","28573c2d17dd0fcb57c6d2171e7a2761d47c6ed0","b1cb8339ed437ce74deaf4b080b33cf61bbebd5d","61011eb60b242f529f58eecaf7029524920cd6cf","4edd5bfd9d9e846ccfb1d1830fb5fdfa3ab2efce","42cf741f1b38315c3376c301601cfee74571c6b6","0b7c1bc9636d8cc66c36fb7e676d3badfe5df696","861fbac82ae5ec0ea654d0d95ce4d48de62419ea","96fc6181d8f72a1b75b6660049d6a6e8c2daa4ce","16a04050353b741974c7d0448e8b0149831bfdc0","32257d8d2b08c87e58c7b7f4b2430d58e4b51a81","bca55bdc9fbc192b88848cf82d1679e3bee2f505","033fd9ff33b69fbd8d9e24b98f77aa8adee06514","fdb29e3a00c560d54e7994d133f93c110794612d","c911a39f2b5d0a5d5962010685d30d7f6381a7ac","6b5eeb5a017de5758e9773b52b0292cfc987ce3d","c7e3b2bbdef407f64bd8f513b399837e018d0784","00ac447d02035c26c7e2852c2457fe812e89038f","11ef7c142295aeb1a28a0e714c91fc8d610c3047","0c80eb8588fac0a763a15e1b7a33c6d885ce80a4","d5229a1f0e3111bc9feaccb018eedc647e03cf5f","6e90c995cc9caa0f7d9d68d536f5e16e9bcbbcd6","2cdeab1558a3fe046ec7e1a36224bc46afcaff90","454b06a17e2f6656e65935cb9d36dcf2b2044bf5","08d8c62df23a5f6f8b79cc3639cc179938a48ba4","47e88885a7e0ef276ba68d01febbc51a53ad1314","02eb9ac41a6a5c18829cd7b4af7fbd753185238e","73ca3c562121d9707daaab88afc997680b8cd010","ab0d8f966a6fd16865b9a459ccb5383bf58e70a3","b25e758ebb32d05683b9671d5880f4016888125f","a1c6a7817891703ff1d103a23ab01961dda598cb","0e227474e5e90dcdf796998a33126cbe70434ce1","34d269619576cd827b9842581755c06dac344b16","2346439ece014d5e3ce1564adc2a7ca098a37c8e","635fe1706a2a719b9c7935712db6e720fd418fa9","01cfec4ca6637fb90cec8afee2a2694aebb83a61"],"s2Url":"https://semanticscholar.org/paper/d8da1fae13be213d8627e6e4f3451115db7b1e03","s2PdfUrl":"","id":"d8da1fae13be213d8627e6e4f3451115db7b1e03","authors":[{"name":"Todd Warszawski","ids":["2155642"]},{"name":"Peter Bailis","ids":["2740804"]}],"journalName":"","paperAbstract":"In theory, database transactions protect application data from corruption and integrity violations. In practice, database transactions frequently execute under weak isolation that exposes programs to a range of concurrency anomalies, and programmers may fail to correctly employ transactions. While low transaction volumes mask many potential concurrency-related errors under normal operation, determined adversaries can exploit them programmatically for fun and profit. In this paper, we formalize a new kind of attack on database-backed applications called an <i>ACIDRain</i> attack, in which an adversary systematically exploits concurrency-related vulnerabilities via programmatically accessible APIs. These attacks are not theoretical: ACIDRain attacks have already occurred in a handful of applications in the wild, including one attack which bankrupted a popular Bitcoin exchange. To proactively detect the potential for ACIDRain attacks, we extend the theory of weak isolation to analyze latent potential for non-serializable behavior under concurrent web API calls. We introduce a language-agnostic method for detecting potential isolation anomalies in web applications, called Abstract Anomaly Detection (2AD), that uses dynamic traces of database accesses to efficiently reason about the space of possible concurrent interleavings. We apply a prototype 2AD analysis tool to 12 popular self-hosted eCommerce applications written in four languages and deployed on over 2M websites. We identify and verify 22 critical ACIDRain attacks that allow attackers to corrupt store inventory, over-spend gift cards, and steal inventory.","inCitations":["8c17cb64a2153ed38d7a2517ac6b57083e0a0eff"],"pdfUrls":["http://www.bailis.org/papers/acidrain-sigmod2017.pdf","http://doi.acm.org/10.1145/3035918.3064037"],"title":"ACIDRain: Concurrency-Related Attacks on Database-Backed Web Applications","doi":"10.1145/3035918.3064037","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064037","venue":"SIGMOD Conference"},
{"entities":["Column-oriented DBMS","Computer data storage","Database","Field-programmable gate array","Hardware acceleration","Intel QuickPath Interconnect","MonetDB","Multi-core processor","Pattern matching","Response time (technology)","SQL","Throughput","User-defined function"],"journalVolume":"","journalPages":"403-415","pmid":"","year":2017,"outCitations":["82e5e034d02a0d3e1219fe527ab8480401fefd50","4881b2d926ef5f4757898534c91db884414e6b3c","f87bee8ca2b7bbd78d6eb985dba3ea15a1d12aae","9b10f9a29167b3350b01f00db84410f40a066fdd","5f15172770c0250ae385182f9bb9882c1be44b45","b6f83d871948e3f4216026b0455ddebfb1cf3b1a","06c9511a3a29f1afa3971b1885ad56b5a890dbdc","2620a9ecf588a4a76d22d5a8dd14657aec97d71b","704b2e130ad85ee95e136d00d55cce7da883cf57","5750815fc3230623164fa3cd3a983b6e58bf64f4","643c43c21c1aab97faa18669dd7ef27bd33e8989","6a6bc40832da2e03451fe1caa812d10c434f9b1a","f6c62e96e2cec8ea1f73047d4692aafd73dd9dc5"],"s2Url":"https://semanticscholar.org/paper/3376caa6140cf46ccb4c22454aa0069d8f05615c","s2PdfUrl":"","id":"3376caa6140cf46ccb4c22454aa0069d8f05615c","authors":[{"name":"David Sidler","ids":["2910553"]},{"name":"Zsolt István","ids":["1753260"]},{"name":"Muhsen Owaida","ids":["2094139"]},{"name":"Gustavo Alonso","ids":["1687400"]}],"journalName":"","paperAbstract":"Taking advantage of recently released hybrid multicore architectures, such as the Intel's Xeon+FPGA machine, where the FPGA has coherent access to the main memory through the QPI bus, we explore the benefits of specializing operators to hardware. We focus on two commonly used SQL operators for strings: LIKE, and REGEXP_LIKE, and provide a novel and efficient implementation of these operators in reconfigurable hardware. We integrate the hardware accelerator into MonetDB, a main-memory column store, and demonstrate a significant improvement in response time and throughput. Our Hardware User Defined Function (HUDF) can speed up complex pattern matching by an order of magnitude in comparison to the database running on a 10-core CPU. The insights gained from integrating hardware based string operators into MonetDB should also be useful for future designs combining hardware specialization and databases.","inCitations":["d251e2b4ddf95d84c2ff3d5eef01311ec1a323c4","c84206427e3c4978fb8d0e725e8f26e0bfed29dd","ea5d5ad680f54c81f455a194094cf02c669452f9","cfd6cfdab32782394652944ca4ccac7ec9f2c2a5","6f537c85b5160a6375306f6eca1a3e8558e7dbd9"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035954","http://www.davidsidler.com/files/sigmod17-patternmatching.pdf"],"title":"Accelerating Pattern Matching Queries in Hybrid CPU-FPGA Architectures","doi":"10.1145/3035918.3035954","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035954","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Baseline (configuration management)","Cache (computing)","Computation","Computational complexity theory","Decision support system","Join (SQL)","Memoization","PostgreSQL","Program optimization","Relational algebra","Rewrite (programming)","SQL","Value (ethics)"],"journalVolume":"","journalPages":"1243-1258","pmid":"","year":2017,"outCitations":["78b3f0d59de6f43bbb2725cec75d55d6137a88e4","335606158cd0e80d353c0820aa7f3519c0edef87","036e20936fc1e452509c0b64196a0e937ab733be","006cafc8d8f1af2595daa20078b501c10d9fcf5e","fc7f5ed67a23f708222e6a3c2243a12baa898c28","3f419db6f66c32bbb7ea887b139abd4e088a0405","07f617c9ceece546c5180ed301a010cde17b28b8","f9ba2d1dcd7a58436bd401b56766ad0050f9aab0","5ce1483f20173531cc259b60595ecd827cbbe8eb","0bc3f74da97f976e1f94deff106860d39c477be3","8df1e547181611e390c428de59d31ab69d64bcd1","a0203b4a547a6d172a053d39d1d618ee47ce3e31","89e701c706894415950eb4160ba95a717cdc9594","11ea30b09ba54b39f8d4c19e600d87f96b96ffaa","128985b85556c30ad405863f2a34340049957616","1f21c3d03726264e48d156f0430ec6357d6fa642","65e0af21793f0dc748a1755b736db4fbeb9bb4e8","114fd5089776a0562cf4e8276049cc11222fe51f","28e702e1a352854cf0748b9a6a9ad6679b1d4e83"],"s2Url":"https://semanticscholar.org/paper/3f9b77306c3160aafe370a6d36895f9dca124ebe","s2PdfUrl":"","id":"3f9b77306c3160aafe370a6d36895f9dca124ebe","authors":[{"name":"Brett Walenz","ids":["39614837"]},{"name":"Sudeepa Roy","ids":["31938009"]},{"name":"Jun Yang","ids":["2845918"]}],"journalName":"","paperAbstract":"Iceberg queries, commonly used for decision support, find groups whose aggregate values are above or below a threshold. In practice, iceberg queries are often posed over complex joins that are expensive to evaluate. This paper proposes a framework for combining a number of techniques---a-priori, memoization, and pruning---to optimize iceberg queries with complex joins. A-priori pushes partial GROUP BY and HAVING condition before a join to reduce its input size. Memoization caches and reuses join computation results. Pruning uses cached results to infer that certain tuples cannot contribute to the final query result, and short-circuits join computation. We formally derive conditions for correctly applying these techniques. Our practical rewrite algorithm produces highly efficient SQL that can exploit combinations of optimization opportunities in ways previously not possible. We evaluate our PostgreSQL-based implementation experimentally and show that it outperforms both baseline PostgreSQL and a commercial database system.","inCitations":[],"pdfUrls":["https://users.cs.duke.edu/~sudeepa/sigmod2017-iceberg.pdf","http://doi.acm.org/10.1145/3035918.3064053"],"title":"Optimizing Iceberg Queries with Complex Joins","doi":"10.1145/3035918.3064053","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064053","venue":"SIGMOD Conference"},
{"entities":["Compile time","Compiler","Crash (computing)","Database","Degree of parallelism","E-commerce","In-memory database","Multi-core processor","Online transaction processing","Parallel computing","Parallel database","Relational database management system","Server (computing)","Stored procedure","Transaction processing"],"journalVolume":"","journalPages":"267-281","pmid":"","year":2017,"outCitations":["2520cfc29a521f2333fda020d7ae41860f8dfebd","5a36f17e0560750a956064ff06b63bcd57c6145f","5046a718f92447642939f5c93414dc97225d726a","e75c5d1b7ecd71cd9f1fdc3d07f56290517ef1e5","ca61d435baaaa92dc06333bb7a54676e482283fb","3702d6e0c78050f3261fdbf0eb1aefbac59fb8cf","97498df02888b55d3a48648aadf7ce0769d7b358","514a5c15e8cf3f681febecad954a4508d9189c99","65106d0a26da1352faa5a32a8016f8504d10b1c4","7bc692b8d73d506dc7585eaecab30af3acf59459","016cc168aaf437843c65cb3ebdade0330007c2e4","12e1c4ebf2464570d461d26407c87e7439b99ff5","ef47742e72bd64fb1ae5359cd6d5dd6dfad34dc8","33457f49553d918e912c2d8c54b81f4fd8a4c234","13e6aa5f61267b2814fa9b32f47c17c0fcdef2d5","6e90c995cc9caa0f7d9d68d536f5e16e9bcbbcd6","6c079493f0d1f7df6613f00edc985a753e75a5c0","0d29a696d8c66d795336ab34aff0b6fb8decb06d","10551c91b4d36d1009b23b4d2b88a9e1733fe029","4b14389e3ed8bdf2c470e69cc0eff3be6fdbe254","11620e0e8d0224d4401439a1c6774f5bd750b847","9baa88ccbc656e0774ae1bc01d5698f7801919d6","3ae8993ebc28dd9b99d415d04d2b766dc99212d9","e8b3ecb8f19b638603ab296deac8aa3fbd303f90","1b3a8d042ed8569d027cb120774f50521709abb2","136eefe33796c388a15d25ca03cb8d5077d14f37","512e19f69011155c9618c650a7d4e2e525a4d1dd","66702084eca2b6ada4526b81fdc3d3c53b02535d","39e3d058a5987cb643e000bce555676d71be1c80","4ab55cf927d366b9307f4f5d1a705948b9f7ea02","412a9e54bbb31e12d008a9579994e009c5b40b46","56f6aec0132e56769e2036bbeff791dfa137d107","37d543efda665556815dc45af537a3400fb106c7","0997037e940df06ed7a6d19f7501579aab01e829","08d1cedbbaa798855e30fa7dc9ddbf88060b1399","71691ee2dbe001d599334e5389d80dd32c44a74e","3bb3f2b1e3642cbe3885cc616f576621d3f36fe4","549dd5a7c187fbf2a727f84f174e5ed79ade02b1","afb3bfadd61e2613d179ce3310581da883c66898","15c80ec5104e98d6f84b5ed348ba0276c0739862","5121709bf42b13a93c70b45a456c82db92850a02","9748241beb02ef1e2d0e6dc877c04b354033a838","2525c025f11aec60cff428271ca851381b92008f","2543a986d875f86119cb4ad9b1e287873ac4bce2"],"s2Url":"https://semanticscholar.org/paper/791453489be6112655b3049d9ae0a403bb31678b","s2PdfUrl":"","id":"791453489be6112655b3049d9ae0a403bb31678b","authors":[{"name":"Yingjun Wu","ids":["7860942"]},{"name":"Wentian Guo","ids":["3393323"]},{"name":"Chee Yong Chan","ids":["39712651"]},{"name":"Kian-Lee Tan","ids":["1688848"]}],"journalName":"","paperAbstract":"Main-memory database management systems (DBMS) can achieve excellent performance when processing massive volume of on-line transactions on modern multi-core machines. But existing durability schemes, namely, tuple-level and transaction-level logging-and-recovery mechanisms, either degrade the performance of transaction processing or slow down the process of failure recovery. In this paper, we show that, by exploiting application semantics, it is possible to achieve speedy failure recovery without introducing any costly logging overhead to the execution of concurrent transactions. We propose PACMAN, a parallel database recovery mechanism that is specifically designed for lightweight, coarse-grained transaction-level logging. PACMAN leverages a combination of static and dynamic analyses to parallelize the log recovery: at compile time, PACMAN decomposes stored procedures by carefully analyzing dependencies within and across programs; at recovery time, PACMAN exploits the availability of the runtime parameter values to attain an execution schedule with a high degree of parallelism. As such, recovery performance is remarkably increased. We evaluated PACMAN in a fully-fledged main-memory DBMS running on a 40-core machine. Compared to several state-of-the-art database recovery mechanisms, can significantly reduce recovery time without compromising the efficiency of transaction processing.","inCitations":["64451ec9c182374a0ce6a3503946692f674569e2","264a5e7a5230b228b86f63a75546738a66454c56"],"pdfUrls":["https://arxiv.org/pdf/1604.03226v2.pdf","https://arxiv.org/pdf/1604.03226v1.pdf","http://arxiv.org/pdf/1604.03226v1.pdf","http://doi.acm.org/10.1145/3035918.3064011"],"title":"Fast Failure Recovery for Main-Memory DBMSs on Multicores","doi":"10.1145/3035918.3064011","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064011","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Data access","Data dependency","Database","Distributed computing","Distributed database","Fragmentation (computing)","Inter-process communication","Online analytical processing","Relational database management system","Replication (computing)","Requirement","Scalability","Shard (database architecture)"],"journalVolume":"","journalPages":"315-330","pmid":"","year":2017,"outCitations":["08a3d212e2b6e2bc7d5166b194a16edd8c566b6e","2a4a6cc4942ca263fa598155c707fa8809372bb5","688c82d3a97368e0ffc9b32703adad5393e1109e","1d99b7749a9311d2db24a3d84728e444eff23e4b","4f43ae162baf252ff4a868f21633db3832c5cce0","8831310e66f79ee379ff99073a4dcd80cf51d893","f51674bb4796dc81d5ff9ee397b22b3aa0b8609a","0f44833eb9047158221e7b3128cde1347b58ccd6","13d350d63b88061db3b63355e90a05ef270972d6","8b9a748ae77f9235396e04301b82143feb1167fe","6fce42ef86ba6fb6d8f25b39622b22746640ee3f","1af9a3eefa1d0eafc895d571a3865a724084c7be","0658b1922d6a30a0191bb5fe13b0a9e43e49c999","be272d78b46895f6e9878d59238a0ccca88ea124","4f246dd7f2ba3764245d8a16c3048adf0cc68b1d","16cbcf9658d9d16a422b463587f6b9823d26b2ac","f010eef368d69d6ef80c473012aa83b49e7ee0e8","848c717ba51e48afef714dfef4bd6ab1cc050dab","b082bca6933d56bb630e2630aa014cb0919b221d","0acc31039de608f2ac51f59b6848a48d50c919a5","130ccb9eff2ac055e2abe185e14672a1cdeb2677","7709d65b7bee682f15961f05efb5c23850475e24","9325e04589893bf821da6d8be7546c3cdf97331b","d1c21c34936f587779c216ed79ca33883845caa1","32865cc4368d8b267346fac308cc9c367bd68cdf","123e38805c50b0816d4a52c3cf8d0e8ad05c5fe4","0541d5338adc48276b3b8cd3a141d799e2d40150","24251f02c34f32b1dd96572a1d984c4463a26a10","a4d773c524f3fafd7413fb505ca9e98f4c1ecdb0","53ad6a3c95c8be67bddbae3ef76c938adcd9775d","0cd4edaa194488d50bad837e9941ce4a3a254aeb","207def18c67fa8024741b7ae3cdc655b57f2053f","3dc937b9c635d08d3428703f11cb0fc6270930b2","48e992a734ef6ecbc9d5aeb3fc9135bbee531e07","037a0b4588db8a086e4feec9562a60b00dd05f99","74a9dece7565783b0e4d49806a131473db05555f","03639687dca8ec3e140e2a1705b5026b8c263fb7","0317680478b271366a9a51639253bc02b7d63924","1cbb5a54f4b3b0e4f48c0531f2e12b44b3d8bb36","a038197cf7d7d8cce171673aa377e491d0757d04","1d905342c3d78dd3236863382ae7bae0482d3055","67eb4c1794be54919266f70b5bf8ba7a6824f091","5f077c55d598864d16245febd6b77b35c185452f","9235602100bee501219229b91464c3a711bac9bf","8a43d82d7796d9d062fe6e650e3b84db71347a02","62d9c9469bd8f99548ba296a0db72a6752d6d181","1e557937f418accc13f9c5edb33a3d48259d80e5","0456f71d2dbbfd77bc933cf8b12bcfd126f6da89","676ee37c4d2faa71aec10b38db91545f9dcb612f","5eba0b1e946e787621b893a6ef8553e39d752eba","0f460e5e031db63ba81f9521e3f6c27a8a39ab93","19390e486bbf9891f9c13f4ca8b4f49cae1b1429","0d45d3f73e706ff444bde3a504d74fc5e7868a64","682f34e8845a5f54c20d636b3255525ded099502","740ee3de6f8ca734797d7a808c956e303f4a5730","c5ebebfb199fae183e0650e8af5b3ca20ad9a677","11b8ef5da9c8df214859bb41b60001a0abd2b5b2"],"s2Url":"https://semanticscholar.org/paper/bfa86f9268bd7189aced3bdb7dbb8dd15f3a6f4e","s2PdfUrl":"","id":"bfa86f9268bd7189aced3bdb7dbb8dd15f3a6f4e","authors":[{"name":"Tilmann Rabl","ids":["1731210"]},{"name":"Hans-Arno Jacobsen","ids":["1738552"]}],"journalName":"","paperAbstract":"A key feature of database systems is to provide transparent access to stored data. In distributed database systems, this includes data allocation and fragmentation. Transparent access introduces data dependencies and increases system complexity and inter-process communication. Therefore, many developers are exchanging transparency for better scalability using sharding and similar techniques. However, explicitly managing data distribution and data flow requires a deep understanding of the distributed system and the data access, and it reduces the possibilities for optimizations.\n To address this problem, we present an approach for efficient data allocation that features good scalability while keeping the data distribution transparent. We propose a workload-aware, query-centric, heterogeneity-aware analytical model. We formalize our approach and present an efficient allocation algorithm. The algorithm optimizes the partitioning and data layout for local query execution and balances the workload on homogeneous and heterogeneous systems according to the query history. In the evaluation, we demonstrate that our approach scales well in performance for OLTP- and OLAP-style workloads and reduces storage requirements significantly over replicated systems while guaranteeing configurable availability.","inCitations":["2b5e804e23c3cc227eec50aaaae21ac1234fba69"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064052"],"title":"Query Centric Partitioning and Allocation for Partially Replicated Database Systems","doi":"10.1145/3035918.3064052","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064052","venue":"SIGMOD Conference"},
{"entities":["Data curation","Interaction","Refinement (computing)","Requirement"],"journalVolume":"","journalPages":"667-682","pmid":"","year":2017,"outCitations":["13cbb8aa7d957987f76fcd3cc0ccb8ae623fdcb4","585681b8a7f941ab6bf5b34fa6437fc75f38966b"],"s2Url":"https://semanticscholar.org/paper/0d1199cec94a61b379ccb90d3b0238a1b31ddade","s2PdfUrl":"","id":"0d1199cec94a61b379ccb90d3b0238a1b31ddade","authors":[{"name":"Angela Bonifati","ids":["1699192"]},{"name":"Ugo Comignani","ids":["10757249"]},{"name":"Emmanuel Coquery","ids":["1718479"]},{"name":"Romuald Thion","ids":["1721642"]}],"journalName":"","paperAbstract":"While schema mapping specification is a cumbersome task for data curation specialists, it becomes unfeasible for non-expert users, who are unacquainted with the semantics and languages of the involved transformations.\n In this paper, we present an interactive framework for schema mapping specification suited for non-expert users. The underlying key intuition is to leverage a few exemplar tuples to infer the underlying mappings and iterate the inference process via simple user interactions under the form of boolean queries on the validity of the initial exemplar tuples. The approaches available so far are mainly assuming pairs of complete universal data examples, which can be solely provided by data curation experts, or are limited to poorly expressive mappings.\n We present several exploration strategies of the space of all possible mappings that satisfy arbitrary user exemplar tuples. Along the exploration, we challenge the user to retain the mappings that fit the user's requirements at best and to dynamically prune the exploration space, thus reducing the number of user interactions. We prove that after the refinement process, the obtained mappings are correct. We present an extensive experimental analysis devoted to measure the feasibility of our interactive mapping strategies and the inherent quality of the obtained mappings.","inCitations":["69f53559815f4645ec3e358b40e611ad3ad36a8c","b8a0b3852627b083ba9922702838cd09782b09d1"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064028","https://liris.cnrs.fr/~ucomigna/files/poster-sigmod17.pdf"],"title":"Interactive Mapping Specification with Exemplar Tuples","doi":"10.1145/3035918.3064028","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064028","venue":"SIGMOD Conference"},
{"entities":["Data center","Telematics","explanation"],"journalVolume":"","journalPages":"","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/bcf2d9d2a382dd782a7ec26f1656ca5327781225","s2PdfUrl":"http://pdfs.semanticscholar.org/bcf2/d9d2a382dd782a7ec26f1656ca5327781225.pdf","id":"bcf2d9d2a382dd782a7ec26f1656ca5327781225","authors":[],"journalName":"","paperAbstract":"MacroBase is a new kind of data analysis engine designed to prioritize human attention in large-scale fast data streams. Given increasing data volumes that are increasingly too large for manual inspection, MacroBase highlights interesting behaviors in streams and produces explanations for these behaviors that can be used for tasks including diagnostics, alerting, and root cause analysis. MacroBase has already found interesting, previously unknown behaviors and trends in production data in domains including mobile telematics, datacenter operations, electrical utilities, and satellite imaging. The purpose of this document is to describe the architecture, interaction model, and ongoing research in the MacroBase project.","inCitations":["9d6ac16d4f2bc78648c9b66995721b04ff2e7462","cf50d827bd05a50a3d05e8538fea6026877caf4d","65085beceabd9d4e6d30aef58ca7812b84ad787b","dcbcfaf9ef12c29a5120fc2eff57ab0634de4016","4937876603808427510230d9d7bdf15dfd686ebf","b61bd7521b65077eac8381e71facc397060c60b0","4f12e36e79485604932de3c9a3a0e22f2bf2e201","1e5ae8e09f00ea8f53047b7313b9dab884e96043","cbbf860f8065a3e1bd72a07d4cbac5f798065ca1","6315d7f2619d9ec05846765d1283dee28bce9bad","16b2f6152bae3005aa426b3cc45766a17126bc16","00f191227ef407a92db0581c2f39918d3726d2d6","1cfb0e14b5db871e6f88e4096fb6751d33741b1e","38a96a0585e6d4c5f9fe5d326fd639bb289e69f8","7352c0c3e4217188ebc73430d12d4ce240e35c79","d7c141c9290998c002cf5db3bb95e9ae044a1f7b","5715e1e106dae3a49a40314e3b05c142d38da6d9","5088b1ca95e4b3e988d30dadac20e8436f4a0c4e","0c8b6128488719a216b95d255d65de2a85c5bb07","fa099d45212e0b0e6486b6bd378e6f4fd06c222d","4853a26200889f033c0f509abf0f91d8cafba55b","2de68ac42d7b54b3ef0596c18e3d4a2b3a274f72","213b5f30cd84c80c1f53e46553fa221fdcc226dd"],"pdfUrls":["http://futuredata.stanford.edu/private/mb-onepage.pdf"],"title":"MacroBase: Prioritizing Attention in Fast Data","doi":"","sources":[],"doiUrl":"","venue":""},
{"entities":["Cache (computing)","Control knob","Data-intensive computing","Database","Database tuning","Machine learning","Management system","Relational database management system","Supervised learning"],"journalVolume":"","journalPages":"1009-1024","pmid":"","year":2017,"outCitations":["71c1a0fc681a7a62cdd1c6a533e5f581e2287781","73f585b1579c69d6b1e5c7c4a8226238e8448f94","4fd6f219cd8347d96095e8b0b79372c47c8ca901","153703ab30c7cb56a49718991f6bc450f0c2273f","5c3785bc4dc07d7e77deef7e90973bdeeea760a5","a114adf98d48bbaf5c26b496803f448d85e87ff0","1592fe924114866c1ac559bae33ea789930daa98","162d50e6e2c000baf10148f761cc0929aad48ca2","5dd36ed50668b5cc1c95ce6cf83b1b9b21a5f560","55dfddfa4b2ed657a95600f617978aff2bb3c0ae","4a66348c79300fc798db8fd45db84b39cc3da37f","9c018f1b0aabe84ba61dfc969e273f2a9653c6ec","4ca3c1040a4bc0d1ae200d26d1c18fbc6df0e95a","36d858eb19bba43244b92f7faabfce47b13f2403","0c40c39840e0eb577b67ec9f3f590d28fd30c683","62be31097d51acb6530dd933a7f0ff8741019937","347920406c9a9a3846adf485e2b864d4523a0652","5f41cc7c081b294f684928c35a08626490ec4f8a","723439f6dba7c6213772286a6d46bcd45265479f","7df1de1c9663c2dfaefc1277a7d1cb3366b8c358","e4984e24c407a629e7ad21315eb1e92449ee50cf","0346de4027e75bc194811be80421c6e403495c7a","0dafdc7debdcae528b2549489a03509cb4ecb9fe","22584367753de3804867fe88530468c5984d86fa","aeccdfbab928e994fe4a419130a4d24bea9571c8","e9775d2e173f989c580df3fc967a905c336405c5","9aa0d7253574e50fe3a190ccd924433f048997dd","10551c91b4d36d1009b23b4d2b88a9e1733fe029","36209da01ff06d4889f9472839a3373e1f211be3","702879a978853613de4de67a72999b8cc6acc80a","006b89abc356c1c3bf2dfa35f47c0601c39dce38","40fecfef456c760912685b372151732b38e69d6e","21c66366122ebde6c367b106e0067e10f3a1d4d4","019902292dff81eae20f3e87970dd7a1151d9405","502ff2f9220ebc8c3544e6c4a005e819429ab716","8c6f43d8a0ea0b183a7c277f576b52ac46d5450e","231a0787b6361fca082cefe580c41c74e230b255","44662438b9659fc7a48d32eae112dd9bcdef9ee3","1b2457906994b5942b0ecc6e0ca38e2e3b2450c7","489996303d862cc86eb8010fb818d47eab75ed12","1b65af0b2847cf6edb1461eda659f08be27bc76d","30c4b5432dded3ce170f58d96e8935d538c58b98","f4e62f813e8cb019c85504597a87a6f1cd3c2194","64cc18eacc8b33ab5b7ee2f789ca409bbd7455d9","1e557937f418accc13f9c5edb33a3d48259d80e5","9f74a87a39cf4922b7b13e4b5386eb52025959ee","1be16d8c557b15cdf2db9e7eb4453f2274fd60af","e0dbc2deeb87f9c17e7b2b298e0c8f4eb1bc3dcc","c5faa674df8fe81d17ec2537b865045c20d79990"],"s2Url":"https://semanticscholar.org/paper/1f1f47da8fff8da53589d7eab36d6bae32b2c3d2","s2PdfUrl":"","id":"1f1f47da8fff8da53589d7eab36d6bae32b2c3d2","authors":[{"name":"Dana Van Aken","ids":["40270373"]},{"name":"Andrew Pavlo","ids":["1774210"]},{"name":"Geoffrey J. Gordon","ids":["1736834"]},{"name":"Bohan Zhang","ids":["2903546"]}],"journalName":"","paperAbstract":"Database management system (DBMS) configuration tuning is an essential aspect of any data-intensive application effort. But this is historically a difficult task because DBMSs have hundreds of configuration \"knobs\" that control everything in the system, such as the amount of memory to use for caches and how often data is written to storage. The problem with these knobs is that they are not standardized (i.e., two DBMSs use a different name for the same knob), not independent (i.e., changing one knob can impact others), and not universal (i.e., what works for one application may be sub-optimal for another). Worse, information about the effects of the knobs typically comes only from (expensive) experience.\n To overcome these challenges, we present an automated approach that leverages past experience and collects new information to tune DBMS configurations: we use a combination of supervised and unsupervised machine learning methods to (1) select the most impactful knobs, (2) map unseen database workloads to previous workloads from which we can transfer experience, and (3) recommend knob settings. We implemented our techniques in a new tool called OtterTune and tested it on two DBMSs. Our evaluation shows that OtterTune recommends configurations that are as good as or better than ones generated by existing tools or a human expert.","inCitations":["cb80292ff6fa871c917ab1fdaed7ef40d2c05a11","178738930dc750ef8cf70f1dc7fbab6edca0d184","d308092a5da30ef6687b6a26287f1e54ba4c5e10","a55a685d254caeeb4f071062d5910734f8135057","0bbbcf1376762a9e1a6289b75286f39dec625728","502e33592ce72ccd5d68dae4acf3bb3c4d056e68","4fcb1e0a25a5617ddee8174b48af80d88b4881f4","ad64649f20cc20a2d1584cbc4b859d9fa9920538","0fb3400d39c08b6dddbbfa8689711ca36a87afd0","28e4ae18a652e7d67df3e3fa6f4703ae9ef930e9","7254ad8940dc3ea502ef65fd9b71a9a2952daf81","9d1ad91bff04bea0b8e6220c4da8244cd88d44b1","5b5552aae4a3a6943aa9b4d1f1ea08e30c4065f8","0bdb6e2cb1d8960ecf754fd4d28ea11714178fdf","a060a4be76d6789113df800da0f20aa62ac99990","8c7044398d1994b12a9bf7212e11398f59eaf446","576f13a5f349ecc60e5e491395e8aa7a9c9f0c05","162be49582b29ed18775f089810fb8cdc2ed6808","e20549f3678d18f1788debdeacd0fa121220669e"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064029","http://www.pdl.cmu.edu/PDL-FTP/Database/parameters.pdf","http://www.cs.cmu.edu/afs/.cs.cmu.edu/Web/Posters/CSSpeakingSkills-DVAken17.pdf","http://www.cl.cam.ac.uk/~ey204/teaching/ACS/R244_2017_2018/presentation/S7/Ioana_Otto.pdf","http://www.pdl.cmu.edu/ftp/News/newsletter17.pdf","http://db.cs.cmu.edu/papers/2017/p1009-van-aken.pdf"],"title":"Automatic Database Management System Tuning Through Large-scale Machine Learning","doi":"10.1145/3035918.3064029","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064029","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Connected component (graph theory)","Database","Directed acyclic graph","Directed graph","Graph (discrete mathematics)","Graph operations","Reachability","Strongly connected component","Time complexity","Transitive reduction"],"journalVolume":"","journalPages":"375-390","pmid":"","year":2017,"outCitations":["0c2ff25bf68074214a960666bff2a7b0d5e29fcc","13bda7e7a6d3ae153ff1b8c546174d2bfac6c5aa","ea1e01aa57774c0adff45dbfe9cd5a47d8b163c4","15ad785d44ff34ad028426c31a1e8d43b2b44ab6","b503111efb0560aaea70e950a6928116df2862a7","e26a832a1588b7e38212a5c1e31c6d9dfb81e713","0420abce5921d7e80838ab746da96c1b4bc71474","1ad8410d0ded269af4a0116d8b38842a7549f0ae","480dabdf58171f02358fbcc39a011680f6ba91c3","3030fa2aecda339d593b86a260bfab9988b42df7","c17014959370282e7c3efc96d9d831c1663c919f","95eb1efa27358aa89dda77545758bc58b53ede4d","229c3cb87d18538315b18c5ad6796ac367adf45a","385742fffcf113656f0d3cf6c06ef95cb8439dc6","24ec656fa6eb25b7ddaba66697dd660a0ddc283b","d3a7853dabbd406bb803fbec7de7292e5e65947b","29b3fdcdda43e08534d6cae560b08dd2fbe88427","b9c5678100693e00b59e58f3368f4797b9f11e77","3615c522a69d613491a780a47571a84c476c3712","26a2b94a118334585f5d717b24ef06b6f9014ba8","d153c2177e8058f82a45c492ddc6f60ea5d58ab6","2fbeba55935a0fa9597d1ef4cc1cbdac7e41e39e","d0be1e20643e7e15bd4669f1c3ef0c2287852566","421241a61dc5332237c84116422043c3503f6577","81a2883e9a0396b2eda737d048b85281766f58af","c2070e3e1fce3c420d4e3c2d310fb63f5aa7ccb6","6384234e698f793cfba0cbf890b1c2a2209d06b7","737e43bd36ac3cc785915fa2930997976137ef35","d59baf77e392539565c286de8a716f624bf3336f","a3d5e5d2fae76af242e40e35989237a8c3e6385f"],"s2Url":"https://semanticscholar.org/paper/9cf7699e39fa3aad6b60aa69822dda6d06f600d7","s2PdfUrl":"","id":"9cf7699e39fa3aad6b60aa69822dda6d06f600d7","authors":[{"name":"Junfeng Zhou","ids":["2914356"]},{"name":"Shijie Zhou","ids":["1818568"]},{"name":"Jeffrey Xu Yu","ids":["1718849"]},{"name":"Hao Wei","ids":["1725477"]},{"name":"Ziyang Chen","ids":["1871595"]},{"name":"Xian Tang","ids":["35676781"]}],"journalName":"","paperAbstract":"Answering reachability queries is one of the fundamental graph operations. The existing approaches build indexes and answer reachability queries on a directed acyclic graph (<i>DAG</i>) <i>G</i>, which is constructed by coalescing each strongly connected component of the given directed graph G into a node of <i>G</i>. Considering that <i>G</i> can still be large to be processed efficiently, there are studies to further reduce <i>G</i> to a smaller graph. However, these approaches suffer from either inefficiency in answering reachability queries, or cannot scale to large graphs.\n In this paper, we study <i>DAG</i> reduction to accelerate reachability query processing, which reduces the size of <i>G</i> by computing transitive reduction (<i>TR</i>) followed by computing equivalence reduction (<i>ER</i>). For <i>ER</i>, we propose a divide-and-conquer algorithm, namely <i>linear-ER</i>. Given the result <i>G<sup>t</sup></i> of <i>TR</i>, <i>linear-ER</i> gets a smaller <i>DAG G</i><sup>&#949;</sup> in linear time based on equivalence relationship between nodes in <i>G</i>. Our <i>DAG</i> reduction approaches (<i>TR</i> and <i>ER</i>) significantly improve the cost of time and space, and can be scaled to large graphs. We confirm the efficiency of our approaches by extensive experimental studies for <i>TR</i>, <i>ER</i>, and reachability query processing using 20 real datasets.","inCitations":["f077dabe280ab3ed9956a5db54f7162fa82b44ce","0ed6e7d571fed36bd705675ce9261af440a7a7bb","c9b7ce8aae0e9ba537847fab95b4e4511c148679","aa8c9f7dc4695e960b61341e4ed81015ecf63248"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035927"],"title":"DAG Reduction: Fast Answering Reachability Queries","doi":"10.1145/3035918.3035927","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035927","venue":"SIGMOD Conference"},
{"entities":["Big data","Bioinformatics","Computer scientist","Parallel computing","Personalization","Pipeline (computing)","Rewrite (programming)","Speedup","Synergy","Whole genome sequencing"],"journalVolume":"","journalPages":"187-202","pmid":"","year":2017,"outCitations":["3b3a2c3ade468de01802e0d3e333b4b02cdfb8ff","6a74715681aa5040d4818e90ded929f2501c5b3a","53e978ec681a8aba65523e70ab502c63960e35cf","58fc1b429d4ef4dd5d804bae8c54d4238bd15cc6","4cad8f2a31b3c72742a761fe90a372d4a4717ebf","0558c94a094158ecd64f0d5014d3d9668054fb97","0388e6b008d51c922341a2caccbc9ce7187c6850","720f612c68bdefc404bb2ac8a702cd1804b2472f","0b72a5e4bec54e9f0a4d77db5b484d27886b49fe","d3c0a49cd01559bc2402d91bbf7290c43634218b","2228b4208c5ea6754df6edcae805038f3e47857c","032e0ad4973e40acc3d83afd3d6cf57d5befc968","1529d0842475f8ad061f0e725449b7c7ce19b6ac","196514ca53f505dec7a8a2b446fc599e8de3f0cc","3edb4a12b89adc56bb899c57557ec9dab39f7960","5ab1e2783b702d89865df5834c8fe22124ed890a","efa5558bddd68abe4adc81adbbef6f739e648392","55f633638dafc5bb07f65cf7a12886ad0322f781","4e7c664adc0bfc1800d70d6593515c78df1509db","2e5186cb10b1945f13ad8a961100b94e63a96b95","3146b400f6257d8dbe0fa99fe171c5e2dc3d5dff","14a80b973aeb96e6f2f8b9e292fc05b0d5f9aad0","700e1d1b7c54711e96645691438d7fd9fda229ef","bd0b6d9a13e76ada9b634b988bdb3a0131ac5533","42fee5b7c0d96f93172ac64bfef5a888874f3ab6","8315f131d02ab573b6eda86bda6437f208cef6fb"],"s2Url":"https://semanticscholar.org/paper/554262fc1b37f8a3d45e91ade79c851f776748c5","s2PdfUrl":"","id":"554262fc1b37f8a3d45e91ade79c851f776748c5","authors":[{"name":"Abhishek Roy","ids":["1800402"]},{"name":"Yanlei Diao","ids":["1891854"]},{"name":"Uday Evani","ids":["10776562"]},{"name":"Avinash Abhyankar","ids":["5442319"]},{"name":"Clinton Howarth","ids":["31890802"]},{"name":"Rémi Le Priol","ids":["10712297"]},{"name":"Toby Bloom","ids":["1707880"]}],"journalName":"","paperAbstract":"This paper presents a joint effort between a group of computer scientists and bioinformaticians to take an important step towards a general big data platform for genome analysis pipelines. The key goals of this study are to <i>develop a thorough understanding of the strengths and limitations of big data technology for genomic data analysis, and to identify the key questions that the research community could address</i> to realize the vision of personalized genomic medicine. Our platform, called Gesall, is based on the new \"Wrapper Technology\" that supports existing genomic data analysis programs in their native forms, without having to rewrite them. To do so, our system provides several layers of software, including a new Genome Data Parallel Toolkit (GDPT), which can be used to \"wrap\" existing data analysis programs. This platform offers a concrete context for evaluating big data technology for genomics: we report on super-linear speedup and sublinear speedup for various tasks, as well as the reasons why a parallel program could produce different results from those of a serial program. These results lead to key research questions that require a synergy between genomics scientists and computer scientists to find solutions.","inCitations":["398c22da3edb238bcf928d24fd9a65e2a219a2c8"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064048","http://people.cs.umass.edu/~aroy/gesall-sigmod17.pdf"],"title":"Massively Parallel Processing of Whole Genome Sequence Data: An In-Depth Performance Study","doi":"10.1145/3035918.3064048","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064048","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Central processing unit","Complex event processing","Computation","Experiment","Graph partition","Kleene star","Responsiveness"],"journalVolume":"","journalPages":"109-124","pmid":"","year":2017,"outCitations":["a087916314b7986ac11510dc2e26a812431675f5"],"s2Url":"https://semanticscholar.org/paper/40fe3bee79d95d6886d778cf16b6b120ad0509f2","s2PdfUrl":"","id":"40fe3bee79d95d6886d778cf16b6b120ad0509f2","authors":[{"name":"Olga Poppe","ids":["3035292"]},{"name":"Chuan Lei","ids":["40536846"]},{"name":"Salah Ahmed","ids":["3681379"]},{"name":"Elke A. Rundensteiner","ids":["1715020"]}],"journalName":"","paperAbstract":"Event processing applications from financial fraud detection to health care analytics continuously execute event queries with Kleene closure to extract event sequences of arbitrary, statically unknown length, called Complete Event Trends (CETs). Due to common event sub-sequences in CETs, either the responsiveness is delayed by repeated computations or an exorbitant amount of memory is required to store partial results. To overcome these limitations, we define the CET graph to compactly encode all CETs matched by a query. Based on the graph, we define the spectrum of CET detection algorithms from CPU-optimal to memory-optimal. We find the middle ground between these two extremes by partitioning the graph into time-centric graphlets and caching partial CETs per graphlet to enable effective reuse of these intermediate results. We reveal cost monotonicity properties of the search space of graph partitioning plans. Our CET optimizer leverages these properties to prune significant portions of the search to produce a partitioning plan with minimal CPU costs yet within the given memory limit. Our experimental study demonstrates that our CET detection solution achieves up to 42--fold speed-up even under rigid memory constraints compared to the state-of-the-art techniques in diverse scenarios.","inCitations":["18f97e0f25ff60651992c30eed70d3b0b6e24e68","f43ab3ebfe43a33ff0204832b8ca89e6a9b79f0f","eb23b67ff0450e83691548cd8e8043edcd9d6f47"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035947","http://users.wpi.edu/~opoppe/papers/CET-poster.pdf","http://users.wpi.edu/~opoppe/papers/CET.pdf"],"title":"Complete Event Trend Detection in High-Rate Event Streams","doi":"10.1145/3035918.3035947","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035947","venue":"SIGMOD Conference"},
{"entities":["Access control","Cache (computing)","Computer data storage","Data compression","Data system","Experiment","Full table scan","Multi-core processor","SIMD","Selectivity (electronic)","Single-access key","Systems design"],"journalVolume":"","journalPages":"715-730","pmid":"","year":2017,"outCitations":["6abf5107efc723c655956f027b4a67565b048799","92e0243e1a73c77ef8b90292e3798f765b38f269","02f8e4a8b3f16a988233f309db548415268322c2","459693b64731566a5cce5aa8b05fb88275865e9e","24c3330d34d640945e0eb99fe4a0b1c31695a8cb","19629429a0ade02b450f5a585bdde880fd32b22b","3a134bc11a5805bcf45fdcb88a91321a1b1b63c3","34fa41ccb6e548612886623916d502fce17fd3a8","eb35aa48b342cf5733977ad2634701fe9c7cb603","c0b438eee7bd423606da9335229602b9c77c10d4","6521560a99dd3c4abeec8ad9634e949d5a0e77cd","6033797f241a3687aab939db1d88b5184d32c0fb","2d403a99e4dc71520aad53e46ba41c52d089207e","079433997c7270ea95e23042ffd8105d75d22cdd","2ceb62fcec9212fb408cf6ae847ff3a03b52f83e","19e5a8ea876cee86e78b659fc96ae18eb8c3a834","207def18c67fa8024741b7ae3cdc655b57f2053f","a4d7e7af926b1aee100dbe370021ef3fc6d460bc","1be04eef05d2547199ed787125f38610a2838658","8db5d8f4bf055bbe64ccfe29c5fd778ef24ade5b","359760cb0df73b9d8e6501b5ab5ff93a6c12b44f","b59c6e2eca208e99a18d2778d99cccd1792835fc","1dc19048a74d9bc7564f0114dc201ffc9e77d43a","14023b8086f53f29376fe6351cf5c68aac7b24f1","463bec3d0298e96e3702e071e241e3898f76eff2","370e1fcea7074072fe5946d3e728affd582a9a44","55ce0391cae3d7663a26bc6bb1a1e5618b8b9475","1d5cbc071f918143dbedf67a513850eadf30cbae","4139eedda8717ffd60052f68ed78b996aaebfced","09c1b69ab0fe1315b0d5e5e0b0853585c4a319b5","1c27eafecd3d6f0008d74ffbe1e7c59a25869407","2b320e83114b35b35570010a9e8dbfb8d1b01e85","96f73a90e87b330e60de8d403870aa81ee21a65d","0235fb69431fa5892333eb48a06ede07df6ff4f6","52b32996324d12ae6c9068e6ff301ece06f09835","9141bafcff1df2dbabf9a20671d2fa1bcb55aae5","04700bcc5abfad47d11b67a2d9901f01c8f0adf5","291470e5e557ac526f79a59c83e98fbf53406401","e75c5d1b7ecd71cd9f1fdc3d07f56290517ef1e5","8541e44cfdc11587a04581987a03daccddd3514a","0a5033c0b2bb2421f8c46e196fb0fb1464a636b6","206b086db0cc1c807a9fdbf7bbc9c261a50bfd34","cd4b958bf9dda5f44fbb457f7bf0eca96d6563e7","da9a4fdd63d6c9f30e1f5b8032fbf8ac3f79f7b6","ab4e0d6c59196243ab8d7f8644ecff86708fbefe","313e8120c31fda6877ea426d8a3be9bcf1b6e088","239c67e18caa0001ae05784d8dcbd4d1d1c67103","5046a718f92447642939f5c93414dc97225d726a","afda6470dd16dc0a865dbb6fc291e5806132379b","3c6be4c9ea5c56d4ab97aabb4e7c9d5ced57bea8","8479ca0d391184dc7c0c217df08e10046169c9fd","18869d8964793da4837b5b38d4aec5854d37f08c","31d2c9e85d395b0dcb48123d03b1b33440d389fb","30b1293e39c52ddd0e2a617de47c1ad843621258","03416be8097852a54dd3e309434e5a0806824646","ef47742e72bd64fb1ae5359cd6d5dd6dfad34dc8","bf24ea819099ce17fd5f9f497e4598e980288564","6089f230642f394d3688e4a373117a5ab02c8521","a1330395dda0d0174926f5152778ead7925983f7","beceeaaeee67884b727248d1f9ecda075e4ce85d","f8e04cb0d6ffa19b3cfe57f10c0763fbf762e2df","1d3e8f4d3ce97a3779ed9e395a793d4a935dda60","5ad1dd1aa78ba772c969aa01ee5e8ee0d255ce3d","2616c0df5d07bd88356381976243f21b4ddd0344","153703ab30c7cb56a49718991f6bc450f0c2273f","7ead08393fa2000ea03bb1cc1e3e6e0ac991aac6","d4ca38d1a7786a7a11ebf874dceaf95d0b53d4da","3c457cec00499e41dd05516db79c4daf836102ad","3be993b9891d812581d7c2649a4224107570049a","6c5462d31a0d0f4e6cb2ff7ae795250957d9fcab","a34b2c1c1fdbb800ea84028325fb8b01f673157f","0ad5ed5a0a7b9210993753d7594c7285d5e9b179","3aed29136db8f1e5c6a89fc22d3ae4b4926a3555","2c5b8766a1dae62b86ba38013253ab8673f6ec44","45ac2218b74fd28ff170dc93cf4390649466c491","2dbd58aa9b36388c92d3ccb5bd1bc387ea712a30","4f05a78c2e2abf932915c33c6a2bb9c726ce4ac2","4a283fe7de108d476ba8cab69acbbed907e5c4d8","0b19f413ffb5bc68b43f3bd05a97c282a7c6d6ab","834b72142d0737b12b53540ea671cd6b6d5be5c3","1cf0a0e6c09bbc2539d2fffddc372d47fbce14fb","295521cfe1a56458d53a58613de5fb92c97c5c23","2c1a0af30cc12ec108ce8bffde856ced8b759022","0f288da3454e8d5750dd319962a28cabe07709a6"],"s2Url":"https://semanticscholar.org/paper/2c9f40ac8125cc5115d8d65eabb5c257d67c9b5f","s2PdfUrl":"","id":"2c9f40ac8125cc5115d8d65eabb5c257d67c9b5f","authors":[{"name":"Michael S. Kester","ids":["3109687"]},{"name":"Manos Athanassoulis","ids":["1840402"]},{"name":"Stratos Idreos","ids":["2203901"]}],"journalName":"","paperAbstract":"The advent of columnar data analytics engines fueled a series of optimizations on the scan operator. New designs include column-group storage, vectorized execution, shared scans, working directly over compressed data, and operating using SIMD and multi-core execution. Larger main memories and deeper cache hierarchies increase the efficiency of modern scans, prompting a revisit of the question of access path selection.\n In this paper, we compare modern sequential scans and secondary index scans. Through detailed analytical modeling and experimentation we show that while scans have become useful in more cases than before, both access paths are still useful, and so, access path selection (APS) is still required to achieve the best performance when considering variable workloads. We show how to perform access path selection. In particular, contrary to the way traditional systems choose between scans and secondary indexes, we find that in addition to the query selectivity, the underlying hardware, and the system design, modern optimizers also need to take into account <i>query concurrency</i>. We further discuss the implications of integrating access path selection in a modern analytical data system. We demonstrate, both theoretically and experimentally, that using the proposed model a system can quickly perform access path selection, outperforming solutions that rely on a single access path or traditional access path models. We outline a light-weight mechanism to integrate APS into main-memory analytical systems that does not interfere with low latency queries. We also use the APS model to explain how the division between sequential scan and secondary index scan has historically changed due to hardware and workload changes, which allows for future projections based on hardware advancements.","inCitations":["6f10e7cc100865feec746294e90e8d9ca2322059","8c7044398d1994b12a9bf7212e11398f59eaf446"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064049","http://stratos.seas.harvard.edu/files/stratos/files/accespathselection.pdf"],"title":"Access Path Selection in Main-Memory Optimized Data Systems: Should I Scan or Should I Probe?","doi":"10.1145/3035918.3064049","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064049","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Central processing unit","Data parallelism","Database","Experiment","Graphics processing unit","Multi-core processor","Parallel computing","Pareto efficiency","Programming paradigm","Threaded code"],"journalVolume":"","journalPages":"447-462","pmid":"","year":2017,"outCitations":["4439b5ce4506099452a2b2c30939bfa9f6020eb9","4a7960e5f9e16aefbed71ae5d437cd0ccfcfc48a","05a99a31ed4a5a25e21859fca562b7c0f70ab0dc","34fa41ccb6e548612886623916d502fce17fd3a8","335606158cd0e80d353c0820aa7f3519c0edef87","43d794b0c7e8fbed5d65a71cd2e06816233ee6e4","339358fda0285c6760edce559105b97fdabae02d","3ece2061c7c94e406c2ca28845f76e050ba81877","6130cd6b45f26d58ce9255b2dce9d82095ab1d36","93cccf4711ae0cfbf1bbdf048c089eacb333f742","410e117f9fb9c89f5edc9c8c2490bb8fada4f148","041969f14a8deb754f5162194d917bdcaf782319","99593995f1772301413463a64a165dcae583ca7f","6d59fd2b815de3c5836b362cd177cda0b115ac71","5adece4919d359441c506260dc22ea6e7489e9fd","4701832beac42eb0b6262157966314c9e02d9dc0","6e21a27e457c25fa6158c5c78757c5b7bc0017a6","6c15df6e5195b05083fc05d80d74a7f595a5bb93","534b6dee5e86587676047d7ff921cea970b7d95b","88333eaec5057661e1306c875248e9c8cab07c2b","2a4cf7df272cb2b7d684c1e630594b5368d67b7d","65848c1e1e7f04350b30176f504826f4ee04dd39","85d542ce705eb3fcb923ca93d781d93c4a6ee061","893167546c870eac602d81874c6473fd3cd8bd21","97669a145aa4011e1cabd1a2ca269256774c240e","4279521956426d1fb4fb71270e0ed95e292163c7","9fb8f081e203cc0114ea93a1b19123aa164438b9","6247338483718ef2876cbb21e483ee4bec66c51d","772ddb61b7c96033c4ccae4303d35d74ccf15470","a6725be97c70a3f9c7719f23d4d8233e4771cdf1","be87b87400d68221be036d8c7b36b1dc09d2775b","9d62524ce36b4ecdefe847ef5c95c040569991f6","6c27f5ba435733960ed6624f9a2b7a7785c8cfef","a40cb295b6c1633c549d5846cd9fe59c381e6920","1be11ffbcc103c070e9de3a28eeca2de5f8f8369","5dbe84872b42cb6167d3b601fdf68b4eb2d7f5d9","a1f2fb587abcab6cca51abc3c9fd28bd8b06737c","00689648ecb99287550c99479d221088327f8692","8865aeb8efaa49a1700230e2cb1dee4c157800c8","8e2fe6add0e4f6643409202da05e69cb4bfd20f2"],"s2Url":"https://semanticscholar.org/paper/8a1a0335500abde19a441d33214555dd1d4b7602","s2PdfUrl":"","id":"8a1a0335500abde19a441d33214555dd1d4b7602","authors":[{"name":"Kenneth S. Bøgh","ids":["3103778"]},{"name":"Sean Chester","ids":["1738624"]},{"name":"Darius Sidlauskas","ids":["3132288"]},{"name":"Ira Assent","ids":["1713664"]}],"journalName":"","paperAbstract":"Multicore CPUs and cheap co-processors such as GPUs create opportunities for vastly accelerating database queries. However, given the differences in their threading models, expected granularities of parallelism, and memory subsystems, effectively utilising all cores with all co-processors for an intensive query is very difficult. This paper introduces a novel templating methodology to create portable, yet architecture-aware, algorithms. We apply this methodology on the very compute-intensive task of calculating the *skycube*, a materialisation of exponentially many skyline query results, which finds applications in data exploration and multi-criteria decision making. We define three parallel templates, two that leverage insights from previous skycube research and a third that exploits a novel point-based paradigm to expose more data parallelism. An experimental study shows that, relative to the state-of-the-art that does not parallelise well due to its memory and cache requirements, our algorithms provide an order of magnitude improvement on either architecture and proportionately improve as more GPUs are added.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035962","https://sean-chester.github.io/assets/preprints/sigmod_boegh_2017.pdf"],"title":"Template Skycube Algorithms for Heterogeneous Parallelism on Multicore and GPU Architectures","doi":"10.1145/3035918.3035962","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035962","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Algorithm Selection","Data dependency","Differential privacy","End-to-end principle","Metaheuristic","Naive Bayes classifier","Naivety","PYTHIA","Range query (data structures)"],"journalVolume":"","journalPages":"1323-1337","pmid":"","year":2017,"outCitations":["47f8fc00b01f76c652da39173be4f5b4eb62757b","0e12b1a390a8e6108cc8500acfadcb1f3409e535","2dbb9570eca417eb62f349e3322366c730e4357b","009d284fe935b5f421d24321073097a0cd34e21f","1cacac4f0ea9fdff3cd88c151c94115a9fddcf33","04ce064505b1635583fa0d9cc07cac7e9ea993cc","167343175b3a8965585b45707f6b8a217ec327ad","1050926bf7fc494f56f332bfbc0dee494b2ab8ff","34bdd36330946cf9b377d274bdaaa7dc41888aa2","63b88452574095639ef9a1f692eef3c1ec386b0a","0fba3766c7d613da8f35a2872f728c0c9e081092","7d093d143a149b3bcefd1727b05305a5c42f5580","0b9286a010bee710e74362a35f96dd1c6fee0fdb","1cd8cd2bcdae06d72c7da16091f1c525221a58e8","12b5772dcd12ff9f2f7ec553a09c6f3cdd2091bb","56c56187cdaa03372298fb6ad1dc51dba7b3499b","17fac85921a6538161b30665f55991f7c7e0f940","0ab8aa62424d49562964f7fe5119fc1a16104538","188b3b5ffc060110a650eebe33ee911a8e93f553","9509f45ebc129bd68ea94d55d90fee410afb8143","ca89b599a814440ecf4ee36039d28ead6484e767","0ce4e33a66a354b431fd9ca0cad65f2e528c1f11"],"s2Url":"https://semanticscholar.org/paper/0d5caaeb3f0a03bd396c556b9f422781b39dc5bb","s2PdfUrl":"","id":"0d5caaeb3f0a03bd396c556b9f422781b39dc5bb","authors":[{"name":"Ios Kotsogiannis","ids":["8817631"]},{"name":"Ashwin Machanavajjhala","ids":["2357165"]},{"name":"Michael Hay","ids":["2103203"]},{"name":"Gerome Miklau","ids":["1729605"]}],"journalName":"","paperAbstract":"Differential privacy has emerged as a preferred standard for ensuring privacy in analysis tasks on sensitive datasets. Recent algorithms have allowed for significantly lower error by adapting to properties of the input data. These so-called data-dependent algorithms have different error rates for different inputs. There is now a complex and growing landscape of algorithms without a clear winner that can offer low error over all datasets. As a result, the best possible error rates are not attainable in practice, because the data curator cannot know which algorithm to select prior to actually running the algorithm.\n We address this challenge by proposing a novel meta-algorithm designed to relieve the data curator of the burden of algorithm selection. It works by learning (from non-sensitive data) the association between dataset properties and the best-performing algorithm. The meta-algorithm is deployed by first testing the input for low-sensitivity properties and then using the results to select a good algorithm. The result is an end-to-end differentially private system: Pythia, which we show offers improvements over using any single algorithm alone. We empirically demonstrate the benefit of Pythia for the tasks of releasing histograms, answering 1- and 2-dimensional range queries, as well as for constructing private Naive Bayes classifiers.","inCitations":["15c34de38e69935fd8c4b5147708d88a5f3c8552","0c5eb2bcc294db127645324e26f6ddbe25b38db1","25b6e649699a4121cd629828f8f7595d58a6fd0f","531c3177ad2804ea1358da5bc68737fca3bc9a71","ec250679861ba116b89cecd27a52364eb818ba73"],"pdfUrls":["https://users.cs.duke.edu/~iosk/pubs/pythia-SIGMOD2017.pdf","http://people.cs.umass.edu/~miklau/assets/pubs/dp/Ios17Pythia.pdf","http://doi.acm.org/10.1145/3035918.3035945"],"title":"Pythia: Data Dependent Differentially Private Algorithm Selection","doi":"10.1145/3035918.3035945","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035945","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Benchmark (computing)","Expectation–maximization algorithm","Experiment","Time complexity"],"journalVolume":"abs/1705.05144","journalPages":"","pmid":"","year":2017,"outCitations":["460a9dbc3bc1434d1999362427f70e96be741b08","4cd73382dc17561cd276f276c61d5ebf39bf69ad","6eb45da9c8582c2e426a4896ff399987b73558b3","20c88e23020ea3c42e640f8ae3dc2a1f8569892d","4bb0f607c1f6be38ca720ad6913577a778cc2f15","4b983a1a0b370a4ea87c2be4f2c7c53b13edb4f6","23d85a0008429845870780c6db3640c05165acaf","89ee56421940d3d84bb0e6a32d1e6b57d871ff59","6e2a2e690ed9cd8cc4e0401d4edd7e541a88c557","0fedb3f3459bb591c3c2e30beb7dd0a9d3af3bcc","abb152802d5b4686a394e221abe951187ea06158","28bf0df09f97e7ef9108e71b45fe1b9a7aa201e2","b790f9ae49cdee5354eacfc7897ab9752acd5e2a","b9e43395663f74c581982e9ca97a0d7057a0008c","184cbf767d2f5501ddab3babe7be8ba93321e14c","15bab2a8c42af2bed7e811fdec7db655f9392bad","048a42699d9991ec18b34bdb484ef244830e1d71","8476714438669d5703690d4bbee9bfe751f61144","3d84a02dfe4fc904aa729b8b7ca51fd8c97a9dc7","18badf42f540207df7b76e639c34dff823119b21","480b1e3419d38363604016a2746f3f9b3bdc7de6","7febcbdf1b86ff38d19d65927f83bab185f44e1d","706c83309fa09454a136d4e607364b27be66172c","2d49ad12e22313a82e7f14dd41efe20ecd5daf43","72465eb427490619a5a625a45dda81c92a8cfe14","d7f9c3253552e13f24c3b73bc055ef60388af57c","0a3858df9b27de264f39d774e26e1be50ef28337"],"s2Url":"https://semanticscholar.org/paper/42b0fb834260a07be0a358ecaabd822a148a5f3c","s2PdfUrl":"http://pdfs.semanticscholar.org/fe35/53a10fbc21788d2d52e14bce346e94c1fd36.pdf","id":"42b0fb834260a07be0a358ecaabd822a148a5f3c","authors":[{"name":"Wei Lu","ids":["40178792"]},{"name":"Xiaokui Xiao","ids":["33285410"]},{"name":"Amit Goyal","ids":["1770151"]},{"name":"Keke Huang","ids":["2558448"]},{"name":"Laks V. S. Lakshmanan","ids":["1708593"]}],"journalName":"CoRR","paperAbstract":"In a recent SIGMOD paper titled “Debunking the Myths of Influence Maximization: An In-Depth Benchmarking Study”, Arora et al. [1] undertake a performance benchmarking study of several well-known algorithms for influence maximization. In the process, they contradict several published results, and claim to have unearthed and debunked several “myths” that existed around the research of influence maximization. It is the goal of this article to examine their claims objectively and critically, and refute the erroneous ones. Our investigation discovers that first, the overall experimental methodology in Arora et al. [1] is flawed and leads to scientifically incorrect conclusions. Second, the paper is riddled with issues specific to a variety of influence maximization algorithms, including buggy experiments, and draws many misleading conclusions regarding those algorithms. Importantly, they fail to recognize the trade-off between running time and solution quality, and did not incorporate it correctly in their experimental methodology. In this article, we systematically point out the issues present in [1] and refute 11 of their misclaims.","inCitations":[],"pdfUrls":["http://www.cs.ubc.ca/~goyal/research/Refutations%20on%20Debunking%20Myths%20Influence%20Maximization.pdf","http://arxiv.org/abs/1705.05144","https://arxiv.org/pdf/1705.05144v1.pdf","https://arxiv.org/pdf/1705.05144v2.pdf","https://arxiv.org/pdf/1705.05144v3.pdf"],"title":"Refutations on \"Debunking the Myths of Influence Maximization: An In-Depth Benchmarking Study\"","doi":"","sources":["DBLP"],"doiUrl":"","venue":"ArXiv"},
{"entities":["Adobe Flash","Adobe Flash Player","Byte","Delta encoding","Emulator","Flash memory","Flash memory emulator","High- and low-level","IBM Tivoli Storage Productivity Center","In-place algorithm","Multi-level cell","Online transaction processing","Throughput"],"journalVolume":"","journalPages":"1571-1586","pmid":"","year":2017,"outCitations":["7ae91ea70c601145a9c977b8b0419f6ba4c42900","d4c9dd82ff88ad4a1f26fbe9424e2a81559d417b","2525c025f11aec60cff428271ca851381b92008f","0997037e940df06ed7a6d19f7501579aab01e829","ca6c637d2ef7d0ff5a2d77139b07eb7ee7e7bbdf","437df9d3c0f294dadddae07ad6fa42e31940e143","a08fde3d9b36c7e570598010d2c3452b64946097","5a85a3e51019c7d28136efd5ad17697a61ce200d","29c8572f3bb27e4dc2f1c05a51e2b8cdaa4e2b15","ddc3e4501691c41bda5d927628f5f4abb2cfeb7f"],"s2Url":"https://semanticscholar.org/paper/6e82d815f9ea3e0a09ab96221843d0edd04ce499","s2PdfUrl":"","id":"6e82d815f9ea3e0a09ab96221843d0edd04ce499","authors":[{"name":"Sergey Hardock","ids":["2754784"]},{"name":"Ilia Petrov","ids":["40145493"]},{"name":"Robert Gottstein","ids":["2252634"]},{"name":"Alejandro P. Buchmann","ids":["1743524"]}],"journalName":"","paperAbstract":"Under update intensive workloads (TPC, LinkBench) small updates dominate the write behavior, e.g. 70% of all updates change less than 10 bytes across all TPC OLTP workloads. These are typically performed as in-place updates and result in random writes in page-granularity, causing major write-overhead on Flash storage, a write amplification of several hundred times and lower device longevity.\n In this paper we propose an approach that transforms those small in-place updates into small update deltas that are appended to the original page. We utilize the commonly ignored fact that modern Flash memories (SLC, MLC, 3D NAND) can handle appends to already programmed physical pages by using various low-level techniques such as ISPP to avoid expensive erases and page migrations. Furthermore, we extend the traditional NSM page-layout with a delta-record area that can absorb those small updates. We propose a scheme to control the write behavior as well as the space allocation and sizing of database pages.\n The proposed approach has been implemented under Shore- MT and evaluated on real Flash hardware (OpenSSD) and a Flash emulator. Compared to In-Page Logging [21] it performs up to 62% less reads and writes and up to 74% less erases on a range of workloads. The experimental evaluation indicates: (i) significant reduction of erase operations resulting in twice the longevity of Flash devices under update-intensive workloads; (ii) 15%-60% lower read/write I/O latencies; (iii) up to 45% higher transactional throughput; (iv) 2x to 3x reduction in overall write amplification.","inCitations":["d8552f846701a2758ff2bdd8112370ddd121badc"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035958"],"title":"From In-Place Updates to In-Place Appends: Revisiting Out-of-Place Updates on Flash","doi":"10.1145/3035918.3035958","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035958","venue":"SIGMOD Conference"},
{"entities":["32-bit","Algorithm","Attribute–value pair","Byte","Central processing unit","End-to-end encryption","Endeavour (supercomputer)","Gigabyte","Graphics processing unit","Memory bandwidth","PCI Express","Radix sort","Sorting","Sorting algorithm"],"journalVolume":"","journalPages":"417-432","pmid":"","year":2017,"outCitations":["aea592e9886c28a546ac3c74d3b2cf262836acc7","c06dbf2b7ff03f422b89dcd9c28a44c279099c8f","420a0e5fc398f197bca3dfe40291a82b2c65655a","0d75e43d77976353dc8fae02945d69c651604b88","a03d4b0cad5de84c025bc341945fd28da0582569","9c5882ea02390e3ca93d04aeeb4ec440ae17ff50","223353fed7921739e91e3757d5c0cbca14d45d32","1898098b68d4e664f0ebf9faec772c9a8ed4f946","4b7f05a35378a0b17a0f9af3180d43cf7970aa15","377571a4e7153f2607619ccab6ae32534f638b03","c5c16c6a974213168d589b647ae1858633a5fbe0","8572f800eeaae01b7faf7be62e041e3d08ea83ec","5a81b638c966141b12d47565eeecbfadc0e16fd1","60e7f7f9367e952f53b8545ef441886a84e3ff58","4139eedda8717ffd60052f68ed78b996aaebfced","2dbd58aa9b36388c92d3ccb5bd1bc387ea712a30","18cce5c91c9bc01b7e432980beaab00511af74e0","36305430c70e3b0d3409e47cf71d1e844e163122","05d372b38bb05c96e7575a9f48fe5e292fa34e0e","53d1657eef932911c95ed051961c8136d34ba486","07c1bb1c7169d1d6c8b6729be265d73a5fd6cc64","04abc8ba1238b7eb29c52e3677a55b5079e83b39","f465e873cb9d9e5cd74cc759c2b015da06385a86","32d355a7a20f92ccda0608f83d7456870231c570","8900d8141d4c81ec9aaac0f97399fed1e36827b2","138887a7f5c6c9614ab876de1d42c9a85462c5c8","b2bbe784fe5a691beae60a9710ff66fcda819dab","580835ee30534043f53b1cb03fe1f27ce85bcdcf","08639cd6b89ac8f375cdc1076b9485ac9d657083","2e166453a92457400c1127704f9e57c2f14634d2","0e2993ddba78626376651c3ab8d14f0d680f0595"],"s2Url":"https://semanticscholar.org/paper/459c33ccdeb78baff36c2d4a3d1b5b0b41b08b60","s2PdfUrl":"","id":"459c33ccdeb78baff36c2d4a3d1b5b0b41b08b60","authors":[{"name":"Elias Stehle","ids":["8562471"]},{"name":"Hans-Arno Jacobsen","ids":["1738552"]}],"journalName":"","paperAbstract":"Sorting is at the core of many database operations, such as index creation, sort-merge joins, and user-requested output sorting. As GPUs are emerging as a promising platform to accelerate various operations, sorting on GPUs becomes a viable endeavour. Over the past few years, several improvements have been proposed for sorting on GPUs, leading to the first radix sort implementations that achieve a sorting rate of over one billion 32-bit keys per second. Yet, state-of-the-art approaches are heavily memory bandwidth-bound, as they require substantially more memory transfers than their CPU-based counterparts. Our work proposes a novel approach that almost halves the amount of memory transfers and, therefore, considerably lifts the memory bandwidth limitation. Being able to sort two gigabytes of eight-byte records in as little as 50 milliseconds, our approach achieves a 2.32-fold improvement over the state-of-the-art GPU-based radix sort for uniform distributions, sustaining a minimum speed-up of no less than a factor of 1.66 for skewed distributions. To address inputs that either do not reside on the GPU or exceed the available device memory, we build on our efficient GPU sorting approach with a pipelined heterogeneous sorting algorithm that mitigates the overhead associated with PCIe data transfers. Comparing the end-to-end sorting performance to the state-of-the-art CPU-based radix sort running 16 threads, our heterogeneous approach achieves a 2.06-fold and a 1.53-fold improvement for sorting 64 GB key-value pairs with a skewed and a uniform distribution, respectively.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064043","https://arxiv.org/pdf/1611.01137v1.pdf","https://arxiv.org/pdf/1611.01137v2.pdf","http://arxiv.org/abs/1611.01137","https://arxiv.org/pdf/1611.01137.pdf"],"title":"A Memory Bandwidth-Efficient Hybrid Radix Sort on GPUs","doi":"10.1145/3035918.3064043","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064043","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Automatic parallelization","Computation","Fixed point (mathematics)","GRAPE","Parallel computing","Social media","Social media marketing","Termination analysis"],"journalVolume":"10","journalPages":"1889-1892","pmid":"","year":2017,"outCitations":["30d963e87c462606793d229dbdf0786ac38ede6e","1156f60e40548096df49528b1342bb3e88b0f378","68d3ada8bc4fb3de685cb870d9e72853d56b5c7d","2b9e6181502369199bd89691a27f89bdbaac36e4","b78c04c7f29ddaeaeb208d4eae684ffccd71e04f","75e217284d18901ce8b1fc4a389d3c1152b544fb","0ec9c37e6571cfbb69c98fabeccb620286f6eea3","87f931f4d8aad3b71b8261703bbcfa18c1293181","3bb6d5834bfb355553588e382ac5f9fa8a8d831d","0975baea2e5a34f75c06284ac355af7f2de2499b"],"s2Url":"https://semanticscholar.org/paper/691e4fcf559e9d19ee6354715a8ccdcc4416c47b","s2PdfUrl":"http://pdfs.semanticscholar.org/691e/4fcf559e9d19ee6354715a8ccdcc4416c47b.pdf","id":"691e4fcf559e9d19ee6354715a8ccdcc4416c47b","authors":[{"name":"Wenfei Fan","ids":["1777183"]},{"name":"Jingbo Xu","ids":["2724949"]},{"name":"Yinghui Wu","ids":["2948541"]},{"name":"Wenyuan Yu","ids":["37681774"]},{"name":"Jiaxin Jiang","ids":["2969767"]}],"journalName":"PVLDB","paperAbstract":"We demonstrate GRAPE, a parallel GRAPh query Engine. GRAPE advocates a parallel model based on a simultaneous fixed point computation in terms of partial and incremental evaluation. It differs from prior systems in its ability to parallelize existing sequential graph algorithms as a whole, without the need for recasting the entire algorithms into a new model. One of its unique features is that under a monotonic condition, GRAPE parallelization guarantees to terminate with correct answers as long as the sequential algorithms “plugged in” are correct. We demonstrate its parallel computations, ease-of-use and performance compared with the start-of-the-art graph systems. We also demonstrate a use case of GRAPE in social media marketing.","inCitations":["771610413f3654b8e4f38aab4dd970a481c7196f"],"pdfUrls":["http://www.research.ed.ac.uk/portal/files/42164359/p1889_fan.pdf","http://www.vldb.org/pvldb/vol10/p1889-fan.pdf"],"title":"GRAPE: Parallelizing Sequential Graph Computations","doi":"","sources":["DBLP"],"doiUrl":"","venue":"PVLDB"},
{"entities":["Sampling (signal processing)","Telematics","Web search engine"],"journalVolume":"","journalPages":"541-556","pmid":"","year":2017,"outCitations":["341a08d1854b5ecf871bbb4c7833a435927abbda","bd5374aff89135c13d7ecec1bcbfa46fe44a2b28","383478370162b80f1ef24ccc9c95e156fc808077","5866cd7c8cc8ba1578e5d80033d93849eb7792a7","0dd16e993f715a0c8b8d992d5c6ec1fd5d54eda0","999d2fe3e353dc6e667ff1450415920a05ee7e2f","a512812f72321eb4b198cc11cbd6755bfa71aa1c","b243eb82bfb859bdfe6c85b6b9eb5bcbe60d65ea","bef6dd24974bdb8d5b8ca6e0daea88b86ebacb93","1dea42bf7c515495906a7aa5c59b6cf37484e809","da8277e61a78224d965fc695477aa519fdef96cd","a11b243c571ade72c1be5bbb4105b00388174bd6","213a719cdecdd2e3a449c736db0d4449476ab323","52f15040034aa360cee4470f332c3ea2f105e545","1b88e9567c05701a4d7023c86b4e36685db88372","7e7b6249b598d9a4c63394e3a2efd008268ae851","b1465e8bcb39230525472c7ab4f3aba0cae9db3d","da01f7fcc5c7eeba75bc09a41fdd946e65210090","43512270b070aadfc572896f99a02de748e75db3","af81591de7f434c38ed16dff2eb4406f3c8a872f","d3c5b084da0ad30d75bcc630949fa4df0243eff2","6168504963fd5e100e0d86f6426826ead80bfefb","0c700847fa371cfe9b28f30eacf57fcd4243998e","4b155455a56bb0fb229d23e8ddcafdae263c9f65","7b45580d96f2b3c3fe95f960e38fad4cdf515712","469c93bd8a79c6a400405437cbb97cbfa3a27abe","2ce369cdbd656fd3a6df6e643657376e63d1aee2","16b04a8df23119ab446a33becde3e888cbbf854c","3096595380cfc118bb163b74897e13a84d094432","604929ca65a7ba35a135445546158d2901ed349f","2024c8eb42f6a64944e21636fb2ba725aff490c8","a90e2d5e65b1216a4f3a9e18c662c81f3c52fbaa","156e7730b8ba8a08ec97eb6c2eaaf2124ed0ce6e","4f4138548394b83146ff3c225c38f57d70a6cdfc","29373c5bb0d60320844905916aec09d64c24cd79","356f0b99f43251e2b2a0e66c3fd4c61c3baf2e32","c04534fc225c7db0780a8a38d37f9a45ced0d3d4","dcbcfaf9ef12c29a5120fc2eff57ab0634de4016","ad44d6645aed9dd9ac0791ef25841e8285f3fd7a","6d8c9fcce8177d6f8d122d653c7d32d7624d6714","5f7bdee8b639879090e8dee24188135833c94b2f","1df05b37ab38851a7537f5a7d1cc31d60ab819dd","ded1ab521c9839145040cb45c1f0c353536de8d5","7df1de1c9663c2dfaefc1277a7d1cb3366b8c358","1a55371d325cd1fd477ad42a9fab02048c70f5d9","1f1077fbfbabb3c529a2d97e81a1daa0e7eda43e","0bad381b84f48b28abc1a98f05993c8eb5be747d","bb75c8e0337a9e10e6eacf3d8aad9b51b446d3cf","0cc7d0a7a36ef920147b39eb7da49e8e8e5b951b","19d13084ea644842e42802ec7aac2fb977ed7584","b9e98e4c7a68a7c14b0d85d4fb6b0c6a6481e263","355692eb86b06a0a23af45c106cfb02c95bf380e","9f69b5c4afae4481ba85acbf147151296604e981","188e1d54d2c73b0b83e543d9183ec4c413625622","739f18de865a83d048e0e9e0dcb3b224e32691be","9af26df2edd37eca936ba261746d239242b488b6"],"s2Url":"https://semanticscholar.org/paper/9686c4d5ff91b6043fc21df7ebc241b8d34b8935","s2PdfUrl":"","id":"9686c4d5ff91b6043fc21df7ebc241b8d34b8935","authors":[{"name":"Peter Bailis","ids":["2740804"]},{"name":"Edward Gan","ids":["40209711"]},{"name":"Samuel Madden","ids":["2033016"]},{"name":"Deepak Narayanan","ids":["22252150"]},{"name":"Kexin Rong","ids":["7804757"]},{"name":"Sahaana Suri","ids":["2763552"]}],"journalName":"","paperAbstract":"As data volumes continue to rise, manual inspection is becoming increasingly untenable. In response, we present MacroBase, a data analytics engine that prioritizes end-user attention in high-volume fast data streams. MacroBase enables efficient, accurate, and modular analyses that highlight and aggregate important and unusual behavior, acting as a search engine for fast data. MacroBase is able to deliver order-of-magnitude speedups over alternatives by optimizing the combination of explanation and classification tasks and by leveraging a new reservoir sampler and heavy-hitters sketch specialized for fast data streams. As a result, MacroBase delivers accurate results at speeds of up to 2M events per second per query on a single core. The system has delivered meaningful results in production, including at a telematics company monitoring hundreds of thousands of vehicles.","inCitations":["391a6a423e06b0767e9fc9df4f43c5533c0ab662"],"pdfUrls":["http://www.bailis.org/papers/macrobase-sigmod2017.pdf","http://doi.acm.org/10.1145/3035918.3035928"],"title":"MacroBase: Prioritizing Attention in Fast Data","doi":"10.1145/3035918.3035928","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035928","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Gradient","Gradient descent","Iteration","Machine learning","SPARK","Stochastic gradient descent","Technological convergence","TensorFlow"],"journalVolume":"","journalPages":"463-478","pmid":"","year":2017,"outCitations":["70967767f355c34869029217bbaa0b2c32a193ec","0144941d255dad89d3d90c2d131a15cc01df9829","0122e063ca5f0f9fb9d144d44d41421503252010","0e9bac6a2b51e93e73f7f5045d4252972db10b5a","45619a2b7b41fea02345badf880530519d3d4c8f","11930afbab8b7629a45d8a717e7a924bc19ff4af","d26d2f73f1f0a1a2e0b606a581567c29fa90bdda","9cea29601e72fd8e6ef8419aa31ddc103eceb7f8","1e557937f418accc13f9c5edb33a3d48259d80e5","49503ab6a1f0c86a33c599adebe0e10e69b48c3a","0de0c3240bda7972bd0a3c8369ebc4b4f2e4f9c2","121d9c737a887f7f6a03ffbc5be87b26bdad17f8","3c029e72f5c75c8dd87a6acd43d05f23407e39cf","2b3113b7fda6414548e88fc664f3be96d5209830","4a0bb4eece00f3e9445d1a0d933422aa408ce8d1","89fe2dc8fbea1876ad351ac413d1af9c4878b45c","31f27864950a6c417cf996927b2d5558f70d2b14","4baac77b6242eb4c7bdbc62720f9c26e6dd044f6","31bd159b02068fbe1994b7a5e9d7b91adab0d142","395d819e9df1f9dc92a6bb871d055a39ece74ba8","34b8809c214db18544ce93674bf85fce0e8b3330","36f49b05d764bf5c10428b082c2d96c13c4203b9","006b89abc356c1c3bf2dfa35f47c0601c39dce38","043afbd936c95d0e33c4a391365893bd4102f1a7","4c4f01846be3ecc79d030d577b9933ea64c4bf4f","0790c77c1eaf2368b55c6a0def09a43690eeb848","0558c94a094158ecd64f0d5014d3d9668054fb97","419aebb6462f5b2021adb62385be1d778fcc685f","0546fa6622b8b8db8527be777a692d88c5c037b0","5c3785bc4dc07d7e77deef7e90973bdeeea760a5","ec941934e8389addb8620f911de9c83825fac9be","347920406c9a9a3846adf485e2b864d4523a0652","687c203c9d66f0b870fa4a48d02171c72824368d","8a7e4164d954eb55617362dcb18ca1359b4b753b","395ad865b5ab99e552f631fa713579c8fb6962e6","04c73e4f13a19a2ce270a0aa391bd7842aa113ae","244f7c483b1035144f04f7c58f20c3f806d3f1b3","391a5f286f814d852dddcab1b2b68e5c1af6c79e","44d4e4111ee7ba147c400a548d25108e92a4662e","1156f60e40548096df49528b1342bb3e88b0f378","b293405e9b3cfac8c58083b38bdc85d18dd0c187","471271dfcd33ceb2553b4bd3b3431983fd6ec888","04785a6c48ceeeaa0413c42cad206583868b863f","2b0cc03aa4625a09958c20dc721f4e0a52c13fd0","a058935fd019c2367fd32c16cd1ce6983a29aafb","7717b438da4ec3ca4247ff7abf6dd603e91fe41d"],"s2Url":"https://semanticscholar.org/paper/1b641441ded82bacf84cfb27986de81572ea5232","s2PdfUrl":"","id":"1b641441ded82bacf84cfb27986de81572ea5232","authors":[{"name":"Jiawei Jiang","ids":["3452475"]},{"name":"Bin Cui","ids":["1750622"]},{"name":"Ce Zhang","ids":["1776014"]},{"name":"Lele Yu","ids":["2697681"]}],"journalName":"","paperAbstract":"We study distributed machine learning in <i>heterogeneous environments</i> in this work. We first conduct a systematic study of existing systems running distributed stochastic gradient descent; we find that, although these systems work well in homogeneous environments, they can suffer performance degradation, sometimes up to 10x, in heterogeneous environments where stragglers are common because their synchronization protocols cannot fit a heterogeneous setting. Our first contribution is a heterogeneity-aware algorithm that uses a constant learning rate schedule for updates before adding them to the global parameter. This allows us to suppress stragglers' harm on robust convergence. As a further improvement, our second contribution is a more sophisticated learning rate schedule that takes into consideration the delayed information of each update. We theoretically prove the valid convergence of both approaches and implement a prototype system in the production cluster of our industrial partner Tencent Inc. We validate the performance of this prototype using a range of machine-learning workloads. Our prototype is 2-12x faster than other state-of-the-art systems, such as Spark, Petuum, and TensorFlow; and our proposed algorithm takes up to 6x fewer iterations to converge.","inCitations":["48bbf730ec09dec82a7f86df3c200724ef2467fa","0d561187be02ccf7905c0d2376796b5814e96a6c","4571230343fef61fd2ebeee8ab9704b6bd0752e9","f37f387ddba906fba0ae81d1b323b08cd4e1fe59","26b827cd12b0ff1c52dbf6bea1c2286bf1788d29","01ccc5b1487ad86632050e1c4cd546c6e140824f","48231ac69e8d17ce08a2868b27d1a9b08f99be83","a70ba22645eba9891e8cac8d08e36cc3d09e242b","4461768c4453d056a602ae60e5d86e5f105c519d","bd6cfcb0f3bd98d9fb9ebcb93c9389771563d96b","d0556be65e8564ab8bb3e26b6a0146a62027bc40"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035933","http://net.pku.edu.cn/~cuibin/Papers/2017%20sigmod.pdf"],"title":"Heterogeneity-aware Distributed Parameter Servers","doi":"10.1145/3035918.3035933","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035933","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Algorithmic efficiency","Analysis of algorithms","Baseline (configuration management)","Database","Database engine","Delta encoding","Dex","Dynamic programming","Heuristic","Pipeline (computing)","Query plan","Synthetic data","Version control"],"journalVolume":"","journalPages":"171-186","pmid":"","year":2017,"outCitations":["473fa1c5c66d4a51adbb64c263687d730fc6d217","5d37dbcead67858f972056555745041250bb1b6a","c9b91e05b4ad22ddd078b8658b14dd8fcba66d5f","62ea7fbdc3349f4fe8f12f098f1ce4a746faa5db","12b6044216d1a0849d74d1a7258619279027e8fc","75a4860c9b3b2e95bc3a8056543e7560a1753f2b","87f753c9679a8e06c35d4c5faa50015e8f602f0f","3bb527f0149baba20caa9a9dbbf5403066a5132f","844a6ced825c82a1eb31d03f62a0baa45d487406","3f8d104ebd8b63b761db1dc49747fbbb40681b70","1d1c3e69ceb5ac354f8a8a245da4dfc404ad266a","4306478b5205fb34e7a1036db4b714f51e419e45","09cacb2d068d605e6f8148b173524094a41670d5","5aefda15f1dcf04529bbf518659a23112cbb5246","2ff1c5db24059f32a086bc58b2bcfbeaaae23be4","215aad1520ec1b087ab2ba4043f5e0ecc32e7482","6616f158581ec7d7871c056a57a834ed2f09f528","07c589765de3d9a37ceb558d37fab03e091321a0","79e69f6a619c2d088ed8139a569e30c9628c1e1e","d79411c18f55d86bc9c9c7164108f77fb4f469aa","f458bd30b0f27959b1147ea8afa08ec8fef94ad5","d7ebd33290b4f178e1c0e9c294be28e321cd30e9","238bc5f0a213632d0928c7360d07f002fa7f1d37","209cd159fba2945dfd4d594998189dbd89e01652","29cc097c8d9ad13df2f1e02d6ab99a9ca2936178","363116c764453d9b740c46d23b1f5a3c5801d76e","3593269a4bf87a7d0f7aba639a50bc74cb288fb1","74e89eafa75fed08224710ef55007eb7cf349ce2","2f8da4fea7268c6f846af7453d763d2ec2da6111","03a666995669ebb66f3a8e7cd3b6e0f07a0f8d6a","1948575f4cedf689f708d1f0880e79de9ec4c4a5","b716349a3072afbede9f0fb8f561a8e0f297baf0","3ed00b246b5f3be959d0335203e59861024ac69d","c8e9e10457825d908e1a2bd1173c47d9dd3f3dec","46a574413123beb2ba0572c563e1a4883baec997","36288858ac21b08b863a7d181dd0430c4c91ab3f","1ae482036382ecde3ad475626504569a17421396","2c0e63c99e51fb7eefd96d9f63e5dc5a8709e179","f5c0978ee0166d19ede8184650dfae64d2784af1","0a4af05224a4837fe8b1df087528e74388b6fcbd","0dafdc7debdcae528b2549489a03509cb4ecb9fe","08b3d43e099f6afe15704cbf8388e01ebd2fd078","72d6c08256143c4445cfb349e84f2a220f082bf1","0fb2ab7176f91e34061b128c86ef100401a1b037","c5e4449a63eea9277672ef2e2d3f387449f6e2b0","0f41cd1792db9ff879fdfffc746cf5a01adf207f","5704f6ee368d4d178612d526ccbb300cdcb95d2c"],"s2Url":"https://semanticscholar.org/paper/6f6806f8dc90f1e1b73ee432602e13698a788827","s2PdfUrl":"","id":"6f6806f8dc90f1e1b73ee432602e13698a788827","authors":[{"name":"Amit Chavan","ids":["33651904"]},{"name":"Amol Deshpande","ids":["2313625"]}],"journalName":"","paperAbstract":"The increasing reliance on robust data-driven decision-making across many domains has made it necessary for data management systems to manage many thousands to millions of versions of datasets, acquired or constructed at various stages of analysis pipelines over time. <i>Delta encoding</i> is an effective and widely-used solution to compactly store a large number of datasets, that simultaneously exploits redundancies across them and keeps the average retrieval cost of reconstructing any dataset low. However, supporting any kind of rich retrieval or querying functionality, beyond single dataset checkout, is challenging in such storage engines. In this paper, we initiate a systematic study of this problem, and present DEX, a novel stand-alone delta-oriented execution engine, whose goal is to take advantage of the already computed deltas between the datasets for efficient query processing. In this work, we study how to execute <i>checkout, intersection, union</i> and <i>t-threshold</i> queries over record-based files; we show that processing of even these basic queries leads to many new and unexplored challenges and trade-offs. Starting from a query plan that confines query execution to a small set of deltas, we introduce new transformation rules based on the algebraic properties of the deltas, that allow us to explore the search space of alternative plans. For the case of checkout, we present a dynamic programming algorithm to efficiently select the optimal query plan under our cost model, while we design efficient heuristics to select effective plans that vastly outperform the base checkout-then-query approach for other queries. A key characteristic of our query execution methods is that the computational cost is primarily dependent on the size and the number of deltas in the expression (typically small), and not the input dataset versions (which can be very large). We have implemented DEX prototype on top of git, a widely used version control system. We present an extensive experimental evaluation on synthetic data with diverse characteristics, that shows that our methods perform exceedingly well compared to the baseline.","inCitations":["678f12849b2b0ce95a1a01961e73a8397e03c025","901c0c68e0cf0dc84d3f1f4ac7195b9a667da4bd"],"pdfUrls":["http://cs.umd.edu/~amitc/pubs/chavanA-dex.pdf","http://doi.acm.org/10.1145/3035918.3064056"],"title":"DEX: Query Execution in a Delta-based Storage System","doi":"10.1145/3035918.3064056","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064056","venue":"SIGMOD Conference"},
{"entities":["Algorithm","Data science","Data structure","Domain-specific modeling","Exploratory testing","In-memory database","Library (computing)","Machine learning","Motorola Canopy","Statistical model"],"journalVolume":"","journalPages":"557-572","pmid":"","year":2017,"outCitations":["aceb72aeefa7e6a752cfa25f75b57c1af4aa0d37","bd0de8fb2d9c1e1a6420f5842927d20216b271af","96ff658c6fd8237b789ff89ed485cf9503d59cb8","5208060771fd213eefd827e3e1260b939f1aed6d","418f49d4a4b58f8aa7ba610ee474420fec4f4a71","65c46b04244c194aafe5cff074e824b4aad081ce","8388bfc21e16e69bdda4b66db395a3618816c76d","3f419db6f66c32bbb7ea887b139abd4e088a0405","a70e02b6e42b908cdbc53bc6cecb532cf72d4d4a","2340c3dc69abd0b767d3c5dfd5de2d153399f776","44662438b9659fc7a48d32eae112dd9bcdef9ee3","6f1f5ab2eb6965e3fd12c21d4ed0fd76b3c12f85","8af01e6cb7375ff671ed6efd8576253ab6e12d04","a24d39e7c504a5705e4a480f99c1461992931934","1317f7e3d1de6ffd0888303ca95d9c8c6bae2af3","0d1346ced4b1b04765573433bfad5c328fd4e734","dc39c68a00e38f2993b450eb01c96e1d032ab850","156060edfc6b4b00871e9f9f83a994c5f97ad470","56974d490966a9d4f5c28f8be37fc34a08256388","1536706ebf24447ba6a45e5829c8bf036edf7b76","50b36b1b72056b9dc2814cd2c5d1a4146bebdd53","03a666995669ebb66f3a8e7cd3b6e0f07a0f8d6a","b6eb482777d1686f6ea2b0e2d05cb0ec9431a6b3","0b22e6cab2d101003b315c7b50ce0dc6060e37e0","299613bc57efd6e4bb590878220ecdd1d222d7b1","e321ac7f3872d07dbe8c6e634c96a4c28fb7a7aa","1fe660134bf98e6d5b8408a831b0fbc262979697","3493b2232449635aff50fc17e03163cb4b66f1b5","4de9d0429992392dce8508ba7800e11c03e42277","31d2c9e85d395b0dcb48123d03b1b33440d389fb","1c8e9f9fa4a030ef03d6b5f912a8ff1bc1cb2c47","78c5118f50ce4369809133cfb9496d2f97917c1e","588f2b2f5fa6d08ef729a64a45a1e15dfd90dd6e","3e140ea76fe8bbdcd0aa5702294ca4371376ba1b","0c0cfae57d32de295292fff6e67b2a22001bde23","541ddea3fa1cf2e22099f014101da492d12788b1","366c4ab50da396991b28c6fb58996ac7ff1775e8","0403ef9fd23e2a10069ac979ea56791aa1f0e580","62a8ec1501872ae45d7607ac83f08f89b0486a92","1f9e5cf7648c50ed764edcf0b8a6e32ad3aa5a96","845067be5ce40ff2e82257b834c6dff02e2d193c","23cedbae2800fecf6a3784faeda064f7f4ea6126","b63eaa5aab7788f783bc0f25c94c4eca7f19313b","11f5a2cfda10410dc581c6c09d08ef669238e978","42fee5b7c0d96f93172ac64bfef5a888874f3ab6","a6078ad365012c1f527c192894a9184daab8e597","406a30efc72f227c2c3289f3046cce44a0ff4a9c","efa5558bddd68abe4adc81adbbef6f739e648392","2321a150c84d771d81fd81759757795dcda25750","ad2ed0db597b4c87d1c6443e525d55d8c09656ee","dc638336827ebf5f6f2d4dd055bc2e6b9bffe2f0","17e01776d5734c27c5305ff3af6e904cfbf136f9","5eab0265b76dbcfaa1402a6e20acc12eff721a26","168de446821c0de9ebfa6d2145ca69837bd92671","3963ff791608bd2ee2621a00fa035efdf3d5048a","45790ddf3309753f47689da6ad2d874e2362c7f3","008b18ee86a04bf65e461c9d77f56bcbc28c3788","9c2a576de3e2dc9bc670f5bf8aeb7d9ec738d9ce","a5dba464aa71d5048408fc8ac9d734a284f1cd54","00aa614734a26a19b09a0a3bdee2adc77bdac5e4","0b9f263a7fe1a6a6f1db60068b72cba8f7510345","39ce3db4516cd6e7d7f8e580a494c7a665a6a16a","65e0af21793f0dc748a1755b736db4fbeb9bb4e8","7a278ee0578f194700cadc3811cdda4ec751f88a","81957286d692030cc7f1572debbb046edf11a43b","43aac4922fc82c1e8062d4d22b670701b93d980a"],"s2Url":"https://semanticscholar.org/paper/08a76016f0864089ea6d5cdf535382fe3d8c97fd","s2PdfUrl":"","id":"08a76016f0864089ea6d5cdf535382fe3d8c97fd","authors":[{"name":"Abdul Wasay","ids":["3224854"]},{"name":"Xinding Wei","ids":["10704708"]},{"name":"Niv Dayan","ids":["3242478"]},{"name":"Stratos Idreos","ids":["2203901"]}],"journalName":"","paperAbstract":"During exploratory statistical analysis, data scientists repeatedly compute statistics on data sets to infer knowledge. Moreover, statistics form the building blocks of core machine learning classification and filtering algorithms. Modern data systems, software libraries, and domain-specific tools provide support to compute statistics but lack a cohesive framework for storing, organizing, and reusing them. This creates a significant problem for exploratory statistical analysis as data grows: Despite existing overlap in exploratory workloads (which are repetitive in nature), statistics are always computed from scratch. This leads to repeated data movement and recomputation, hindering interactive data exploration.\n We address this challenge in Data Canopy, where descriptive and dependence statistics are synthesized from a library of basic aggregates. These basic aggregates are stored within an in-memory data structure, and and are reused for overlapping data parts and for various statistical measures. What this means for exploratory statistical analysis is that repeated requests to compute different statistics do not trigger a full pass over the data. We discuss in detail the basic design elements in Data Canopy, which address multiple challenges: (1) How to decompose statistics into basic aggregates for maximal reuse? (2) How to represent, store, maintain, and access these basic aggregates? (3) Under different scenarios, which basic aggregates to maintain? (4) How to tune Data Canopy in a hardware conscious way for maximum performance and how to maintain good performance as data grows and memory pressure increases?\n We demonstrate experimentally that Data Canopy results in an average speed-up of at least 10x after just 100 exploratory queries when compared with state-of-the-art systems used for exploratory statistical analysis.","inCitations":["38a96a0585e6d4c5f9fe5d326fd639bb289e69f8","b61bd7521b65077eac8381e71facc397060c60b0"],"pdfUrls":["http://daslab.seas.harvard.edu/classes/cs165/doc/guest_lectures/DC_CS165.pdf","https://stratos.seas.harvard.edu/files/stratos/files/datacanopy.pdf","http://doi.acm.org/10.1145/3035918.3064051","http://daslab.seas.harvard.edu/data-canopy/doc/DC_SIGMOD.pdf"],"title":"Data Canopy: Accelerating Exploratory Statistical Analysis","doi":"10.1145/3035918.3064051","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064051","venue":"SIGMOD Conference"},
{"entities":["Application programming interface","Computer data storage","Data compression","Distributed memory","Facebook Graph Search","Interactivity","Neo4j","Server (computing)","TAO","Terabyte","Throughput","Titan"],"journalVolume":"","journalPages":"1149-1164","pmid":"","year":2017,"outCitations":["0d8fadb88666b1137e9e767b5c82d2a98f807f2d","473fa1c5c66d4a51adbb64c263687d730fc6d217","0e3253e5ca318e70d4968a45f8d41f88dbffd9e3","0ad8e89091eed09217e66adc98136126addc2619","45a916500ce98c8d018c13de4c1d5c53130e8a72","15c7d3d5cfce46110a5aa5c6a482e359a96082b4","1e557937f418accc13f9c5edb33a3d48259d80e5","751d4061b9ec44b6824badd8384ce6022e377110","ef8d3a389410124d21dfda44295de8af786f5516","841e495ec20ab72170138b2f4fdf75bd17fd27bf","1521d39088b203ddac981d10d214f463449ae95b","c8e2d72db05ad9ec096058d7a5ed4bcdbf37ec8a","4dc578364f357b993b5554b9181c90c84aa6b4d1","32ed33a9bb1173cb9d9df9a3f8922a8c3cb6bddd","3dff11679346f5344af1018cad57fa14cc349f2f","dac57d16256af2f4913b72164a7bc3cb593937c1","3486aeaf540c48952120fe853d672af984f40a6a","19cadcb4e7439bc525c604771ab4872ec93a5b53","1a289721c6570d757f33be50dc80ebb22e29bf16","24e8be45a2b2a30a01b7e9f1502e7bd6a7870e7a","080f44d89bf6f4404f476ffec8d2f8ad3f60e07d","bcbc4b1f04f81e2af00ad0a5b83b55f52d638c24","0b9c6fe7beb3971b27aff8c5aa5e133de74316a4","62bfdedb87d1fed25eb5aa1bc6ff546c70a0ba6a","d1c21c34936f587779c216ed79ca33883845caa1","02c7714e034a832ce25bf0bf563cf0a789ad7342","2e1c33f55f80cb7e440435deb6f5fdf8bed95f47","1d99b7749a9311d2db24a3d84728e444eff23e4b","26deee037b221bd05ed34461819f5c067b745445","13f7df91eb208a387d18fbad192c6f0f834f0b82","2414283ed14ebb0eec031bb75cd25fbad000687e","39ac2e0fc4ec63753306f99e71e0f38133e58ead","59ca22b032e7e1fb4467a3b2ad577cbf9d8f0ea8","73dd7060a97f8ae5728ac2533926aee492400261","b9c5678100693e00b59e58f3368f4797b9f11e77","aac9932004ff0b07bcc40224c368f72553b424d2","0cc2bb8fe99755aacbb76100a345322d164835ab"],"s2Url":"https://semanticscholar.org/paper/1f93ee1306f9439eb7e82e638d0a48380d1bc0de","s2PdfUrl":"","id":"1f93ee1306f9439eb7e82e638d0a48380d1bc0de","authors":[{"name":"Anurag Khandelwal","ids":["2712026"]},{"name":"Zongheng Yang","ids":["1867996"]},{"name":"Evan Ye","ids":["10771670"]},{"name":"Rachit Agarwal","ids":["34292316"]},{"name":"Ion Stoica","ids":["1716557"]}],"journalName":"","paperAbstract":"We present ZipG, a distributed memory-efficient graph store for serving interactive graph queries. ZipG achieves memory efficiency by storing the input graph data using a compressed representation. What differentiates ZipG from other graph stores is its ability to execute a wide range of graph queries directly on this compressed representation. ZipG can thus execute a larger fraction of queries in main memory, achieving query interactivity. ZipG exposes a minimal API that is functionally rich enough to implement published functionalities from several industrial graph stores. We demonstrate this by implementing and evaluating graph queries from Facebook TAO, LinkBench, Graph Search and several other workloads on top of ZipG. On a single server with 244GB memory, ZipG executes tens of thousands of queries from these workloads for raw graph data over half a TB; this leads to an order of magnitude (sometimes as much as 23&#215;) higher throughput than Neo4j and Titan. We get similar gains in distributed settings compared to Titan.","inCitations":["306185d6b16f1ac9c770d2e2a80656cbdc1e9224"],"pdfUrls":["https://people.eecs.berkeley.edu/~anuragk/papers/zipg.pdf","http://www.cs.cornell.edu/~ragarwal/pubs/zipg.pdf","http://doi.acm.org/10.1145/3035918.3064012"],"title":"ZipG: A Memory-efficient Graph Store for Interactive Queries","doi":"10.1145/3035918.3064012","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064012","venue":"SIGMOD Conference"},
{"entities":["Attribute–value pair","Best, worst and average case","Bloom filter","Computational complexity theory","Computer data storage","Experiment","Key-value database","LevelDB","Lookup table","Memory footprint","Value (ethics)"],"journalVolume":"","journalPages":"79-94","pmid":"","year":2017,"outCitations":["39c88337433b1ddedb1a180a90dacff53810ebe5","7f49cad23f57a8bc48133b2c599d40c216d1c046","214c966d1f9c2a4b66f4535d9a0d4078e63a5867","7ae71ff8a5f950c12305f27d8584a9c9203717a9","1d99b7749a9311d2db24a3d84728e444eff23e4b","3492873a8bc6d1d501dcac97e891c43dfecc29c0","2b56f0ca7e74a43a54b70a7bb3507855c653a85b","9b90568faad1fd394737b79503571b7f5f0b2f4b","098d792d1783b5f6fc098203f71f21f5d053c653","59ca22b032e7e1fb4467a3b2ad577cbf9d8f0ea8","06bd4d2d21624c7713d7f10ccb7df61bf6b9ee71","f4147b82166813bbe5dc01e9486664c273d1556c","77ee477b0e6d0b6245eca5865ba95b55ed3db434","39ac2e0fc4ec63753306f99e71e0f38133e58ead","18a5f443299784479e78d9e77f175af57cb2fa2b","b05f104f5a28a1a2c2fdb216d3d0959a5786f0ad","3593269a4bf87a7d0f7aba639a50bc74cb288fb1","46d76119315b7f999ff52f97bbc7f078fe037aad","b4087345c63a7b2412eeb31066b5e4bceadbbcb2","395b3c67b88c7d094997e1c6ad75c5425cbc0400","09d1a6f5a50a8c3e066fb05a8833bc00663ada0e","199ac28b6bc68bf05c77645ffae7640df114bca5","19e5a8ea876cee86e78b659fc96ae18eb8c3a834"],"s2Url":"https://semanticscholar.org/paper/46c0f934ef0705b953ba8b14c5dee79b4df724db","s2PdfUrl":"","id":"46c0f934ef0705b953ba8b14c5dee79b4df724db","authors":[{"name":"Niv Dayan","ids":["3242478"]},{"name":"Manos Athanassoulis","ids":["1840402"]},{"name":"Stratos Idreos","ids":["2203901"]}],"journalName":"","paperAbstract":"In this paper, we show that key-value stores backed by an <b>LSM</b>-tree exhibit an intrinsic trade-off between lookup cost, update cost, and main memory footprint, yet all existing designs expose a suboptimal and difficult to tune trade-off among these metrics. We pinpoint the problem to the fact that all modern key-value stores suboptimally co-tune the merge policy, the buffer size, and the Bloom filters' false positive rates in each level.\n We present <b>Monkey</b>, an <b>LSM</b>-based key-value store that strikes the optimal balance between the costs of updates and lookups with any given main memory budget. The insight is that worst-case lookup cost is proportional to the sum of the false positive rates of the Bloom filters across all levels of the <b>LSM</b>-tree. Contrary to state-of-the-art key-value stores that assign a fixed number of bits-per-element to all Bloom filters, <b>Monkey</b> allocates memory to filters across different levels so as to minimize this sum. We show analytically that <b>Monkey</b> reduces the asymptotic complexity of the worst-case lookup I/O cost, and we verify empirically using an implementation on top of LevelDB that <b>Monkey</b> reduces lookup latency by an increasing margin as the data volume grows (50%-80% for the data sizes we experimented with). Furthermore, we map the <b>LSM</b>-tree design space onto a closed-form model that enables co-tuning the merge policy, the buffer size and the filters' false positive rates to trade among lookup cost, update cost and/or main memory, depending on the workload (proportion of lookups and updates), the dataset (number and size of entries), and the underlying hardware (main memory available, disk vs. flash). We show how to use this model to answer what-if design questions about how changes in environmental parameters impact performance and how to adapt the various <b>LSM</b>-tree design elements accordingly.","inCitations":["8542fdcb42804a31fedb86874e3c75cd03830d4d","5fca7b8c3ada3be2b41160a776c6389501998ce0","33b44d897e73fb50b9ab7bc3ebdc2986e3c77736","004fc351f16722654bf9d7ca2d36e90fec00cd5d"],"pdfUrls":["http://stratos.seas.harvard.edu/files/stratos/files/monkeykeyvaluestore.pdf","http://doi.acm.org/10.1145/3035918.3064054"],"title":"Monkey: Optimal Navigable Key-Value Store","doi":"10.1145/3035918.3064054","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064054","venue":"SIGMOD Conference"},
{"entities":["Benchmark (computing)","Mathematical optimization","Microsoft SQL Server","Online optimization","Optimization problem","Parameter (computer programming)","Plan","Prepared statement","Program optimization","Query optimization","SQL"],"journalVolume":"","journalPages":"1539-1554","pmid":"","year":2017,"outCitations":["4625894637eb3cafbdeb532e8c6a4d5c6f37aec2","350f2592b78f4b56adae1dedd07d370b81349652","3a20575b768022e3d3f20c0b8da386086cc49c57","53ad950cf2b6bc38bf377ffeff984c5175a064a9","280e98c45ceb53d878adbba0f8bee688c6716f7d","b6059f5464b8c03708a06b1aa3007d6825bbc9d0","f7991290e9555c18f5093de1d0c6c49bd1ad0bf0","018a9648b76366ef01057e4f235a0af5ade0068c","0685db30b47d0b389fdebcc9fbc0097894abb52a","a71d88bb81df4a0841bb5b06dbbe0835fa75876a","7d9ab1a068ea85df72a66826579feb397bd8687a","214fbc64cb1aed66af3dc948eceb35760c06e788","b082b168501959694f0181b1a01fa097bf62f937","1484eb5ced5ebe4eaf6f29a762f74f56d1d39340","037e3628bb6c0ed8db46927526ab13e15c79c832"],"s2Url":"https://semanticscholar.org/paper/390081f63e9e8014a3e2574fe02930d8ebd9d197","s2PdfUrl":"","id":"390081f63e9e8014a3e2574fe02930d8ebd9d197","authors":[{"name":"Anshuman Dutt","ids":["2387745"]},{"name":"Vivek R. Narasayya","ids":["1765803"]},{"name":"Surajit Chaudhuri","ids":["1728620"]}],"journalName":"","paperAbstract":"Parametric query optimization (PQO) deals with the problem of finding and reusing a relatively small number of plans that can achieve good plan quality across multiple instances of a parameterized query. An ideal solution to PQO would process query instances <i>online</i> and ensure (a) tight, bounded cost sub-optimality for each instance, (b) low optimization overheads, and (c) only a small number of plans need to be stored. Existing solutions to online PQO however, fall short on at least one of the above metrics. We propose a plan re-costing based approach that enables us to perform well on all three metrics. We empirically show the effectiveness of our technique on industry benchmark and real-world query workloads with our modified version of the Microsoft SQL Server query optimizer.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064040","https://www.microsoft.com/en-us/research/wp-content/uploads/2017/04/onlinePQO.pdf"],"title":"Leveraging Re-costing for Online Optimization of Parameterized Queries with Guarantees","doi":"10.1145/3035918.3064040","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064040","venue":"SIGMOD Conference"},
{"entities":["Computation","Cubic function","Data point","Dimensionality reduction","Inverse iteration","Kernel (operating system)","LU decomposition","Lagrange multiplier","Nonlinear dimensionality reduction","Nonlinear system","Power iteration","Ripple"],"journalVolume":"","journalPages":"1479-1492","pmid":"","year":2017,"outCitations":["06a934d2f0102d1a011e3f0e2d13bfe3a4cd9559","244e27bf8c5a5277a733c5271fdeb306f98115d5","1c718faf70f8285e7093c23d78a740a918a9a9fd","702049aa4b4255a7c40acde1cbc15787f38140f5","4f62d84f1171ec81519ecbe573fc617e174dd753","79b59321cfe90c3835a7b74d7e15de862614be5e","2059be0aa4a57d00d204c9ccdf4deeed2c984e07","a039592b7a86ce1d928aa12fa3d475f35c2a6e77","195e2a1e5e6ad0c3352730527723efa164e5dc34","ec975f959cc47a78dffc22d0219f3bf0b95de80e","ad612f9c4b3219120ad0c715614e06fd1caa6eec","1dbc30663ff1284534baf992ba82774817b2f36d","7419cb6342f5dba08790465dded2e9a79ef79ff5","708c6a0020f2c56ab225a748c3f90eb3faddfecc","27909aa46f74c23eae41912e27b0c9dc0bfacb0f","66dbec672b044eb917efb0c0d3238290688fd47f","be37eaa99bee96dec9c20964b79c37a07806843c","9c018f1b0aabe84ba61dfc969e273f2a9653c6ec","5a87d1c6cf8fc2737f1f8dedfb31ab364872cfe0","128fd1c7a051eb456480096b78d52e5f89533dc5","18bdc78571825b2cf66f18a0f52f3d218d02fb16","bf4f79fd31493648d80d0a4a8da5edeeaba74055","5a2d20868eddd4312c19c0144f2d651dc9141163","3339f78b2d27233d22fd806cfcdc6800a2a2d945","0ca73582f2c773ecbeeea6932bfc26494e965058","0c4867f11c9758014d591381d8b397a1d38b04a7","2d32885d9ba6a67598c9161a5ffbe5544e098d15","2ef606258486d6c32fd0b9ca54244273c21331b9","bf229459f3b3e617dafb5315262283eac2735634","456bdfe889ea06bc1a1c8891e65f57b5549b6e92","eede0832ebef207c2c55415294f44ce2fdc0b905","408cd9103f2d7cdafce2f6b984035b2be0ed9b7d","3b8a4cc6bb32b50b29943ceb7248f318e589cd79","c11169fbf077d8e762a476d3b38b14fc84edd8ab","6d73c9947d840cd84a8eee79c224add5fbbb929e","31181e73befea410e25de462eccd0e74ba8fea0b","0479b7e8c433e3f18a2b6c5dedd328f0229c1566","122eddb0391a84eb40bca0370975229919e2e10b"],"s2Url":"https://semanticscholar.org/paper/7667d3b352358134d46554400ebb0297102a9de2","s2PdfUrl":"","id":"7667d3b352358134d46554400ebb0297102a9de2","authors":[{"name":"Yasuhiro Fujiwara","ids":["32130106"]},{"name":"Naoki Marumo","ids":["3049487"]},{"name":"Mathieu Blondel","ids":["27257992"]},{"name":"Koh Takeuchi","ids":["2775065"]},{"name":"Hideaki Kim","ids":["2144822"]},{"name":"Tomoharu Iwata","ids":["2664600"]},{"name":"Naonori Ueda","ids":["1735221"]}],"journalName":"","paperAbstract":"Locally Linear Embedding (LLE) is a popular approach to dimensionality reduction as it can effectively represent nonlinear structures of high-dimensional data. For dimensionality reduction, it computes a nearest neighbor graph from a given dataset where edge weights are obtained by applying the Lagrange multiplier method, and it then computes eigenvectors of the LLE kernel where the edge weights are used to obtain the kernel. Although LLE is used in many applications, its computation cost is significantly high. This is because, in obtaining edge weights, its computation cost is cubic in the number of edges to each data point. In addition, the computation cost in obtaining the eigenvectors of the LLE kernel is cubic in the number of data points. Our approach, <i>Ripple</i>, is based on two ideas: (1) it incrementally updates the edge weights by exploiting the Woodbury formula and (2) it efficiently computes eigenvectors of the LLE kernel by exploiting the LU decomposition-based inverse power method. Experiments show that Ripple is significantly faster than the original approach of LLE by guaranteeing the same results of dimensionality reduction.","inCitations":[],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3064021","https://bigdata.nii.ac.jp/eratokansyasai4/wp-content/uploads/2017/09/a3e433715ef245279f3b644d59265792.pdf"],"title":"Scaling Locally Linear Embedding","doi":"10.1145/3035918.3064021","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3064021","venue":"SIGMOD Conference"},
{"entities":["Central processing unit","Computation","Contextual Query Language","Data model","Dynamic problem (algorithms)","Incremental computing","Internet of things","Numerical analysis","Online and offline","Query language","Signal processing"],"journalVolume":"","journalPages":"95-108","pmid":"","year":2017,"outCitations":["441556574aef7df8520b9040516350d09edbc7de","ac853fee48dd655536f1fab285d95427de34de6d","7ec028ace29244cb74c105327a7e4177a34aa6bd","43715cdc52b75ffaaff701852deafc4736a89081","d7a7c36223904b3030161ba04aa98ea1935b927d","edd661ca12ef8ef988679f7b399f2f846ef01fbd","52ef5f3c9dc4890d47af02aaa6bf43133ba5e6e1","0558c94a094158ecd64f0d5014d3d9668054fb97","e3482c42436fbc6c06397e53a966b4a7e344d2ba","5208060771fd213eefd827e3e1260b939f1aed6d","f9f2f902e2a7708e2e975cd5f53682e04e736785","f8e9b050c93af6dea582563f61b6460b590bc3af","0776c68524206020faa2651273d3ac80c6442a95","5850ead375e41daceeca0efd7d02b7f6e70578c1","7e7b6249b598d9a4c63394e3a2efd008268ae851","0ef1dd03db41de69165075562a051021a186c230","00c5d5189e29dba8f2729929476b739a5c35bc02","e847c3ec130da57328db79a7fea794b07dbccdd9","5ebcf0eebc36f9d355debb54816b81a9f4134673","6da6570ee13c04c9294581c290a793290b01f5cf","5de8c44c31696abbbda0a6664d2cf5b2586fd79a","5c94454722d8d4fb43bfd4e8449211267ab1d086","6df617304e9f1185694f11ca5cae5c27e868809b","1b3301aa8df5e31fa12789684e5047e6305190e9","439e9d67451d9d465601e704b78f159ab0fb4065","35ffae4ccf5e7ac45162b4e50e6a7da71fc74bea","d9c2586e599816defa98d04056fcb8e490d1eba4","83a500fcc7cd98db063b73461277ac885c8fe7c3","8af01e6cb7375ff671ed6efd8576253ab6e12d04"],"s2Url":"https://semanticscholar.org/paper/bd542ddc4b094d5cdbeea9c5ccf57b6f2d4c7dce","s2PdfUrl":"","id":"bd542ddc4b094d5cdbeea9c5ccf57b6f2d4c7dce","authors":[{"name":"Milos Nikolic","ids":["33994059"]},{"name":"Badrish Chandramouli","ids":["2241445"]},{"name":"Jonathan Goldstein","ids":["37070730"]}],"journalName":"","paperAbstract":"Internet of Things applications analyze the data coming from large networks of sensor devices using relational and signal processing operations and running the same query logic over groups of sensor signals. To support such increasingly important scenarios, many data management systems integrate with numerical frameworks like R. Such solutions, however, incur significant performance penalties as relational data processing engines and numerical tools operate on fundamentally different data models with expensive inter-communication mechanisms. In addition, none of these solutions supports efficient real-time and incremental analysis.\n In this paper, we advocate a deep integration of signal processing operations and general-purpose query processors. We aim to reconcile the disparate data models and provide a common query language that allows users to seamlessly interleave tempo-relational and signal operations for both online and offline processing. Our approach is extensible and offers frameworks for quick and easy integration of user-defined operations while supporting incremental computation. Our system that deeply integrates relational and signal operations, called TRILLDSP, achieves up to two orders of magnitude better performance than popular loosely-coupled data management systems on grouped signal processing workflows.","inCitations":["38a96a0585e6d4c5f9fe5d326fd639bb289e69f8","2127fddaf8bc57f74efd40d71c6cc364773063f1"],"pdfUrls":["http://doi.acm.org/10.1145/3035918.3035935","http://www.cs.ox.ac.uk/files/9135/sigmod2017-trilldsp.pdf"],"title":"Enabling Signal Processing over Data Streams","doi":"10.1145/3035918.3035935","sources":["DBLP"],"doiUrl":"https://doi.org/10.1145/3035918.3035935","venue":"SIGMOD Conference"},
