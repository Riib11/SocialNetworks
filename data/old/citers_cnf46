{"entities":["Kernel (operating system)"],"journalVolume":"","journalPages":"256-274","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/a76a3e5acaca9531a0b8628a9ed7a946ca717131","s2PdfUrl":"","id":"a76a3e5acaca9531a0b8628a9ed7a946ca717131","authors":[{"name":"Rob F. Van der Wijngaart","ids":["2636545"]},{"name":"Evangelos Georganas","ids":["2418537"]},{"name":"Timothy G. Mattson","ids":["2682150"]},{"name":"Andrew M. Wissink","ids":["3313944"]}],"journalName":"","paperAbstract":"","inCitations":[],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_14"],"title":"A New Parallel Research Kernel to Expand Research on Dynamic Load-Balancing Capabilities","doi":"10.1007/978-3-319-58667-0_14","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_14","venue":"ISC"},
{"entities":["Simulation"],"journalVolume":"","journalPages":"277-293","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/f1beead9a9d624f82b0c994fca9c0ea8e1da9058","s2PdfUrl":"","id":"f1beead9a9d624f82b0c994fca9c0ea8e1da9058","authors":[{"name":"Stephen Hamilton","ids":["5674766"]},{"name":"Randal C. Burns","ids":["1726784"]},{"name":"Charles Meneveau","ids":["1704150"]},{"name":"Perry Johnson","ids":["37511429"]},{"name":"Peter Lindstrom","ids":["1682771"]},{"name":"John Patchett","ids":["2465886"]},{"name":"Alexander S. Szalay","ids":["7934073"]}],"journalName":"","paperAbstract":"","inCitations":[],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_15"],"title":"Extreme Event Analysis in Next Generation Simulation Architectures","doi":"10.1007/978-3-319-58667-0_15","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_15","venue":"ISC"},
{"entities":["Simulation"],"journalVolume":"","journalPages":"3-21","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/29b5858fc907446023632d33359ebdf3a47ce763","s2PdfUrl":"","id":"29b5858fc907446023632d33359ebdf3a47ce763","authors":[{"name":"Christoph Rettinger","ids":["9035209"]},{"name":"Christian Godenschwager","ids":["3328821"]},{"name":"Sebastian Eibl","ids":["12519276"]},{"name":"Tobias Preclik","ids":["2063777"]},{"name":"Tobias Schruff","ids":["17114269"]},{"name":"Roy Frings","ids":["16686871"]},{"name":"Ulrich Rüde","ids":["1793279"]}],"journalName":"","paperAbstract":"","inCitations":["8fafdad93c6c03708e51e7b69fa42de3b46541e2","fad7ca95bdb8696c707ce9845f1752c60481772e"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_1"],"title":"Fully Resolved Simulations of Dune Formation in Riverbeds","doi":"10.1007/978-3-319-58667-0_1","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_1","venue":"ISC"},
{"entities":["Galerkin method"],"journalVolume":"","journalPages":"237-255","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/ea0ec5eca466341ecb4bf52eb1c66bd2cdee0b52","s2PdfUrl":"","id":"ea0ec5eca466341ecb4bf52eb1c66bd2cdee0b52","authors":[{"name":"Martin Kronbichler","ids":["1784588"]},{"name":"Katharina Kormann","ids":["1765698"]},{"name":"Igor Pasichnyk","ids":["5436472"]},{"name":"Momme Allalen","ids":["2540483"]}],"journalName":"","paperAbstract":"","inCitations":["096bf447a521f76c2874d523be4251af995b08b8"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_13"],"title":"Fast Matrix-Free Discontinuous Galerkin Kernels on Modern Computer Architectures","doi":"10.1007/978-3-319-58667-0_13","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_13","venue":"ISC"},
{"entities":["Message Passing Interface","Message passing","Message queue","Parallel computing","Program optimization","Scalability","Waypoint"],"journalVolume":"","journalPages":"217-236","pmid":"","year":2017,"outCitations":["09db308c41c3107b0fb25e1f61922da2ddc460d3","e98f988ad47a2c304036c8dcfb1c56ec99b11f85","03c316a2177d112efb7c64fae4fc10377419610b","cf60b4d7f37cc74ca7345a579201b89a010a67e8","33dce868e0d719474b9f822c139628d06eca7eb1","6f197e5aa64900079d760a397bb6a062df152ea6","14a3c198a025d77ba502410df5ed9aaadb96f66c","4849bbb611153b5a7c53894fa1c1314138f5ae89","51dcb9e45b0ff083ea015ed4be79e660ec5b1e2a","547014986afdf86ced23cdcce4583ee04f464160","da538cfbda96a1fe98142fee6f55261c8433f41b","7f2cbf3dd422dec88f5725700913a1d44c6f5beb","53211544bc0c9a0303a1380e422dfaf7642312d8","3e1e61d1128dae2038cd9701ba95f348f6d12db1","081c32609be4adcf16fe6f3bd6ae35ce2622edaf","5e555daf8dd73cee02ee54e7eff6cb90f2944ba9","8ce244596d60478c4c9c4dd5cf43c57e45fccfa2"],"s2Url":"https://semanticscholar.org/paper/63d9562d2e50c57e684faed416801732a37d39fd","s2PdfUrl":"http://pdfs.semanticscholar.org/63d9/562d2e50c57e684faed416801732a37d39fd.pdf","id":"63d9562d2e50c57e684faed416801732a37d39fd","authors":[{"name":"Benjamin Klenk","ids":["2712837"]},{"name":"Holger Fröning","ids":["1731123"]}],"journalName":"","paperAbstract":"The scale of applications and computing systems is tremendously increasing and needs to increase even more to realize exascale systems. As the number of nodes keeps growing, communication has become key to high performance. The Message Passing Interface (MPI) has evolved to the de facto standard for inter-node data transfers. Consequently, MPI is well suited to serve as proxy for an analysis of communication characteristics of exascale proxy applications. This work presents characteristics like time spent in certain operations, point-to-point versus collective communication, and message sizes and rates, gathered from a comprehensive trace analysis. We provide an understanding of how applications use MPI to exploit node-level parallelism, always with respect to scalability, and also locate parts which require more optimization. We emphasize on the analysis of the message matching and report queue lengths and associated matching rates. It is shown that most data is transferred via point-to-point operations, but the most time is spent in collectives. Message matching rates significantly depend on the length of message queues, which tend to increase with the number of processes. As messages are also become smaller, the matching is important to high message rates in large-scale applications.","inCitations":["97ce2604a719d65ee6ea3b7c7bb21a4b439262e6","3e1e61d1128dae2038cd9701ba95f348f6d12db1","798bb03fd4b95f7f5b23ae21893dfacd36c68fcf"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_12","http://www.ziti.uni-heidelberg.de/ziti/uploads/ce_group/2017-ISC.pdf"],"title":"An Overview of MPI Characteristics of Exascale Proxy Applications","doi":"10.1007/978-3-319-58667-0_12","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_12","venue":"ISC"},
{"entities":["Benchmark (computing)","Broadwell (microarchitecture)","CPU cache","Clock rate","Graph500","HPCG benchmark","Haswell (microarchitecture)","Ivy Bridge (microarchitecture)","Memory hierarchy","Sandy Bridge","Throughput","Uncore","snoop"],"journalVolume":"","journalPages":"294-314","pmid":"","year":2017,"outCitations":["044c1f0bcda1af4a5eb98074e46d847507a8384f","8ca9b31b957a8bf45b27d9caeb93b91437d50571","55512fc0be51166c06fbde0eda8c1e4cdccd298c","67cf1189c859d66bac309f9438df434fb651f97a","7c0c02245f6704a00800a43ecf7d87f0e977ff7e","9849a9a60d05c79e5cb757ef784982744ebab679","0f9080d297fc22dcf24dfd8ffcd3de5cea04c689","7caf696ceedc1d47c1cb54b1f0fcbf6c67a44613","2636777505e35452269dce101a6e4bc3577bccef","a62f4f774b8d473211fc5fdd2d54841107d5940a","d8d7a9c16c49b4456ef304f71ff91ee6e3039be6","aba0621a287a1aa2161d577ba81281864f3fcf3d","377175d109126aea51714e8ef0e4324d28eb6fcc","c793f23187645bfbc7424645e8b5e306f354807a","7f864cfdde0a6f92e90ac53a73079f4bea884d85","561dcca4267f105e7308751ee73a9273810f8079","092217c2267f6e0673590aa151d811e579ff7760"],"s2Url":"https://semanticscholar.org/paper/055359bf3807f067db7b3518540b719759df2388","s2PdfUrl":"http://pdfs.semanticscholar.org/0553/59bf3807f067db7b3518540b719759df2388.pdf","id":"055359bf3807f067db7b3518540b719759df2388","authors":[{"name":"Johannes Hofmann","ids":["1690745"]},{"name":"Georg Hager","ids":["1694080"]},{"name":"Gerhard Wellein","ids":["1708441"]},{"name":"Dietmar Fey","ids":["1798887"]}],"journalName":"","paperAbstract":"This paper presents a survey of architectural features among four generations of Intel server processors (Sandy Bridge, Ivy Bridge, Haswell, and Broadwell) with a focus on performance with floating point workloads. Starting on the core level and going down the memory hierarchy we cover instruction throughput for floating-point instructions, L1 cache, address generation capabilities, core clock speed and its limitations, L2 and L3 cache bandwidth and latency, the impact of Cluster on Die (CoD) and cache snoop modes, and the Uncore clock speed. Using microbenchmarks we study the influence of these factors on code performance. This insight can then serve as input for analytic performance models. We show that the energy efficiency of the LINPACK and HPCG benchmarks can be improved considerably by tuning the Uncore clock speed without sacrificing performance, and that the Graph500 benchmark performance may profit from a suitable choice of cache snoop mode settings.","inCitations":["43c75b376612800639bd9b23797690be44add6f6"],"pdfUrls":["https://arxiv.org/pdf/1702.07554v1.pdf","http://arxiv.org/abs/1702.07554","https://doi.org/10.1007/978-3-319-58667-0_16"],"title":"An Analysis of Core- and Chip-Level Architectural Features in Four Generations of Intel Server Processors","doi":"10.1007/978-3-319-58667-0_16","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_16","venue":"ISC"},
{"entities":["Algorithm","Fast multipole method","Recursion","Remote direct memory access","Scalability","Space-filling curve","Sparse matrix"],"journalVolume":"","journalPages":"79-96","pmid":"","year":2017,"outCitations":["044c2e4b6ee04fbc1b5838afd8583dc3d11e8222","d2652adc1e298877cfeddf93adbf5019364b3c99","3eb61d9182600f9402b17a1269eba9152f13ada3","6a110a740a2255f13bf27d199c6aa3a1789b9113","4b0b00804d6e57574dd5e12c0a1442ace392c58d","258e8729c918f01644a3f8d9f40aa23d9bea0130","014fd14d7ec998c5376c420c50abcb852d5924e0","2773ae9947e2f6cb58152824eca994434f1b8322","6d211d401b1d13eb054efd13b267f19e4c742aee","212f6bcfb4c1dff1636c29924251ffb20863cb41","66279f9b7a5123d623b8726567a7ce95b7d83d9c","2fe1c7a9be48f8ea8feaabf6d0ddd4ae0cee40ba","21e05bb43446475a2034a62dc8c67dfa368ea0d4","9766d4ef963ed2711ff6f86388192bcefe2385de","688384fc5e643445e835435e96b9dfcfb6598d36","876b16e6d6f2650d794bd13eda37fd15b2010b84","77e9cab2f965b970669052b634794eb19f377541","60c4e253965df3bdde1df6450599457bd2c214d3","aea49287b59299f3c33d29c412e368830da4b208","4dd07b62a60f095fba853292280df8069508f591"],"s2Url":"https://semanticscholar.org/paper/59b0e938a489511a6fe1021f79808ab917911f9c","s2PdfUrl":"http://pdfs.semanticscholar.org/59b0/e938a489511a6fe1021f79808ab917911f9c.pdf","id":"59b0e938a489511a6fe1021f79808ab917911f9c","authors":[{"name":"Mustafa Abdul Jabbar","ids":["8297244"]},{"name":"George S. Markomanolis","ids":["3180418"]},{"name":"Huda Ibeid","ids":["3083117"]},{"name":"Rio Yokota","ids":["2274654"]},{"name":"David Keyes","ids":["10867102"]}],"journalName":"","paperAbstract":"Reduction of communication and efficient partitioning are key issues for achieving scalability in hierarchical N -Body algorithms like FMM. In the present work, we propose four independent strategies to improve partitioning and reduce communication. First of all, we show that the conventional wisdom of using space-filling curve partitioning may not work well for boundary integral problems, which constitute about 50% of FMM’s application user base. We propose an alternative method which modifies orthogonal recursive bisection to solve the cell-partition misalignment that has kept it from scaling previously. Secondly, we optimize the granularity of communication to find the optimal balance between a bulk-synchronous collective communication of the local essential tree and an RDMA per task per cell. Finally, we take the dynamic sparse data exchange proposed by Hoefler et al. [1] and extend it to a hierarchical sparse data exchange, which is demonstrated at scale to be faster than the MPI library’s MPI Alltoallv that is commonly used.","inCitations":["f92991bab11e7cec59576305e6fd44f44e11aff7","48e6c7035b35a3ee8b8c2e430c158bfd7102a2fe","75e5df89fa0b9741a6f2b71f476f26d8aba2e24e"],"pdfUrls":["http://arxiv.org/abs/1702.05459","https://doi.org/10.1007/978-3-319-58667-0_5","https://arxiv.org/pdf/1702.05459v1.pdf"],"title":"Communication Reducing Algorithms for Distributed Hierarchical N-Body Problems with Boundary Distributions","doi":"10.1007/978-3-319-58667-0_5","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_5","venue":"ISC"},
{"entities":["Advanced Configuration and Power Interface","Control system","Dynamic voltage scaling","Open-source software","Perf (Linux)","Plug-in (computing)","Power management","Power supply","Procurement","Program optimization","Runtime system","Scalability","Scheduling (computing)","Software system","Xeon Phi"],"journalVolume":"","journalPages":"394-412","pmid":"","year":2017,"outCitations":["1e8233a8c8271c3278f1b84bed368145c0034a35","68eec7c5cd770a7d0af62f6856263bc675998fb0","12f815cc078020d26f57cfd86d1e4cd18fbc158a","244030cb8e73144251ef3701ac758168031d17f9","dd97355244bb2e1b369be0b2617e8452710ca44b","14bd3627a85b658ea1b8450039df7fe0fb57379e","81c4e99059104b00adc14f6797758aff998c066d","025b0273eb6ccd57e6a949fe44225ca5d8041cf9","8beda53e2b3cd04434aaaabef463ef8e18706df1","5175688633b7c22fdd0b1bec4f042c30d1650a15","51afdc23a72d19f7e6b1d46d25f7c7bb1814e85b","0acc688828bc8397d885f61cf9b7d4e4dcd7a119","429d28998216da5648f40248bf4bc9e508edd2fd","f103c1775462f4409ae15818cfa0a761e282d324","346ee93e610a95c60394900f857d398bc2ae74df","3875d86a9dc765b5ae2e66dc46d0da58ded6d75c","59b709fe6377d2332fe396bf25e9b65a10c1062c","7e757fff66a63b268da83ffccf464437492ac8b6"],"s2Url":"https://semanticscholar.org/paper/8755fd59b74028b0bd45e9b5c355c64c0c70af04","s2PdfUrl":"http://pdfs.semanticscholar.org/8755/fd59b74028b0bd45e9b5c355c64c0c70af04.pdf","id":"8755fd59b74028b0bd45e9b5c355c64c0c70af04","authors":[{"name":"Jonathan Eastep","ids":["2459613"]},{"name":"Steve Sylvester","ids":["29779938"]},{"name":"Christopher Cantalupo","ids":["1866337"]},{"name":"Brad Geltz","ids":["16916763"]},{"name":"Federico Ardanaz","ids":["3042670"]},{"name":"Asma Al-Rawi","ids":["40039182"]},{"name":"Kelly Livingston","ids":["2142084"]},{"name":"Fuat Keceli","ids":["1705061"]},{"name":"Matthias Maiterth","ids":["2975537"]},{"name":"Siddhartha Jana","ids":["38308455"]}],"journalName":"","paperAbstract":"Performance of future large-scale HPC systems will be limited by costs associated with scaling power. Some HPC centers are reaching the limits of their existent site power delivery infrastructure and are facing prohibitive upgrade costs. Others are reaching budgetary limits on their energy operating costs. Without a breakthrough in energy efficiency, the HPC industry may fail to maintain historical performance scaling rates and fall short of 2018-2020 Exascale performance goals by an estimated 23x margin. Overcoming this gap will require co-designed hardware and software system energy management solutions and increased collaboration between hardware vendors and the HPC software community. In this work, we introduce the Global Extensible Open Power Manager (GEOPM): a tree-hierarchical, plug-in extensible, open source runtime framework that we are contributing to the HPC community to accelerate collaboration and research toward co-designed energy management solutions. First results with an experimental power rebalancing optimization demonstrate up to 32% improvements in the runtime of CORAL system procurement benchmarks like miniFE and Nekbone in a power-limited Xeon Phi cluster. These promising initial results motivate further work with the community to extend GEOPM to new optimization strategies to achieve further speedups. Keywords—runtime systems; scalability; control systems; tuning; power management; RAPL; P-states; DVFS; resource management; power-aware scheduling; performance optimization","inCitations":["b4c32173842274974b5724d2fefd14efa0a67077","204ed869f69468d2c88ff64f67300d810f686c1a","c828d212e897354f926e4c1a724bd01c20ccebba","ca83bbc1d1ea5b5a829eed9acd638c626af2aa1d"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_21","http://www.dcs.warwick.ac.uk/pmbs/pmbs/PMBS/papers/paper6.pdf"],"title":"Global Extensible Open Power Manager: A Vehicle for HPC Community Collaboration on Co-Designed Energy Management Solutions","doi":"10.1007/978-3-319-58667-0_21","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_21","venue":"ISC"},
{"entities":["Algorithm","Big data","Central processing unit","Computer data storage","Disk storage","Graphics processing unit","Information retrieval","Memory hierarchy","Multi-core processor","Numerical analysis","Numerical weather prediction","Out of memory","Out-of-core algorithm","Singular value decomposition","Tiled web map"],"journalVolume":"","journalPages":"158-178","pmid":"","year":2017,"outCitations":["980bbba2c2a4fc66c2d19b34856a0d625910369a","33c2130b4459ecba1b58dfaf19012271ccb0998b","0a5617cf569abe3c669a71f4c604d47ca334ae12","70f1197b71aab1617e3c12cd61ee9977bd475c57","a6cbd9bde9bfd59f1594e8a9b96b6d40a7d106e9","82292f38366cbe3167c9de2d71ce86c75fba78a9","bad9b3e0cfddfeb33653bf869af7fffffcd6df8d","dd33bb8de5c88ffd5d71f550c003b0a6ec6440a2","57b832b09eacc30d2742ecb9e3249a0fef2f8d3a","30555c7ea92f59a9b2d3455ea98b1138015dce37","1145ebcc1738ac9b4d1c932402cd23460ae0bed4","c0ce67cfd7e60c0f2cd585353ab4d81be7e0cf7e","76d97e8cae2f5a2d660c294eb2a34faa493175a3","9cb5af4ec44a08510a31d5a6e4856152df89cd63","0747c3f13d5a8c906594caf6994b1e8f6654f175","f6430121b2af7d55b090a1c260570630e6cf1f41","14dec304cb9bbe9f37e04463b9746bc9ec569bd6","8ccb3d51dfceb07a752a62433dcc637efba3930d"],"s2Url":"https://semanticscholar.org/paper/3bf5bd82f4be1d2da6afc224de4827c81e22cb18","s2PdfUrl":"http://pdfs.semanticscholar.org/3db1/504b6711395e2cb733ae5734353605678242.pdf","id":"3bf5bd82f4be1d2da6afc224de4827c81e22cb18","authors":[{"name":"Khairul Kabir","ids":["37253985"]},{"name":"Azzam Haidar","ids":["2168650"]},{"name":"Stanimire Tomov","ids":["1706099"]},{"name":"Aurelien Bouteiller","ids":["1746341"]},{"name":"Jack J. Dongarra","ids":["1708869"]}],"journalName":"","paperAbstract":"Many important applications – from big data analytics to information retrieval, gene expression analysis, and numerical weather prediction – require the solution of large dense singular value decompositions (SVD). In many cases the problems are too large to fit into the computer’s main memory, and thus require specialized out-of-core algorithms that use disk storage. In this paper, we analyze the SVD communications, as related to hierarchical memories, and design a class of algorithms that minimizes them. This class includes out-of-core SVDs but can also be applied between other consecutive levels of the memory hierarchy, e.g., GPU SVD using the CPU memory for large problems. We call these out-of-memory (OOM) algorithms. To design OOM SVDs, we first study the communications for both classical one-stage blocked SVD and two-stage tiled SVD. We present the theoretical analysis and strategies to design, as well as implement, these communication avoiding OOM SVD algorithms. We show performance results for multicore architecture that illustrate our theoretical findings and match our performance models.","inCitations":["a25c7a004a5073c8284d643822dbd3b980c7d0fb"],"pdfUrls":["http://www.netlib.org/utk/people/JackDongarra/PAPERS/a-framework.pdf","https://doi.org/10.1007/978-3-319-58667-0_9","http://www.icl.utk.edu/files/publications/2017/icl-utk-952-2017.pdf"],"title":"A Framework for Out of Memory SVD Algorithms","doi":"10.1007/978-3-319-58667-0_9","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_9","venue":"ISC"},
{"entities":["Algorithm","Cloud computing","Firmware","Machine learning","Overhead (computing)","Resource contention","Software bug","Supercomputer","System administrator","System monitoring","Systems management","Time series"],"journalVolume":"","journalPages":"355-373","pmid":"","year":2017,"outCitations":["157c78c9752b50c632965c213ee85115ff426f67","9f428e6fc51549b12d781ae709054bd64ad741d7","0a5e8d1390f3ceb851f4a37a7ec8edb95e05f698","a31c4bf1eeb568ef3db3d425064eebdcbb832330","8beda53e2b3cd04434aaaabef463ef8e18706df1","397f311e2bac0a0b0e15dbda7cfb7a1bf9a8edce","580cd9345085036c200cbf0a75753653ecebfc94","1ac57524ba2d2a69c1bb6defed7352a06fd7050d","22be3604de30feae20b26f449caa1d2446445e48","3635141c7e3ed8190de4d799d06a71b027c32975","01d62cd850496455ce1616500f491690effa5c98","ffac367fd502040f71b65b1b4b659bfa83fe84c8","98234d0709b21a48cee4a0b82babb3d0c63f4145","0323b626078b11e63509339771c20a7e283a1d70","df97e1b49b7426b64fdaa01a1ffbfd669f0992f2","16a4367795dc7fde9bae65de3a5fda8300f27a46","0d8f9f2db5dd032758ca60cf535c1242d4273f5c","13deab526e6e0762f500694affe587ed298e5233","17f70a07e7f50f6f74952dbbbbe8b667f7db7634","5fac45d1333efb6438d43fef3cf776855140f013","9072581becff808f58b1f1b60baee233df478a7f","260368e4b7ddef442bb5c197078e200b3c0ab7b1","1be16d8c557b15cdf2db9e7eb4453f2274fd60af","4be228917846a218ba00d30b42d709a11b7a5311","20cf8768573bb412bf67e9f627c3216de8fb6cdb","a25131cc32cfc596afa5dbc463de1231024d5dfc","2de224c7c963a4ac466c37fa66cd2a4b1e2ec139","e0bc3395fefd71d81f540d754bc0fd2340c21f6e","4618c9e130481088e0a9d089728eb40576387f9b"],"s2Url":"https://semanticscholar.org/paper/657bc1afb7d045a6a6f9ae3b7a461dafeb045903","s2PdfUrl":"http://pdfs.semanticscholar.org/657b/c1afb7d045a6a6f9ae3b7a461dafeb045903.pdf","id":"657bc1afb7d045a6a6f9ae3b7a461dafeb045903","authors":[{"name":"Ozan Tuncer","ids":["3133439"]},{"name":"Emre Ates","ids":["16828201"]},{"name":"Yijia Zhang","ids":["3357436"]},{"name":"Ata Turk","ids":["1804097"]},{"name":"Jim M. Brandt","ids":["39920348"]},{"name":"Vitus J. Leung","ids":["2667137"]},{"name":"Manuel Egele","ids":["2489809"]},{"name":"Ayse Kivilcim Coskun","ids":["1809774"]}],"journalName":"","paperAbstract":"With the growing complexity and scale of high performance computing (HPC) systems, application performance variation has become a significant challenge in efficient and resilient system management. Application performance variation can be caused by resource contention as well as softwareand firmware-related problems, and can lead to premature job termination, reduced performance, and wasted compute platform resources. To effectively alleviate this problem, system administrators must detect and identify the anomalies that are responsible for performance variation and take preventive actions. However, diagnosing anomalies is often a difficult task given the vast amount of noisy and high-dimensional data being collected via a variety of system monitoring infrastructures. In this paper, we present a novel framework that uses machine learning to automatically diagnose previously encountered performance anomalies in HPC systems. Our framework leverages resource usage and performance counter data collected during application runs. We first convert the collected time series data into statistical features that retain application characteristics to significantly reduce the computational overhead of our technique. We then use machine learning algorithms to learn anomaly characteristics from this historical data and to identify the types of anomalies observed while running applications. We evaluate our framework both on an HPC cluster and on a public cloud, and demonstrate that our approach outperforms current state-of-the-art techniques in detecting anomalies, reaching an F-score over 0.97.","inCitations":["676e8d8260bc251229bec462ad5093d805152573","2c691ecaf440f21441a79ac09e675eca533bb9a8"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_19","http://www.bu.edu/peaclab/files/2017/04/tuncer_isc2017.pdf"],"title":"Diagnosing Performance Variations in HPC Applications Using Machine Learning","doi":"10.1007/978-3-319-58667-0_19","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_19","venue":"ISC"},
{"entities":["Data striping","Load balancing (computing)"],"journalVolume":"","journalPages":"315-333","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/b51cfc0298e4e3c80426c9a5ffca7a709c610ba3","s2PdfUrl":"","id":"b51cfc0298e4e3c80426c9a5ffca7a709c610ba3","authors":[{"name":"Yuichi Tsujita","ids":["1738234"]},{"name":"Tatsuhiko Yoshizaki","ids":["17074822"]},{"name":"Keiji Yamamoto","ids":["1833664"]},{"name":"Fumichika Sueyasu","ids":["2795389"]},{"name":"Ryoji Miyazaki","ids":["3594678"]},{"name":"Atsuya Uno","ids":["39083557"]}],"journalName":"","paperAbstract":"","inCitations":[],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_17"],"title":"Alleviating I/O Interference Through Workload-Aware Striping and Load-Balancing on Parallel File Systems","doi":"10.1007/978-3-319-58667-0_17","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_17","venue":"ISC"},
{"entities":["Algorithm","Graph (abstract data type)","Graphics processing unit","Parallel computing","Program optimization","Programming model","Real-time computing","Scalability","Social network","Speedup","Usability","Velocity","World Wide Web"],"journalVolume":"","journalPages":"97-119","pmid":"","year":2017,"outCitations":["2b0cc03aa4625a09958c20dc721f4e0a52c13fd0","4e88d42dc5f5efe565d87af3b999c43165e42dce","5dbbc4fe19a41441bdcce3395167e97df2d0d812","420a0e5fc398f197bca3dfe40291a82b2c65655a","22a26f40877cbd7ce0fb6c8c94e061332469d071","5bfb81407ab5102ba0369e86ca674eac081a4d0a","835914163add576b4c6c92ae0fcd34f661544ce2","2ae3f1fccf9a184b60585870ac839430f44cd201","75e217284d18901ce8b1fc4a389d3c1152b544fb","947c6bf534ccd620044f77c3bd6068f633b421fb","deaf88487bc3c0f24a809c40f88f393543579015","12809396d9e314df0c8f8e7ec9691bb69571b80d","1041d3f00afb5f5a53196813ceb2ebfab6d0a6ee","00dbf46a7a4ba6222ac5d44c1a8c09f261e5693c","9a8f16a532173bac3aece77d9451bdb3d7f2e57c","105de19ab71db0a38bc0d734c8fd0efeba2faab7","6f7cd29a3dfdcb2f6880a022e13054542020c5ce","3ebf3857a60c3e224284bbbe6c7127d0a12c546d","191fd33f17c2a79b3825d4cc2105c47a8f16ba44","0ad8e89091eed09217e66adc98136126addc2619","2a17c90ed723d6a14415cc1f677a5c0aa512f501","2ae3ac3f7463f838c38e6ca250ca294e813529f2","1156f60e40548096df49528b1342bb3e88b0f378","24e8be45a2b2a30a01b7e9f1502e7bd6a7870e7a","061c4eab625847e26a8fffeecde830bc0ddd22e1","41bdd5eee51158a292c91ca02930ed55ea3aa907","b513711621e81d0abd042e0877ca751581a993f5"],"s2Url":"https://semanticscholar.org/paper/a8992d84bf98a4dfb7a8ecbecf75eb07b7846a02","s2PdfUrl":"http://pdfs.semanticscholar.org/a899/2d84bf98a4dfb7a8ecbecf75eb07b7846a02.pdf","id":"a8992d84bf98a4dfb7a8ecbecf75eb07b7846a02","authors":[{"name":"Dipanjan Sengupta","ids":["6415958"]},{"name":"Shuaiwen Song","ids":["1798309"]}],"journalName":"","paperAbstract":"With the prevalence of the World Wide Web and social networks, there has been a growing interest in high performance analytics for constantly-evolving dynamic graphs. Modern GPUs provide massive amount of parallelism for efficient graph processing, but the challenges remain due to their lack of support for the near real-time streaming nature of dynamic graphs. Specifically, due to the current high volume and velocity of graph data combined with the complexity of user queries, traditional processing methods by first storing the updates and then repeatedly running static graph analytics on a sequence of versions or snapshots are deemed undesirable and computational infeasible on GPU. We present EvoGraph, a highly efficient and scalable GPUbased dynamic graph analytics framework that incrementally processes graphs on-the-fly using fixed-sized batches of updates. The runtime realizes this vision with a user friendly programming model, along with a vertex property-based optimization to choose between static and incremental execution; and efficient utilization of all hardware resources using GPU streams, including its computational and data movement engines. Extensive experimental evaluations for a wide variety of graph inputs and algorithms demonstrate that EvoGraph achieves up to 429 million updates/sec and over 232x speedup compared to the competing frameworks such as STINGER.","inCitations":[],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_6","https://people.csail.mit.edu/jshun/6886-s18/papers/EvoGraph.pdf"],"title":"EvoGraph: On-the-Fly Efficient Mining of Evolving Graphs on GPU","doi":"10.1007/978-3-319-58667-0_6","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_6","venue":"ISC"},
{"entities":["Discontinuous Galerkin method","Galerkin method","IBM WebSphere eXtreme Scale"],"journalVolume":"","journalPages":"41-60","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/e196bcb0dfea0854daa8714a377591e399fe858c","s2PdfUrl":"","id":"e196bcb0dfea0854daa8714a377591e399fe858c","authors":[{"name":"Alexander Breuer","ids":["38960812"]},{"name":"Alexander Heinecke","ids":["1722735"]},{"name":"Yifeng Cui","ids":["2305796"]}],"journalName":"","paperAbstract":"","inCitations":["3e78da59df3a1e72d2aa7d457d8fdfef6b6be9e4"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_3"],"title":"EDGE: Extreme Scale Fused Seismic Simulations with the Discontinuous Galerkin Method","doi":"10.1007/978-3-319-58667-0_3","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_3","venue":"ISC"},
{"entities":["Computational science","Experiment","Limiter","Mathematical optimization","Program optimization","Requirement"],"journalVolume":"","journalPages":"413-430","pmid":"","year":2017,"outCitations":["429d28998216da5648f40248bf4bc9e508edd2fd","08db6c20a034bfdb119e2eb3a049cccccb7e1fc0","260d0adfad93dfd02c7a945dee48c60f8fb938e1","8c12c4ff57e1992d1e3a926a2e75d3d4d9279c96","3d044d4f708b8803ca2323ede66ba5f303ac1fba","54cb190135885898a5fd780253ff14a821ff71cf","b1479a44735a4d93a99c3c1572acc6b752046c04","56e4263251aa8d1888ca5840e0bf187af043f49c","3fdd691621d41ddabdd225878536e4c75223971d","b83c318632affb34e58dbe847b26f491baf6653b","28e34059176c36934de116e138dd53cf4ee1dff0","db365cd0e6c42278fd091a1f3b710e443c2555a4","9d5b5e0e1547f172c3f0d75a78aa7d2894590520","02ebdcf8200135ec0433e12e4ef2459ac740370b","60f41423b70cd2ae454ae5802ad4e4927aeb9d6f","751ee769767a70b6dc1ac2dc57e8957d28308686","f4a91972bf1a05b195bce06a24dc33960bff1151","52d4b916fe76401dc0477e4a00528103cdae4625","6e0607664ee56a9c3404b9b5a570665b4d26a3a0","e17e7bffaa7bdda0dcdec8eb4d200a13e4e156a4"],"s2Url":"https://semanticscholar.org/paper/049a1ac1c022f7b800b185d313239ccb9b60bfed","s2PdfUrl":"http://pdfs.semanticscholar.org/dc80/59bb1d5aa7745b86cd7e3441d60c516b0b86.pdf","id":"049a1ac1c022f7b800b185d313239ccb9b60bfed","authors":[{"name":"Stephen Roberts","ids":["3448436"]},{"name":"Steven A. Wright","ids":["40431102"]},{"name":"Suhaib A. Fahmy","ids":["3450002"]},{"name":"Stephen A. Jarvis","ids":["1690561"]}],"journalName":"","paperAbstract":"Energy consumption is rapidly becoming a limiting factor in scientific computing. As a result, hardware manufacturers increasingly prioritise energy efficiency in their processor designs. Performance engineers are also beginning to explore software optimisation and hardware/software co-design as a means to reduce energy consumption. Energy efficiency metrics developed by the hardware community are often re-purposed to guide these software optimisation efforts. In this paper we argue that established metrics, and in particular those in the Energy Delay Product (Et) family, are unsuitable for energy-aware software optimisation. A good metric should provide meaningful values for a single experiment, allow fair comparison between experiments, and drive optimisation in a sensible direction. We show that Et metrics are unable to fulfil these basic requirements and present suitable alternatives for guiding energy-aware software optimisation. We finish with a practical demonstration of the utility of our proposed metrics.","inCitations":[],"pdfUrls":["http://wrap.warwick.ac.uk/87287/13/WRAP-metrics-energy-aware-software-optimisation-Roberts-2017.pdf","https://doi.org/10.1007/978-3-319-58667-0_22","http://wrap.warwick.ac.uk/87287/7/WRAP_Wright_paper.pdf"],"title":"Metrics for Energy-Aware Software Optimisation","doi":"10.1007/978-3-319-58667-0_22","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_22","venue":"ISC"},
{"entities":["ARM architecture","Haswell (microarchitecture)"],"journalVolume":"","journalPages":"377-393","pmid":"","year":2017,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/2cfa6c557899f09d9a6529ce5ce90251d699bf17","s2PdfUrl":"","id":"2cfa6c557899f09d9a6529ce5ce90251d699bf17","authors":[{"name":"Vojtech Nikl","ids":["2905015"]},{"name":"Michal Hradecky","ids":["16846587"]},{"name":"Jakub Keleceni","ids":["17100725"]},{"name":"Jirí Jaros","ids":["2231982"]}],"journalName":"","paperAbstract":"","inCitations":["91ff6b19c86e74fab4b8c680c52587218d3067e0"],"pdfUrls":["https://doi.org/10.1007/978-3-319-58667-0_20"],"title":"The Investigation of the ARMv7 and Intel Haswell Architectures Suitability for Performance and Energy-Aware Computing","doi":"10.1007/978-3-319-58667-0_20","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_20","venue":"ISC"},
{"entities":[],"journalVolume":"","journalPages":"22-40","pmid":"","year":2017,"outCitations":["da683799144f0b4db8b41d0bd0e0c09414883bab","9b87e0c65c7d517d81d6422849f927dc66b0f059","5425e73a772c68b4be27b6886d7ea8efe2c6f38c","d9b4d4ffa5bf9e9e376b0bdeba19d4090d653feb","0962ac3ffefd3b3ad5b9a0d25862d95f347be82b","ce97ce67ad3f5644601bd2bde69de62ab56be1c7","04717b51d7c7dd598d732fb8a293d69d45c0fa9f","47309382ed0b272a47a48e0b6dc2eaca12fcbe94","db81eb62f54ff80033c6123e7d3c524574bcc458","0fd82e4ff009aadd492d10c889370c73308a3ca2","952896a6656080d1a0e021733bfaa237dd53f832","4c9e7233cc630109709d9ccf9814140fd1d28c9f","917fd12162c12c0fd2cb6409de1dd438531c553a","9498bb96328c3e9498772241b55031570e6577d1"],"s2Url":"https://semanticscholar.org/paper/8f422aa51611bee4905ba431fbd7778651d3f930","s2PdfUrl":"http://pdfs.semanticscholar.org/8f42/2aa51611bee4905ba431fbd7778651d3f930.pdf","id":"8f422aa51611bee4905ba431fbd7778651d3f930","authors":[{"name":"Kadir Akbudak","ids":["2572064"]},{"name":"Hatem Ltaief","ids":["1754635"]},{"name":"Aleksandr Mikhalev","ids":["39625255"]},{"name":"David E. Keyes","ids":["1794014"]}],"journalName":"","paperAbstract":"Covariance matrices are ubiquitous in computational science and engineering. In particular, large covariance matrices arise from multivariate spatial data sets, for instance, in climate/weather modeling applications to improve prediction using statistical methods and spatial data. One of the most time-consuming computational steps consists in calculating the Cholesky factorization of the symmetric, positive-definite covariance matrix problem. The structure of such covariance matrices is also often data-sparse, in other words, effectively of low rank, though formally dense. While not typically globally of low rank, covariance matrices in which correlation decays with distance are nearly always hierarchically of low rank. While symmetry and positive definiteness should be, and nearly always are, exploited for performance purposes, exploiting low rank character in this context is very recent, and will be a key to solving these challenging problems at large-scale dimensions. The authors design a new and flexible tile row rank Cholesky factorization and propose a high performance implementation using OpenMP task-based programming model on various leading-edge manycore architectures. Performance comparisons and memory footprint saving on up to 200K×200K covariance matrix size show a gain of more than an order of magnitude for both metrics, against state-of-the-art open-source and vendor optimized numerical libraries, while preserving the numerical accuracy fidelity of the original model. This research represents an important milestone in enabling large-scale simulations for covariance-based scientific applications.","inCitations":["8deaa1b91a446d77728ee61189ec5fc5234277c7","434025cbbe35130e4a8efdcc9f5d53eb42156fb7"],"pdfUrls":["http://www.springer.com/cda/content/document/cda_downloaddocument/9783319586663-c2.pdf?SGWID=0-0-45-1606804-p180852894","https://doi.org/10.1007/978-3-319-58667-0_2"],"title":"Tile Low Rank Cholesky Factorization for Climate/Weather Modeling Applications on Manycore Architectures","doi":"10.1007/978-3-319-58667-0_2","sources":["DBLP"],"doiUrl":"https://doi.org/10.1007/978-3-319-58667-0_2","venue":"ISC"},
