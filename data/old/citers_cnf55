{"entities":["AOC2 gene","Adenosine Triphosphate","Algorithm","Approximate computing","Approximation algorithm","Automated theorem proving","CNS disorder","Call of Duty: Black Ops","Certification","Communications protocol","Computation","Computation (action)","Computer engineering","Computer science","Computers","Concolic testing","Data center","Embedded system","Ephedra sinica","Evaluation","Failure rate","Graphics processing unit","Hearing Loss, High-Frequency","Liver Failure, Acute","Lossy compression","Machine learning","Middleware","Multi-core processor","NAM","Network as a service","Operating system","Participatory sensing","Program optimization","Remote direct memory access","Requirement","Sampling (signal processing)","Simulation","Single point of failure","Solutions","Stream processing","Streaming media","Subgroup","Therapy, Computer-Assisted","Tsung","Ventral Tegmental Area","Video processing","YunOS","algorithm"],"journalVolume":"","journalPages":"","pmid":"","year":2018,"outCitations":[],"s2Url":"https://semanticscholar.org/paper/6bb78ed774f4c82c38c923479dfe61abdefe3a0d","s2PdfUrl":"http://pdfs.semanticscholar.org/6bb7/8ed774f4c82c38c923479dfe61abdefe3a0d.pdf","id":"6bb78ed774f4c82c38c923479dfe61abdefe3a0d","authors":[{"name":"Yiyang Chang","ids":["2629017"]}],"journalName":"","paperAbstract":"Network architects must ensure that networks meet Service Level Objectives (SLOs), i.e., meet a performance metric a desired percentage of time. The recent shift towards tightly provisioned networks has made this challenging given that failures are the norm. In this talk, I will present a principled approach to tackling the problem. It is based on Slice, our new optimization-based algorithm, which analytically classifies potential failure scenarios into those where the network performs acceptably or violates requirements. The approach combines Slice with network modeling and statistical sampling algorithms in novel ways. Our evaluations show that our approach is effective in certifying network designs and achieves orders of magnitude reduction in (and may even eliminate) explicit testing needs, relative to current practice. Further, our approach identifies failure scenarios with unacceptable performance and accommodates a variety of network and failure models. Bio Yiyang Chang is a Ph.D. student in the School of Electrical and Computer Engineering at Purdue University, advised by Professor Sanjay Rao. He obtained B.S. degree from School of EECS, Peking University. His research interest lies in the area of Computer Networks. He currently focuses on network certification with optimization approaches. Contact him at chang256@purdue.edu Stop Worrying and Start Embracing Lossy Network: a Datacenter Network Protocol for Approximate Computing Ke Liu Abstract Many datacenter applications such as machine learning and streaming systems do not need the complete set of data to perform their computation. These approximate applications often choose to select a subset of data and then transmit them over a reliable network layer like TCP. With such network-oblivious approaches, there is a huge missing opportunity in improving both the performance and accuracy of datacenter approximate applications. We propose to run approximate applications on a lossy network and to allow packet loss (or even intentionally create more) in a controlled manner. Specifically, we designed a new network protocol called Approximate Transmission Protocol, or ATP, for datacenter approximate applications. Our simulation results show that ATP can improve both the performance and accuracy of approximate applications than network-oblivious solutions.Many datacenter applications such as machine learning and streaming systems do not need the complete set of data to perform their computation. These approximate applications often choose to select a subset of data and then transmit them over a reliable network layer like TCP. With such network-oblivious approaches, there is a huge missing opportunity in improving both the performance and accuracy of datacenter approximate applications. We propose to run approximate applications on a lossy network and to allow packet loss (or even intentionally create more) in a controlled manner. Specifically, we designed a new network protocol called Approximate Transmission Protocol, or ATP, for datacenter approximate applications. Our simulation results show that ATP can improve both the performance and accuracy of approximate applications than network-oblivious solutions. ------------Previous Talks ------------------2017 Fall schedule Speaker: please edit the corresponding row to reflect your talk Date Speaker Title 8/30 9/6 Hongyu Miao StreamBox: Modern Stream Processing on a Multicore Machine 9/13 9/20 9/27 Kangjing Huang DryadSynth: A Concolic SyGuS Solver 10/4 10/11 10/18 Shin-Yeh Tsai LITE Kernel RDMA Support for Datacenter Applications 10/25 Heng Zhang Sense-Aid: A framework for enabling network as a service for participatory sensing. 11/1 Bo Fu Parallel Video Processing Using Embedded Computers 11/8 Yizhou Shan Disaggregated Operating System 11/15 11/22 Ashraf Y. Mahgoub Rafiki: A Middleware for Automated Parameters Tuning 11/29 Tsung Tai Yeh Dynamic Warp Collapsing on the GPU 12/6 Yun Seong Nam ABRTuner: Improving the Tail Performance of Video Delivery","inCitations":[],"pdfUrls":["https://wiki.itap.purdue.edu/download/temp/pdfexport-20180302-020318-0300-4935/CES-computerengineeringgraduateseminars-020318-0300-4936.pdf?contentType=application/pdf"],"title":"Ensuring Network Designs Meet Service Level Objectives under Failures","doi":"","sources":[],"doiUrl":"","venue":""},
{"entities":["Aclarubicin","Algorithm","Apache Cassandra","Artificial neural network","Big data","Brute-force search","Data model","Database","Default","Digital Object Identifier","Genetic algorithm","Metagenomics","Metagenomics","Middleware","Neural Network Simulation","NoSQL","Performance","Published Database","Semi-structured data","Surrogate model","Throughput","Workload","algorithm"],"journalVolume":"","journalPages":"","pmid":"","year":2017,"outCitations":["c7ef1e1c9ec1e8ed17b6b634b6963b37838b9614","274a6c951c4aa82e6ef6b9f63c11f0ef66722c20","d7a86ea11c7683a46c324935f82a3065327974ef","1b2457906994b5942b0ecc6e0ca38e2e3b2450c7","8913c7f26429b0e69ca4ad4ba07f7ec5c5567659","8e14f79db4b0d7109ad4db46771ed8673cd265b6","384b6bb8d2ea993ff3cb092ff41bb1c4d5308720","4bfc9a7abd7caf5fb6ab35e3c0e7a7d96adaa1b8","d82ea66f0de4d97abc16b6807acf9ae6c9061e77","3a57e1242fdd3de7604f5b4fe21a8cd152dfce4f","a6d3ceea74deba7ba762ec051492d79794933e98","bc3f207f50ff335be514f66d3c3031b4040fabc2","13d98a5621e1249032a7ddc3a167dc15841a8ada","49532e318be89eed64725b32617c1fc570f824a4","51d6588ff7c1994f035a5a3be8d2e8ca62b78f22","86c83cf81f2df8f6dc4c05843bb2412415e4655b","841dbff787e715ffb5b4c6b5a9841e0a2da0f1a0","9b707fda4ef927f92d9ecb86dea82bd1ede59d49","6b9334e099770bb5e26e408d2bb238cd613afd71","1ccaac0fdcc5ab37a45d0cc616feeaa67a3d4ca1","b93dd6f80d7685c21025aaaa27e972a2af6287d0","6f2270c81885e2f5b3b6bc86f0b2099af9c55534","24cece61e2128780072bc58f90b8ba47f624bc27","9c422cea3027bcb20f48ec94873edf2e071d3dd3","9aa0d7253574e50fe3a190ccd924433f048997dd","18a5f443299784479e78d9e77f175af57cb2fa2b","8162d4f3bfce2055c9a53c267af66103c3bfd167","81ae1752547df73e8b83315515e11967035b8db3","7fed1be51db2c780cd5504f519a5ab9bd484ac56","3fbc9316a792974ba103be76702a6ce5c8d33f2d","d24359f702ff56d53dbecf6197b5af76bedbe8d0"],"s2Url":"https://semanticscholar.org/paper/83c798881b911f7a15e5022ab4d0973fffcd040f","s2PdfUrl":"http://pdfs.semanticscholar.org/83c7/98881b911f7a15e5022ab4d0973fffcd040f.pdf","id":"83c798881b911f7a15e5022ab4d0973fffcd040f","authors":[],"journalName":"","paperAbstract":"High performance computing (HPC) applications, such as metagenomics and other big data systems, need to store and analyze huge volumes of semi-structured data. Such applications oen rely on NoSQL-based datastores, and optimizing these databases is a challenging endeavor, with over 50 conguration parameters in Cassandra alone. As the application executes, database workloads can change rapidly from read-heavy to write-heavy ones, and a system tuned with a read-optimized conguration becomes suboptimal when the workload becomes write-heavy. In this paper, we present a method and a system for optimizing NoSQL congurations for Cassandra and ScyllaDB when running HPC and metagenomics workloads. First, we identify the signicance of conguration parameters using ANOVA. Next, we apply neural networks using the most signicant parameters and their workload-dependent mapping to predict database throughput, as a surrogate model. en, we optimize the conguration using genetic algorithms on the surrogate to maximize the workloaddependent performance. Using the proposed methodology in our system (Rafiki), we can predict the throughput for unseen workloads and conguration values with an error of 7.5% for Cassandra and 6.9-7.8% for ScyllaDB. Searching the conguration spaces using the trained surrogate models, we achieve performance improvements of 41% for Cassandra and 9% for ScyllaDB over the default conguration with respect to a read-heavy workload, and also signicant improvement for mixed workloads. In terms of searching speed, Rafiki, using only 1/1000-th of the searching time of exhaustive search, reaches within 15% and 9.5% of the theoretically best achievable performances for Cassandra and ScyllaDB, respectively— supporting optimizations for highly dynamic workloads. ACM Reference format: Elided. 2016. Rafiki: A Middleware for Parameter Tuning of NoSQL Datastores for Dynamic Metagenomics Workloads. In Proceedings of ACM Conference, Washington, DC, USA, July 2017 (Conference’17), 13 pages. DOI: 10.1145/nnnnnnn.nnnnnnn","inCitations":[],"pdfUrls":["https://engineering.purdue.edu/dcsl/publications/papers/2017/final_rafiki_middleware17_submitted.pdf"],"title":"Rafiki: A Middleware for Parameter Tuning of NoSQL Datastores for Dynamic Metagenomics Workloads","doi":"","sources":[],"doiUrl":"","venue":""},
